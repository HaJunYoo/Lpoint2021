{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf189e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T14:17:24.254983Z",
     "start_time": "2021-12-07T14:17:21.420805Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638cc381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T14:17:34.688657Z",
     "start_time": "2021-12-07T14:17:24.259006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./L.POINT_train.csv')\n",
    "df_test = pd.read_csv('./L.POINT_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e061a5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T14:17:35.730782Z",
     "start_time": "2021-12-07T14:17:35.710046Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('./y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a92a90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T14:17:37.979391Z",
     "start_time": "2021-12-07T14:17:37.947432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_ID</th>\n",
       "      <th>SESS_ID</th>\n",
       "      <th>HITS_SEQ</th>\n",
       "      <th>PD_C</th>\n",
       "      <th>PD_ADD_NM</th>\n",
       "      <th>PD_BRA_NM</th>\n",
       "      <th>PD_BUY_AM</th>\n",
       "      <th>PD_BUY_CT</th>\n",
       "      <th>SESS_SEQ</th>\n",
       "      <th>SESS_DT</th>\n",
       "      <th>...</th>\n",
       "      <th>TOT_SESS_HR_V</th>\n",
       "      <th>DVC_CTG_NM</th>\n",
       "      <th>ZON_NM</th>\n",
       "      <th>CITY_NM</th>\n",
       "      <th>KWD_NM</th>\n",
       "      <th>SEARCH_CNT</th>\n",
       "      <th>PD_NM</th>\n",
       "      <th>CLAC1_NM</th>\n",
       "      <th>CLAC2_NM</th>\n",
       "      <th>CLAC3_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6771240</td>\n",
       "      <td>63</td>\n",
       "      <td>578845</td>\n",
       "      <td>1개</td>\n",
       "      <td>필립스(PHILIPS)</td>\n",
       "      <td>81,000</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20180609</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Bucheon-si</td>\n",
       "      <td>에어컨 커버</td>\n",
       "      <td>1</td>\n",
       "      <td>아방세 프로믹스 핸드블렌더 HR1672/90</td>\n",
       "      <td>생활/주방가전</td>\n",
       "      <td>주방가전</td>\n",
       "      <td>블랜더</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6771240</td>\n",
       "      <td>63</td>\n",
       "      <td>788068</td>\n",
       "      <td>선택:버닝 [베이지] / 1개</td>\n",
       "      <td>쁘리엘르</td>\n",
       "      <td>5,500</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20180609</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Bucheon-si</td>\n",
       "      <td>에어컨 커버</td>\n",
       "      <td>1</td>\n",
       "      <td>스판 벽걸이 에어컨커버(트라이앵글_82x27x26) 모음 - 블루가든 [블루]</td>\n",
       "      <td>침구/수예</td>\n",
       "      <td>수예소품</td>\n",
       "      <td>거실수예소품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5762174</td>\n",
       "      <td>109</td>\n",
       "      <td>180447</td>\n",
       "      <td>사이즈:L(105) / 1개</td>\n",
       "      <td>퀵실버</td>\n",
       "      <td>59,000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20180626</td>\n",
       "      <td>...</td>\n",
       "      <td>1,661</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>바비브라운</td>\n",
       "      <td>1</td>\n",
       "      <td>퀵실버 남성 루즈핏 래쉬가드 QS579KMT - M(100)</td>\n",
       "      <td>시즌스포츠</td>\n",
       "      <td>수영/물놀이</td>\n",
       "      <td>남성수영복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5753875</td>\n",
       "      <td>94</td>\n",
       "      <td>731145</td>\n",
       "      <td>1개</td>\n",
       "      <td>키엘</td>\n",
       "      <td>39,000</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20180626</td>\n",
       "      <td>...</td>\n",
       "      <td>620</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>키엘</td>\n",
       "      <td>2</td>\n",
       "      <td>칼렌듈라 딥 클렌징 포밍 페이스 워시 230ml</td>\n",
       "      <td>화장품/뷰티케어</td>\n",
       "      <td>스킨케어</td>\n",
       "      <td>페이셜클렌저</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7417570</td>\n",
       "      <td>114</td>\n",
       "      <td>216947</td>\n",
       "      <td>1개</td>\n",
       "      <td>키엘</td>\n",
       "      <td>49,000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20180529</td>\n",
       "      <td>...</td>\n",
       "      <td>860</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>키엘비타민</td>\n",
       "      <td>2</td>\n",
       "      <td>키엘 자외선 차단제 점보 세트</td>\n",
       "      <td>화장품/뷰티케어</td>\n",
       "      <td>선케어</td>\n",
       "      <td>선크림류</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLNT_ID  SESS_ID  HITS_SEQ    PD_C         PD_ADD_NM     PD_BRA_NM  \\\n",
       "0        0  6771240        63  578845                1개  필립스(PHILIPS)   \n",
       "1        0  6771240        63  788068  선택:버닝 [베이지] / 1개          쁘리엘르   \n",
       "2        1  5762174       109  180447   사이즈:L(105) / 1개           퀵실버   \n",
       "3        1  5753875        94  731145                1개            키엘   \n",
       "4        1  7417570       114  216947                1개            키엘   \n",
       "\n",
       "  PD_BUY_AM PD_BUY_CT  SESS_SEQ   SESS_DT  ...  TOT_SESS_HR_V DVC_CTG_NM  \\\n",
       "0    81,000         1        17  20180609  ...            922     mobile   \n",
       "1     5,500         1        17  20180609  ...            922     mobile   \n",
       "2    59,000         1        12  20180626  ...          1,661     mobile   \n",
       "3    39,000         1        13  20180626  ...            620     mobile   \n",
       "4    49,000         1         2  20180529  ...            860     mobile   \n",
       "\n",
       "        ZON_NM     CITY_NM  KWD_NM SEARCH_CNT  \\\n",
       "0  Gyeonggi-do  Bucheon-si  에어컨 커버          1   \n",
       "1  Gyeonggi-do  Bucheon-si  에어컨 커버          1   \n",
       "2        Seoul       Seoul   바비브라운          1   \n",
       "3        Seoul       Seoul      키엘          2   \n",
       "4        Seoul       Seoul   키엘비타민          2   \n",
       "\n",
       "                                         PD_NM  CLAC1_NM CLAC2_NM CLAC3_NM  \n",
       "0                     아방세 프로믹스 핸드블렌더 HR1672/90   생활/주방가전     주방가전      블랜더  \n",
       "1  스판 벽걸이 에어컨커버(트라이앵글_82x27x26) 모음 - 블루가든 [블루]     침구/수예     수예소품   거실수예소품  \n",
       "2            퀵실버 남성 루즈핏 래쉬가드 QS579KMT - M(100)     시즌스포츠   수영/물놀이    남성수영복  \n",
       "3                   칼렌듈라 딥 클렌징 포밍 페이스 워시 230ml  화장품/뷰티케어     스킨케어   페이셜클렌저  \n",
       "4                             키엘 자외선 차단제 점보 세트  화장품/뷰티케어      선케어     선크림류  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dda9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72089"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['KWD_NM'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9b4bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72089"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['KWD_NM'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58c0edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1948686 entries, 0 to 1948685\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   CLNT_ID          int64  \n",
      " 1   SESS_ID          int64  \n",
      " 2   HITS_SEQ         int64  \n",
      " 3   PD_C             int64  \n",
      " 4   PD_ADD_NM        object \n",
      " 5   PD_BRA_NM        object \n",
      " 6   PD_BUY_AM        object \n",
      " 7   PD_BUY_CT        object \n",
      " 8   SESS_SEQ         int64  \n",
      " 9   SESS_DT          int64  \n",
      " 10  TOT_PAG_VIEW_CT  float64\n",
      " 11  TOT_SESS_HR_V    object \n",
      " 12  DVC_CTG_NM       object \n",
      " 13  ZON_NM           object \n",
      " 14  CITY_NM          object \n",
      " 15  KWD_NM           object \n",
      " 16  SEARCH_CNT       int64  \n",
      " 17  PD_NM            object \n",
      " 18  CLAC1_NM         object \n",
      " 19  CLAC2_NM         object \n",
      " 20  CLAC3_NM         object \n",
      "dtypes: float64(1), int64(7), object(13)\n",
      "memory usage: 312.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece92141",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>263094</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>263095</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>263096</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>263102</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>263103</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CLNT_ID LABEL\n",
       "0             0   F20\n",
       "1             1   F30\n",
       "2             6   F20\n",
       "3             9   F30\n",
       "4            12   F30\n",
       "...         ...   ...\n",
       "149995   263094   F30\n",
       "149996   263095   F30\n",
       "149997   263096   F30\n",
       "149998   263102   F30\n",
       "149999   263103   F30\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd3f984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F20', 'F30', 'F40', 'M30', 'M40', 'M20'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['LABEL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbebde54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F30    59892\n",
       "F40    51936\n",
       "F20    17727\n",
       "M40     9904\n",
       "M30     7953\n",
       "M20     2588\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc49a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.37857506,  1.        ,  1.15318854, 23.14219474,  7.53074312,\n",
       "        6.04725363])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([59892/17727, 59892/59892, 59892/51936, 59892/2588, 59892/7953, 59892/9904])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c54b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, y, how='left', on='CLNT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7dd636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['CLNT_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60366f9c",
   "metadata": {},
   "source": [
    "1948686행, 150000 유저 -> 유저당 평균 13회 로그 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a892d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280867"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['PD_C'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d04ee",
   "metadata": {},
   "source": [
    "280867개 고유 상품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c58577d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  DVC_CTG_NM\n",
       "F20    mobile        150178\n",
       "       tablet           519\n",
       "       desktop           18\n",
       "F30    mobile        794940\n",
       "       tablet          2417\n",
       "       desktop           13\n",
       "F40    mobile        772145\n",
       "       tablet          5190\n",
       "       desktop           29\n",
       "M20    mobile         19259\n",
       "       tablet           150\n",
       "       desktop            9\n",
       "M30    mobile         78795\n",
       "       tablet           109\n",
       "       desktop           10\n",
       "M40    mobile        123945\n",
       "       tablet           896\n",
       "       desktop           64\n",
       "Name: DVC_CTG_NM, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='LABEL')['DVC_CTG_NM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5efabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gyeonggi-do', 'Seoul', 'Jeollabuk-do', 'Gwangju', 'Busan',\n",
       "       'Incheon', 'Gyeongsangnam-do', 'Gyeongsangbuk-do',\n",
       "       'Chungcheongnam-do', 'Jeollanam-do', 'Daegu', 'Gangwon-do',\n",
       "       'Ulsan', 'Daejeon', 'Chungcheongbuk-do', 'Jeju-do'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ZON_NM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a7d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bucheon-si', 'Seoul', 'Wanju-gun', 'Gwangju', 'Namyangju-si',\n",
       "       'Guri-si', 'Busan', 'Imsil-gun', 'Gimpo-si', 'Incheon',\n",
       "       'Gimhae-si', 'Paju-si', 'Sangju-si', 'Yeongi-gun', 'Hwaseong-si',\n",
       "       'Gongju-si', 'Seongnam-si', 'Andong', 'Jeongeup-si', 'Geoje-si',\n",
       "       'Gangjin-gun', 'Gumi-si', 'Yeoju-gun', 'Pyeongtaek-si', 'Daegu',\n",
       "       'Yongin-si', 'Yangsan-si', 'Chuncheon-si', 'Suwon-si', 'Ulsan',\n",
       "       'Tongyeong-si', 'Haman-gun', 'Goyang-si', 'Daejeon', 'Cheonan-si',\n",
       "       'Yeosu-si', 'Jeonju-si', 'Taean-gun', 'Chungju-si', 'Uijeongbu-si',\n",
       "       'Gangneung-si', 'Gyeongju-si', 'Hanam-si', 'Sunchang-gun',\n",
       "       'Mungyeong-si', 'Gunsan-si', 'Wonju-si', 'Uiwang-si', 'Anseong',\n",
       "       'Anyang', 'Ansan-si', 'Gunpo-si', 'Sacheon-si', 'Cheongju-si',\n",
       "       'Miryang-si', 'Gimcheon-si', 'Sokcho-si', 'Yeongju-si', 'Jeju-si',\n",
       "       'Siheung-si', 'Pohang-si', 'Seosan-si', 'Hapcheon-gun',\n",
       "       'Yangju-si', 'Taebaek-si', 'Muan-gun', 'Goesan-gun', 'Jindo-gun',\n",
       "       'Gwangju-si', 'Yangpyeong-gun', 'Yeongyang-gun', 'Hongseong-gun',\n",
       "       'Goryeong-gun', 'Naju-si', 'Icheon-si', 'Yeongdong-gun',\n",
       "       'Gwangmyeong-si', 'Asan-si', 'Gyeongsan-si', 'Gochang-gun',\n",
       "       'Hoengseong-gun', 'Yeongdeok-gun', 'Uljin-gun', 'Seongju-gun',\n",
       "       'Suncheon-si', 'Cheorwon-gun', 'Boseong-gun', 'Yesan-gun', 'Iksan',\n",
       "       'Geumsan-gun', 'Jincheon-gun', 'Dangjin-si', 'Jeungpyeong-gun',\n",
       "       'Jinju-si', 'Gapyeong-gun', 'Mokpo-si', 'Seogwipo-si', 'Namwon-si',\n",
       "       'Jangheung-gun', 'Geochang-gun', 'Gwangyang-si', 'Goseong-gun',\n",
       "       'Chilgok-gun', 'Donghae-si', 'Yeongcheon-si', 'Cheongwon-gun',\n",
       "       'Yangyang-gun', 'Osan-si', 'Haenam-gun', 'Gwacheon-si',\n",
       "       'Yeonggwang-gun', 'Dongducheon-si', 'Yeongam-gun', 'Eumseong-gun',\n",
       "       'Gokseong-gun', 'Cheongyang-gun', 'Yeongwol-gun', 'Nonsan-si',\n",
       "       'Hongcheon-gun', 'Jecheon-si', 'Danyang-gun', 'Pyeongchang-gun',\n",
       "       'Hamyang-gun', 'Hwasun-gun', 'Buyeo-gun', 'Samcheok-si',\n",
       "       'Okcheon-gun', 'Cheongsong-gun', 'Yecheon-gun', 'Buan-gun',\n",
       "       'Boeun-gun', 'Gyeryong-si', 'Yanggu-gun', 'Gurye-gun', 'Wando-gun',\n",
       "       'Sancheong-gun', 'Namhae-gun', 'Hampyeong-gun', 'Hwacheon-gun',\n",
       "       'Gimje-si', 'Cheongdo-gun', 'Jeongseon-gun', 'Pocheon-si',\n",
       "       'Changnyeong-gun', 'Goheung-gun', 'Boryeong-si', 'Jinan-gun',\n",
       "       'Uiseong-gun', 'Damyang-gun', 'Seocheon-gun', 'Uiryeong-gun',\n",
       "       'Yeoncheon-gun', 'Jangsu-gun', 'Jangseong-gun', 'Sinan-gun',\n",
       "       'Inje-gun', 'Gunwi-gun', 'Ulleung-gun', 'Bonghwa-gun',\n",
       "       'Hadong-gun', 'Muju-gun', '(not set)'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CITY_NM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af1aeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             아방세 프로믹스 핸드블렌더 HR1672/90\n",
       "1          스판 벽걸이 에어컨커버(트라이앵글_82x27x26) 모음 - 블루가든 [블루]\n",
       "2                    퀵실버 남성 루즈핏 래쉬가드 QS579KMT - M(100)\n",
       "3                           칼렌듈라 딥 클렌징 포밍 페이스 워시 230ml\n",
       "4                                     키엘 자외선 차단제 점보 세트\n",
       "                              ...                     \n",
       "1948681         돌핀 배색 올인원 수영복[71SW77831] - 핑크(P) / 110\n",
       "1948682         돌핀 배색 올인원 수영복[71SW77831] - 핑크(P) / 110\n",
       "1948683         돌핀 배색 올인원 수영복[71SW77831] - 핑크(P) / 110\n",
       "1948684         돌핀 배색 올인원 수영복[71SW77831] - 핑크(P) / 110\n",
       "1948685        여아 돌고래 배색 래쉬가드[71SW50831] - 핑크(P) / 105\n",
       "Name: PD_NM, Length: 1948686, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PD_NM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f7e576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['PD_NM'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d550b76",
   "metadata": {},
   "source": [
    "num(PD_C) != num(PD_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb38360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 128, 883)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['CLAC1_NM'].unique()), len(df['CLAC2_NM'].unique()), len(df['CLAC3_NM'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6390f2",
   "metadata": {},
   "source": [
    "대분류 37개, 중분류 128개, 소분류 883개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e17f6370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           에어컨 커버\n",
       "1           에어컨 커버\n",
       "2            바비브라운\n",
       "3               키엘\n",
       "4            키엘비타민\n",
       "            ...   \n",
       "1948681       키즈샌들\n",
       "1948682        갭키즈\n",
       "1948683      팁토이조이\n",
       "1948684    갭키즈 수영복\n",
       "1948685     갭키즈 여아\n",
       "Name: KWD_NM, Length: 1948686, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KWD_NM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116203fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KWD_NM'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c0f18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          2\n",
       "4          2\n",
       "          ..\n",
       "1948681    1\n",
       "1948682    1\n",
       "1948683    1\n",
       "1948684    1\n",
       "1948685    1\n",
       "Name: SEARCH_CNT, Length: 1948686, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEARCH_CNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d76e5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clnt_id = y['CLNT_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69a11a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      6, ..., 263096, 263102, 263103], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clnt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7707353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PD_BUY_CT'] = df['PD_BUY_CT'].astype('string')\n",
    "df['TOT_SESS_HR_V'] = df['TOT_SESS_HR_V'].astype('string')\n",
    "\n",
    "df['PD_BUY_AM'] = df['PD_BUY_AM'].map(lambda x: x.replace(',', ''))\n",
    "df['PD_BUY_CT'] = df['PD_BUY_CT'].map(lambda x: x.replace(',', ''))\n",
    "df['TOT_SESS_HR_V'] = df['TOT_SESS_HR_V'].map(lambda x: x.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0501b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PD_BUY_AM'] = df['PD_BUY_AM'].astype('int')\n",
    "df['PD_BUY_CT'] = df['PD_BUY_CT'].astype('int')\n",
    "df['TOT_SESS_HR_V'] = df['TOT_SESS_HR_V'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd757e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SESS_DT'] = df['SESS_DT'].map(lambda x: date.fromisoformat(str(x)[:4] + '-' + str(x)[4:6] + '-' + str(x)[6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fe195ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_ID</th>\n",
       "      <th>SESS_ID</th>\n",
       "      <th>HITS_SEQ</th>\n",
       "      <th>PD_C</th>\n",
       "      <th>PD_ADD_NM</th>\n",
       "      <th>PD_BRA_NM</th>\n",
       "      <th>PD_BUY_AM</th>\n",
       "      <th>PD_BUY_CT</th>\n",
       "      <th>SESS_SEQ</th>\n",
       "      <th>SESS_DT</th>\n",
       "      <th>...</th>\n",
       "      <th>DVC_CTG_NM</th>\n",
       "      <th>ZON_NM</th>\n",
       "      <th>CITY_NM</th>\n",
       "      <th>KWD_NM</th>\n",
       "      <th>SEARCH_CNT</th>\n",
       "      <th>PD_NM</th>\n",
       "      <th>CLAC1_NM</th>\n",
       "      <th>CLAC2_NM</th>\n",
       "      <th>CLAC3_NM</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12</td>\n",
       "      <td>4738380</td>\n",
       "      <td>47</td>\n",
       "      <td>178471</td>\n",
       "      <td>사이즈:18M / 1개</td>\n",
       "      <td>갭 키즈</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>베베드피노 오버롤</td>\n",
       "      <td>1</td>\n",
       "      <td>베이비 여아 화이트 블루머 5238234509001 - 24M</td>\n",
       "      <td>속옷/양말/홈웨어</td>\n",
       "      <td>유아동양말류</td>\n",
       "      <td>유아동타이즈</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>12</td>\n",
       "      <td>4551726</td>\n",
       "      <td>32</td>\n",
       "      <td>233182</td>\n",
       "      <td>색상:BLUE|사이즈:85 / 1개</td>\n",
       "      <td>베베드피노</td>\n",
       "      <td>39000</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Namyangju-si</td>\n",
       "      <td>뚜아후아 귀걸이</td>\n",
       "      <td>4</td>\n",
       "      <td>베이비 스트라이프 러플 바디수트BP8216222 - BLUE / 85</td>\n",
       "      <td>유아동의류</td>\n",
       "      <td>유아의류전신</td>\n",
       "      <td>영유아점프수트/오버롤</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>12</td>\n",
       "      <td>4130706</td>\n",
       "      <td>104</td>\n",
       "      <td>141349</td>\n",
       "      <td>모델명:01&gt;MS4388아이보리|사이즈:39 / 1개</td>\n",
       "      <td>클립</td>\n",
       "      <td>79000</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>2018-07-22</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Guri-si</td>\n",
       "      <td>코치</td>\n",
       "      <td>1</td>\n",
       "      <td>베스트샌들 MS4388 Malou_Color line Webbing 아이보리 외 1...</td>\n",
       "      <td>패션잡화</td>\n",
       "      <td>여성화</td>\n",
       "      <td>여성샌들</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>12</td>\n",
       "      <td>1776250</td>\n",
       "      <td>36</td>\n",
       "      <td>72185</td>\n",
       "      <td>색상:코랄|사이즈:S(6~12m) / 1개</td>\n",
       "      <td>해피프린스</td>\n",
       "      <td>4560</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Guri-si</td>\n",
       "      <td>해피프린스</td>\n",
       "      <td>4</td>\n",
       "      <td>나리앙 니삭스 - 코랄 / M(12~24m)</td>\n",
       "      <td>속옷/양말/홈웨어</td>\n",
       "      <td>유아동양말류</td>\n",
       "      <td>유아동일반양말</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>12</td>\n",
       "      <td>1011134</td>\n",
       "      <td>50</td>\n",
       "      <td>536257</td>\n",
       "      <td>색상:베이지|사이즈:S / 1개</td>\n",
       "      <td>해피프린스</td>\n",
       "      <td>990</td>\n",
       "      <td>1</td>\n",
       "      <td>345</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Namyangju-si</td>\n",
       "      <td>해피프린스 양말</td>\n",
       "      <td>1</td>\n",
       "      <td>폴리지 삭스 - 블루 / S</td>\n",
       "      <td>속옷/양말/홈웨어</td>\n",
       "      <td>유아동양말류</td>\n",
       "      <td>유아동일반양말</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>12</td>\n",
       "      <td>1011134</td>\n",
       "      <td>58</td>\n",
       "      <td>102618</td>\n",
       "      <td>1개</td>\n",
       "      <td>테팔</td>\n",
       "      <td>15900</td>\n",
       "      <td>1</td>\n",
       "      <td>345</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>Namyangju-si</td>\n",
       "      <td>해피프린스 양말</td>\n",
       "      <td>1</td>\n",
       "      <td>그래픽 패스포트 아이 러브 뉴욕 프라이팬 26cm</td>\n",
       "      <td>식기/조리기구</td>\n",
       "      <td>조리기구</td>\n",
       "      <td>프라이팬</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLNT_ID  SESS_ID  HITS_SEQ    PD_C                      PD_ADD_NM  \\\n",
       "48       12  4738380        47  178471                   사이즈:18M / 1개   \n",
       "44       12  4551726        32  233182            색상:BLUE|사이즈:85 / 1개   \n",
       "57       12  4130706       104  141349  모델명:01>MS4388아이보리|사이즈:39 / 1개   \n",
       "55       12  1776250        36   72185        색상:코랄|사이즈:S(6~12m) / 1개   \n",
       "60       12  1011134        50  536257              색상:베이지|사이즈:S / 1개   \n",
       "59       12  1011134        58  102618                             1개   \n",
       "\n",
       "   PD_BRA_NM  PD_BUY_AM  PD_BUY_CT  SESS_SEQ     SESS_DT  ...  DVC_CTG_NM  \\\n",
       "48      갭 키즈      10000          1       175  2018-07-12  ...      mobile   \n",
       "44     베베드피노      39000          1       189  2018-07-16  ...      mobile   \n",
       "57        클립      79000          1       219  2018-07-22  ...      mobile   \n",
       "55     해피프린스       4560          1       313  2018-09-01  ...      mobile   \n",
       "60     해피프린스        990          1       345  2018-09-13  ...      mobile   \n",
       "59        테팔      15900          1       345  2018-09-13  ...      mobile   \n",
       "\n",
       "         ZON_NM       CITY_NM     KWD_NM SEARCH_CNT  \\\n",
       "48        Seoul         Seoul  베베드피노 오버롤          1   \n",
       "44  Gyeonggi-do  Namyangju-si   뚜아후아 귀걸이          4   \n",
       "57  Gyeonggi-do       Guri-si         코치          1   \n",
       "55  Gyeonggi-do       Guri-si      해피프린스          4   \n",
       "60  Gyeonggi-do  Namyangju-si   해피프린스 양말          1   \n",
       "59  Gyeonggi-do  Namyangju-si   해피프린스 양말          1   \n",
       "\n",
       "                                                PD_NM   CLAC1_NM CLAC2_NM  \\\n",
       "48                 베이비 여아 화이트 블루머 5238234509001 - 24M  속옷/양말/홈웨어   유아동양말류   \n",
       "44             베이비 스트라이프 러플 바디수트BP8216222 - BLUE / 85      유아동의류   유아의류전신   \n",
       "57  베스트샌들 MS4388 Malou_Color line Webbing 아이보리 외 1...       패션잡화      여성화   \n",
       "55                           나리앙 니삭스 - 코랄 / M(12~24m)  속옷/양말/홈웨어   유아동양말류   \n",
       "60                                    폴리지 삭스 - 블루 / S  속옷/양말/홈웨어   유아동양말류   \n",
       "59                        그래픽 패스포트 아이 러브 뉴욕 프라이팬 26cm    식기/조리기구     조리기구   \n",
       "\n",
       "       CLAC3_NM LABEL  \n",
       "48       유아동타이즈   F30  \n",
       "44  영유아점프수트/오버롤   F30  \n",
       "57         여성샌들   F30  \n",
       "55      유아동일반양말   F30  \n",
       "60      유아동일반양말   F30  \n",
       "59         프라이팬   F30  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df[df['CLNT_ID'] == clnt_id[4]]\n",
    "temp_df = temp_df.sort_values(by=['SESS_DT', 'HITS_SEQ'])\n",
    "temp_df = temp_df[~temp_df.duplicated(subset=['SESS_ID', 'HITS_SEQ'], keep='last')]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fedc9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_shopping_interval(df):\n",
    "    mean_shopping_interval = 0\n",
    "    for i in range(len(df)-1):\n",
    "        mean_shopping_interval += (df['SESS_DT'].iloc[i+1] - df['SESS_DT'].iloc[i]).days\n",
    "    if len(df)-1 == 0:\n",
    "        mean_shopping_interval = 183\n",
    "    else:\n",
    "        mean_shopping_interval = mean_shopping_interval / (len(df)-1)\n",
    "    return mean_shopping_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "974f2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_total_price_ct(df):\n",
    "    price = 0\n",
    "    cnt = 0\n",
    "    for i in range(len(df)):\n",
    "        price += df['PD_BUY_AM'].iloc[i] * df['PD_BUY_CT'].iloc[i]\n",
    "        cnt += df['PD_BUY_CT'].iloc[i]\n",
    "    return price/cnt, price, cnt/len(df), cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe9a48",
   "metadata": {},
   "source": [
    "#### 피처 생성 루프 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fce2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 150000/150000 [15:52<00:00, 157.46it/s]\n"
     ]
    }
   ],
   "source": [
    "num_shoppings = []\n",
    "avg_prices = []\n",
    "total_prices = []\n",
    "avg_cts = []\n",
    "total_cts = []\n",
    "avg_sess_views = []\n",
    "total_sess_views = []\n",
    "avg_sess_hrs = []\n",
    "total_sess_hrs = []\n",
    "avg_shopping_intervals = []\n",
    "main_devices = []\n",
    "pd_cs = []\n",
    "clac1_nms = []\n",
    "clac2_nms = []\n",
    "clac3_nms = []\n",
    "\n",
    "for i in tqdm(range(len(clnt_id))):\n",
    "    temp_df = df[df['CLNT_ID'] == clnt_id[i]]\n",
    "    temp_df = temp_df.sort_values(by=['SESS_DT', 'HITS_SEQ', 'PD_C'])\n",
    "    temp_df = temp_df[~temp_df.duplicated(subset=['SESS_ID', 'HITS_SEQ', 'PD_C'], keep='last')]\n",
    "    \n",
    "    num_shopping = len(temp_df)\n",
    "    avg_price, total_price, avg_ct, total_ct = calc_avg_total_price_ct(temp_df)\n",
    "    avg_sess_view = temp_df['TOT_PAG_VIEW_CT'].values.mean()\n",
    "    total_sess_view = temp_df['TOT_PAG_VIEW_CT'].values.sum()\n",
    "    avg_sess_hr = temp_df['TOT_SESS_HR_V'].values.mean()\n",
    "    total_sess_hr = temp_df['TOT_SESS_HR_V'].values.sum()\n",
    "    avg_shopping_interval = calc_avg_shopping_interval(temp_df)\n",
    "    main_device = scipy.stats.mode(temp_df['DVC_CTG_NM'].values).mode[0]\n",
    "    pd_c = temp_df['PD_C'].values\n",
    "    clac1_nm = temp_df['CLAC1_NM'].values\n",
    "    clac2_nm = temp_df['CLAC2_NM'].values\n",
    "    clac3_nm = temp_df['CLAC3_NM'].values\n",
    "    \n",
    "    num_shoppings.append(num_shopping)\n",
    "    avg_prices.append(avg_price)\n",
    "    total_prices.append(total_price)\n",
    "    avg_cts.append(avg_ct)\n",
    "    total_cts.append(total_ct)\n",
    "    avg_sess_views.append(avg_sess_view)\n",
    "    total_sess_views.append(total_sess_view)\n",
    "    avg_sess_hrs.append(avg_sess_hr)\n",
    "    total_sess_hrs.append(total_sess_hr)\n",
    "    avg_shopping_intervals.append(avg_shopping_interval)\n",
    "    main_devices.append(main_device)\n",
    "    pd_cs.append(pd_c)\n",
    "    clac1_nms.append(clac1_nm)\n",
    "    clac2_nms.append(clac2_nm)\n",
    "    clac3_nms.append(clac3_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79ac787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([clnt_id, num_shoppings, avg_prices, total_prices, avg_cts, total_cts, avg_sess_views, \n",
    "                     total_sess_views, avg_sess_hrs, total_sess_hrs, avg_shopping_intervals, main_devices, \n",
    "                     pd_cs, clac1_nms, clac2_nms, clac3_nms, y['LABEL']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49696d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['clnt_id', 'num_shopping', 'avg_price', 'total_price', 'avg_ct', 'total_ct', 'avg_sess_view', \n",
    "                'total_sess_view', 'avg_sess_hr', 'total_sess_hr', 'avg_shopping_interval', 'main_device', \n",
    "                'pd_c', 'clac1_nm', 'clac2_nm', 'clac3_nm', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e87a4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>avg_shopping_interval</th>\n",
       "      <th>main_device</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>clac1_nm</th>\n",
       "      <th>clac2_nm</th>\n",
       "      <th>clac3_nm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43250</td>\n",
       "      <td>86500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>922</td>\n",
       "      <td>1844</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[578845, 788068]</td>\n",
       "      <td>[생활/주방가전, 침구/수예]</td>\n",
       "      <td>[주방가전, 수예소품]</td>\n",
       "      <td>[블랜더, 거실수예소품]</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>77777.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>132.333</td>\n",
       "      <td>1191</td>\n",
       "      <td>1311.11</td>\n",
       "      <td>11800</td>\n",
       "      <td>3.625</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[216947, 236174, 1965, 190233, 731145, 180447,...</td>\n",
       "      <td>[화장품/뷰티케어, 화장품/뷰티케어, 건강식품, 화장품/뷰티케어, 화장품/뷰티케어,...</td>\n",
       "      <td>[선케어, 스킨케어, 홍삼/인삼가공식품, 스킨케어, 스킨케어, 수영/물놀이, 메이크...</td>\n",
       "      <td>[선크림류, 에센스/세럼, 홍삼액, 에센스/세럼, 페이셜클렌저, 남성수영복, BB/...</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>24225</td>\n",
       "      <td>96900</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.75</td>\n",
       "      <td>87</td>\n",
       "      <td>297.25</td>\n",
       "      <td>1189</td>\n",
       "      <td>5.66667</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[554217, 248358, 506337, 506359]</td>\n",
       "      <td>[스포츠패션, 속옷/양말/홈웨어, 속옷/양말/홈웨어, 속옷/양말/홈웨어]</td>\n",
       "      <td>[여성스포츠화, 여성속옷, 여성속옷, 여성속옷]</td>\n",
       "      <td>[여성스포츠샌들/슬리퍼, 여성속옷세트, 여성팬티, 브래지어]</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10550</td>\n",
       "      <td>21100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>498</td>\n",
       "      <td>5049</td>\n",
       "      <td>10098</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[436275, 578537]</td>\n",
       "      <td>[속옷/양말/홈웨어, 속옷/양말/홈웨어]</td>\n",
       "      <td>[유아동속옷, 유아동속옷]</td>\n",
       "      <td>[유아동팬티, 유아동팬티]</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14325.6</td>\n",
       "      <td>229210</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>144.938</td>\n",
       "      <td>2319</td>\n",
       "      <td>4187.25</td>\n",
       "      <td>66996</td>\n",
       "      <td>4.2</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[178471, 233182, 141349, 64916, 72185, 489942,...</td>\n",
       "      <td>[속옷/양말/홈웨어, 유아동의류, 패션잡화, 패션잡화, 속옷/양말/홈웨어, 속옷/양...</td>\n",
       "      <td>[유아동양말류, 유아의류전신, 여성화, 모자, 유아동양말류, 유아동양말류, 모자, ...</td>\n",
       "      <td>[유아동타이즈, 영유아점프수트/오버롤, 여성샌들, 아동모, 유아동일반양말, 유아동일...</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>263094</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>183</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[536890]</td>\n",
       "      <td>[패션잡화]</td>\n",
       "      <td>[여성화]</td>\n",
       "      <td>[여성플랫]</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>263095</td>\n",
       "      <td>2</td>\n",
       "      <td>122000</td>\n",
       "      <td>244000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220.5</td>\n",
       "      <td>441</td>\n",
       "      <td>1828</td>\n",
       "      <td>3656</td>\n",
       "      <td>83</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[411059, 741695]</td>\n",
       "      <td>[유아동의류, 화장품/뷰티케어]</td>\n",
       "      <td>[여아의류아우터, 스킨케어]</td>\n",
       "      <td>[여아점퍼, 스킨케어세트]</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>263096</td>\n",
       "      <td>3</td>\n",
       "      <td>28500</td>\n",
       "      <td>85500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>4237</td>\n",
       "      <td>12711</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[406269, 592279, 592285]</td>\n",
       "      <td>[스포츠패션, 스포츠패션, 스포츠패션]</td>\n",
       "      <td>[여성스포츠화, 남성일반스포츠의류, 남성일반스포츠의류]</td>\n",
       "      <td>[여성런닝/트레이닝화, 남성일반스포츠바지, 남성일반스포츠바지]</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>263102</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>1812</td>\n",
       "      <td>1812</td>\n",
       "      <td>183</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[785281]</td>\n",
       "      <td>[문구/사무용품]</td>\n",
       "      <td>[필기도구]</td>\n",
       "      <td>[볼펜]</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>263103</td>\n",
       "      <td>7</td>\n",
       "      <td>58628.6</td>\n",
       "      <td>410400</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>280</td>\n",
       "      <td>1960</td>\n",
       "      <td>3249.43</td>\n",
       "      <td>22746</td>\n",
       "      <td>4.66667</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[381544, 576311, 171218, 144818, 307370, 30736...</td>\n",
       "      <td>[패션잡화, 식기/조리기구, 유아동의류, 시즌스포츠, 시즌스포츠, 시즌스포츠, 화장...</td>\n",
       "      <td>[유아동화, 그릇/식기, 여아의류상의, 수영/물놀이, 수영/물놀이, 수영/물놀이, ...</td>\n",
       "      <td>[유아동샌들, 커피잔, 여아티셔츠/탑, 아동수영복, 아동수영복, 아동수영복, 크림/...</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clnt_id num_shopping avg_price total_price avg_ct total_ct  \\\n",
       "0            0            2     43250       86500      1        2   \n",
       "1            1            9   77777.8      700000      1        9   \n",
       "2            6            4     24225       96900      1        4   \n",
       "3            9            2     10550       21100      1        2   \n",
       "4           12           16   14325.6      229210      1       16   \n",
       "...        ...          ...       ...         ...    ...      ...   \n",
       "149995  263094            1     10000       10000      1        1   \n",
       "149996  263095            2    122000      244000      1        2   \n",
       "149997  263096            3     28500       85500      1        3   \n",
       "149998  263102            1      1080        1080      1        1   \n",
       "149999  263103            7   58628.6      410400      1        7   \n",
       "\n",
       "       avg_sess_view total_sess_view avg_sess_hr total_sess_hr  \\\n",
       "0                 59             118         922          1844   \n",
       "1            132.333            1191     1311.11         11800   \n",
       "2              21.75              87      297.25          1189   \n",
       "3                249             498        5049         10098   \n",
       "4            144.938            2319     4187.25         66996   \n",
       "...              ...             ...         ...           ...   \n",
       "149995            66              66         513           513   \n",
       "149996         220.5             441        1828          3656   \n",
       "149997           256             768        4237         12711   \n",
       "149998           188             188        1812          1812   \n",
       "149999           280            1960     3249.43         22746   \n",
       "\n",
       "       avg_shopping_interval main_device  \\\n",
       "0                          0      mobile   \n",
       "1                      3.625      mobile   \n",
       "2                    5.66667      mobile   \n",
       "3                          0      mobile   \n",
       "4                        4.2      mobile   \n",
       "...                      ...         ...   \n",
       "149995                   183      mobile   \n",
       "149996                    83      mobile   \n",
       "149997                     0      mobile   \n",
       "149998                   183      mobile   \n",
       "149999               4.66667      mobile   \n",
       "\n",
       "                                                     pd_c  \\\n",
       "0                                        [578845, 788068]   \n",
       "1       [216947, 236174, 1965, 190233, 731145, 180447,...   \n",
       "2                        [554217, 248358, 506337, 506359]   \n",
       "3                                        [436275, 578537]   \n",
       "4       [178471, 233182, 141349, 64916, 72185, 489942,...   \n",
       "...                                                   ...   \n",
       "149995                                           [536890]   \n",
       "149996                                   [411059, 741695]   \n",
       "149997                           [406269, 592279, 592285]   \n",
       "149998                                           [785281]   \n",
       "149999  [381544, 576311, 171218, 144818, 307370, 30736...   \n",
       "\n",
       "                                                 clac1_nm  \\\n",
       "0                                        [생활/주방가전, 침구/수예]   \n",
       "1       [화장품/뷰티케어, 화장품/뷰티케어, 건강식품, 화장품/뷰티케어, 화장품/뷰티케어,...   \n",
       "2                [스포츠패션, 속옷/양말/홈웨어, 속옷/양말/홈웨어, 속옷/양말/홈웨어]   \n",
       "3                                  [속옷/양말/홈웨어, 속옷/양말/홈웨어]   \n",
       "4       [속옷/양말/홈웨어, 유아동의류, 패션잡화, 패션잡화, 속옷/양말/홈웨어, 속옷/양...   \n",
       "...                                                   ...   \n",
       "149995                                             [패션잡화]   \n",
       "149996                                  [유아동의류, 화장품/뷰티케어]   \n",
       "149997                              [스포츠패션, 스포츠패션, 스포츠패션]   \n",
       "149998                                          [문구/사무용품]   \n",
       "149999  [패션잡화, 식기/조리기구, 유아동의류, 시즌스포츠, 시즌스포츠, 시즌스포츠, 화장...   \n",
       "\n",
       "                                                 clac2_nm  \\\n",
       "0                                            [주방가전, 수예소품]   \n",
       "1       [선케어, 스킨케어, 홍삼/인삼가공식품, 스킨케어, 스킨케어, 수영/물놀이, 메이크...   \n",
       "2                              [여성스포츠화, 여성속옷, 여성속옷, 여성속옷]   \n",
       "3                                          [유아동속옷, 유아동속옷]   \n",
       "4       [유아동양말류, 유아의류전신, 여성화, 모자, 유아동양말류, 유아동양말류, 모자, ...   \n",
       "...                                                   ...   \n",
       "149995                                              [여성화]   \n",
       "149996                                    [여아의류아우터, 스킨케어]   \n",
       "149997                     [여성스포츠화, 남성일반스포츠의류, 남성일반스포츠의류]   \n",
       "149998                                             [필기도구]   \n",
       "149999  [유아동화, 그릇/식기, 여아의류상의, 수영/물놀이, 수영/물놀이, 수영/물놀이, ...   \n",
       "\n",
       "                                                 clac3_nm label  \n",
       "0                                           [블랜더, 거실수예소품]   F20  \n",
       "1       [선크림류, 에센스/세럼, 홍삼액, 에센스/세럼, 페이셜클렌저, 남성수영복, BB/...   F30  \n",
       "2                       [여성스포츠샌들/슬리퍼, 여성속옷세트, 여성팬티, 브래지어]   F20  \n",
       "3                                          [유아동팬티, 유아동팬티]   F30  \n",
       "4       [유아동타이즈, 영유아점프수트/오버롤, 여성샌들, 아동모, 유아동일반양말, 유아동일...   F30  \n",
       "...                                                   ...   ...  \n",
       "149995                                             [여성플랫]   F30  \n",
       "149996                                     [여아점퍼, 스킨케어세트]   F30  \n",
       "149997                 [여성런닝/트레이닝화, 남성일반스포츠바지, 남성일반스포츠바지]   F30  \n",
       "149998                                               [볼펜]   F30  \n",
       "149999  [유아동샌들, 커피잔, 여아티셔츠/탑, 아동수영복, 아동수영복, 아동수영복, 크림/...   F30  \n",
       "\n",
       "[150000 rows x 17 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea5ae8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_c_dic = {}\n",
    "for i, nm in enumerate(pd.concat([df, df_test], axis=0)['PD_C'].unique()):\n",
    "    pd_c_dic[nm] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d959d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{578845: 0,\n",
       " 788068: 1,\n",
       " 180447: 2,\n",
       " 731145: 3,\n",
       " 216947: 4,\n",
       " 491876: 5,\n",
       " 1965: 6,\n",
       " 457181: 7,\n",
       " 190233: 8,\n",
       " 236174: 9,\n",
       " 248358: 10,\n",
       " 506359: 11,\n",
       " 506337: 12,\n",
       " 554217: 13,\n",
       " 436275: 14,\n",
       " 578537: 15,\n",
       " 536257: 16,\n",
       " 141349: 17,\n",
       " 535684: 18,\n",
       " 75955: 19,\n",
       " 29069: 20,\n",
       " 41283: 21,\n",
       " 489942: 22,\n",
       " 760527: 23,\n",
       " 233182: 24,\n",
       " 178471: 25,\n",
       " 64916: 26,\n",
       " 535442: 27,\n",
       " 535601: 28,\n",
       " 64933: 29,\n",
       " 72185: 30,\n",
       " 102618: 31,\n",
       " 809170: 32,\n",
       " 837392: 33,\n",
       " 765673: 34,\n",
       " 660999: 35,\n",
       " 804: 36,\n",
       " 375713: 37,\n",
       " 133407: 38,\n",
       " 742158: 39,\n",
       " 742089: 40,\n",
       " 484590: 41,\n",
       " 641183: 42,\n",
       " 68947: 43,\n",
       " 842488: 44,\n",
       " 225207: 45,\n",
       " 682061: 46,\n",
       " 569802: 47,\n",
       " 832202: 48,\n",
       " 221420: 49,\n",
       " 826313: 50,\n",
       " 276275: 51,\n",
       " 140325: 52,\n",
       " 694453: 53,\n",
       " 811116: 54,\n",
       " 585440: 55,\n",
       " 700995: 56,\n",
       " 7893: 57,\n",
       " 733585: 58,\n",
       " 185099: 59,\n",
       " 722909: 60,\n",
       " 611777: 61,\n",
       " 425921: 62,\n",
       " 499940: 63,\n",
       " 549195: 64,\n",
       " 220714: 65,\n",
       " 218301: 66,\n",
       " 626454: 67,\n",
       " 473112: 68,\n",
       " 739681: 69,\n",
       " 746888: 70,\n",
       " 657620: 71,\n",
       " 478990: 72,\n",
       " 676622: 73,\n",
       " 685372: 74,\n",
       " 186166: 75,\n",
       " 455026: 76,\n",
       " 454153: 77,\n",
       " 839324: 78,\n",
       " 523581: 79,\n",
       " 397797: 80,\n",
       " 594883: 81,\n",
       " 836917: 82,\n",
       " 689380: 83,\n",
       " 714091: 84,\n",
       " 554220: 85,\n",
       " 255735: 86,\n",
       " 255805: 87,\n",
       " 841644: 88,\n",
       " 530357: 89,\n",
       " 550764: 90,\n",
       " 217166: 91,\n",
       " 207163: 92,\n",
       " 783266: 93,\n",
       " 733465: 94,\n",
       " 310728: 95,\n",
       " 841642: 96,\n",
       " 634905: 97,\n",
       " 111788: 98,\n",
       " 798665: 99,\n",
       " 740039: 100,\n",
       " 155106: 101,\n",
       " 793821: 102,\n",
       " 498418: 103,\n",
       " 265906: 104,\n",
       " 717107: 105,\n",
       " 789521: 106,\n",
       " 209960: 107,\n",
       " 369827: 108,\n",
       " 412912: 109,\n",
       " 352717: 110,\n",
       " 772781: 111,\n",
       " 664328: 112,\n",
       " 520714: 113,\n",
       " 448099: 114,\n",
       " 315356: 115,\n",
       " 621557: 116,\n",
       " 242314: 117,\n",
       " 577673: 118,\n",
       " 332489: 119,\n",
       " 221077: 120,\n",
       " 339653: 121,\n",
       " 360023: 122,\n",
       " 164956: 123,\n",
       " 217672: 124,\n",
       " 825162: 125,\n",
       " 210784: 126,\n",
       " 657088: 127,\n",
       " 807682: 128,\n",
       " 812803: 129,\n",
       " 782362: 130,\n",
       " 624221: 131,\n",
       " 750564: 132,\n",
       " 427373: 133,\n",
       " 159530: 134,\n",
       " 600643: 135,\n",
       " 659195: 136,\n",
       " 5609: 137,\n",
       " 809732: 138,\n",
       " 744190: 139,\n",
       " 314843: 140,\n",
       " 117061: 141,\n",
       " 72033: 142,\n",
       " 6353: 143,\n",
       " 500350: 144,\n",
       " 651086: 145,\n",
       " 777470: 146,\n",
       " 261331: 147,\n",
       " 406787: 148,\n",
       " 151256: 149,\n",
       " 323680: 150,\n",
       " 696708: 151,\n",
       " 818129: 152,\n",
       " 377510: 153,\n",
       " 736885: 154,\n",
       " 107273: 155,\n",
       " 274604: 156,\n",
       " 149519: 157,\n",
       " 119734: 158,\n",
       " 814520: 159,\n",
       " 418525: 160,\n",
       " 742656: 161,\n",
       " 176758: 162,\n",
       " 193137: 163,\n",
       " 448598: 164,\n",
       " 665779: 165,\n",
       " 222: 166,\n",
       " 812291: 167,\n",
       " 199507: 168,\n",
       " 595905: 169,\n",
       " 431974: 170,\n",
       " 480855: 171,\n",
       " 234515: 172,\n",
       " 417612: 173,\n",
       " 589529: 174,\n",
       " 635789: 175,\n",
       " 402421: 176,\n",
       " 21386: 177,\n",
       " 59919: 178,\n",
       " 59915: 179,\n",
       " 45864: 180,\n",
       " 42760: 181,\n",
       " 788073: 182,\n",
       " 24286: 183,\n",
       " 237980: 184,\n",
       " 279738: 185,\n",
       " 830988: 186,\n",
       " 831995: 187,\n",
       " 657509: 188,\n",
       " 599806: 189,\n",
       " 520208: 190,\n",
       " 678491: 191,\n",
       " 328975: 192,\n",
       " 225011: 193,\n",
       " 704761: 194,\n",
       " 331305: 195,\n",
       " 236745: 196,\n",
       " 331313: 197,\n",
       " 331315: 198,\n",
       " 325462: 199,\n",
       " 754008: 200,\n",
       " 525734: 201,\n",
       " 316297: 202,\n",
       " 234321: 203,\n",
       " 552345: 204,\n",
       " 809795: 205,\n",
       " 656134: 206,\n",
       " 482240: 207,\n",
       " 224538: 208,\n",
       " 190919: 209,\n",
       " 264638: 210,\n",
       " 705025: 211,\n",
       " 526416: 212,\n",
       " 488965: 213,\n",
       " 353082: 214,\n",
       " 484753: 215,\n",
       " 673029: 216,\n",
       " 668377: 217,\n",
       " 668381: 218,\n",
       " 203849: 219,\n",
       " 847487: 220,\n",
       " 624244: 221,\n",
       " 130018: 222,\n",
       " 391390: 223,\n",
       " 305827: 224,\n",
       " 439597: 225,\n",
       " 844427: 226,\n",
       " 742356: 227,\n",
       " 614387: 228,\n",
       " 347882: 229,\n",
       " 417009: 230,\n",
       " 703034: 231,\n",
       " 684955: 232,\n",
       " 833340: 233,\n",
       " 484185: 234,\n",
       " 384940: 235,\n",
       " 741257: 236,\n",
       " 524284: 237,\n",
       " 230466: 238,\n",
       " 425801: 239,\n",
       " 248687: 240,\n",
       " 465628: 241,\n",
       " 528909: 242,\n",
       " 843603: 243,\n",
       " 801330: 244,\n",
       " 188144: 245,\n",
       " 823839: 246,\n",
       " 672920: 247,\n",
       " 248047: 248,\n",
       " 838123: 249,\n",
       " 773995: 250,\n",
       " 464972: 251,\n",
       " 773992: 252,\n",
       " 846851: 253,\n",
       " 469740: 254,\n",
       " 580208: 255,\n",
       " 778734: 256,\n",
       " 667897: 257,\n",
       " 522054: 258,\n",
       " 742108: 259,\n",
       " 89333: 260,\n",
       " 40972: 261,\n",
       " 214597: 262,\n",
       " 835321: 263,\n",
       " 627769: 264,\n",
       " 771557: 265,\n",
       " 17101: 266,\n",
       " 17095: 267,\n",
       " 17100: 268,\n",
       " 179067: 269,\n",
       " 695935: 270,\n",
       " 836099: 271,\n",
       " 564962: 272,\n",
       " 432361: 273,\n",
       " 742269: 274,\n",
       " 497067: 275,\n",
       " 835143: 276,\n",
       " 590408: 277,\n",
       " 1967: 278,\n",
       " 1974: 279,\n",
       " 415723: 280,\n",
       " 789560: 281,\n",
       " 789582: 282,\n",
       " 273953: 283,\n",
       " 588278: 284,\n",
       " 218470: 285,\n",
       " 164930: 286,\n",
       " 539083: 287,\n",
       " 128079: 288,\n",
       " 182425: 289,\n",
       " 803165: 290,\n",
       " 804957: 291,\n",
       " 350387: 292,\n",
       " 590047: 293,\n",
       " 661770: 294,\n",
       " 337522: 295,\n",
       " 337517: 296,\n",
       " 350336: 297,\n",
       " 340910: 298,\n",
       " 98359: 299,\n",
       " 589994: 300,\n",
       " 215829: 301,\n",
       " 220490: 302,\n",
       " 199326: 303,\n",
       " 70943: 304,\n",
       " 783193: 305,\n",
       " 776237: 306,\n",
       " 481452: 307,\n",
       " 648696: 308,\n",
       " 308641: 309,\n",
       " 379286: 310,\n",
       " 548654: 311,\n",
       " 634550: 312,\n",
       " 298844: 313,\n",
       " 584080: 314,\n",
       " 525226: 315,\n",
       " 377512: 316,\n",
       " 132566: 317,\n",
       " 835090: 318,\n",
       " 345871: 319,\n",
       " 793807: 320,\n",
       " 214124: 321,\n",
       " 589276: 322,\n",
       " 786274: 323,\n",
       " 798040: 324,\n",
       " 840782: 325,\n",
       " 827708: 326,\n",
       " 556576: 327,\n",
       " 556736: 328,\n",
       " 556575: 329,\n",
       " 786573: 330,\n",
       " 839528: 331,\n",
       " 787263: 332,\n",
       " 774268: 333,\n",
       " 793173: 334,\n",
       " 787900: 335,\n",
       " 795003: 336,\n",
       " 240984: 337,\n",
       " 839518: 338,\n",
       " 787901: 339,\n",
       " 774271: 340,\n",
       " 511275: 341,\n",
       " 190234: 342,\n",
       " 732222: 343,\n",
       " 687109: 344,\n",
       " 715428: 345,\n",
       " 282505: 346,\n",
       " 484979: 347,\n",
       " 24736: 348,\n",
       " 75417: 349,\n",
       " 91765: 350,\n",
       " 220251: 351,\n",
       " 737516: 352,\n",
       " 419017: 353,\n",
       " 246686: 354,\n",
       " 365338: 355,\n",
       " 475039: 356,\n",
       " 146717: 357,\n",
       " 542723: 358,\n",
       " 70388: 359,\n",
       " 369894: 360,\n",
       " 710881: 361,\n",
       " 363761: 362,\n",
       " 540267: 363,\n",
       " 607801: 364,\n",
       " 339928: 365,\n",
       " 231953: 366,\n",
       " 433158: 367,\n",
       " 405531: 368,\n",
       " 9622: 369,\n",
       " 362816: 370,\n",
       " 346349: 371,\n",
       " 647567: 372,\n",
       " 820596: 373,\n",
       " 702687: 374,\n",
       " 765348: 375,\n",
       " 430918: 376,\n",
       " 384838: 377,\n",
       " 699485: 378,\n",
       " 700083: 379,\n",
       " 454775: 380,\n",
       " 694510: 381,\n",
       " 106165: 382,\n",
       " 835536: 383,\n",
       " 724248: 384,\n",
       " 477852: 385,\n",
       " 763182: 386,\n",
       " 427529: 387,\n",
       " 1555: 388,\n",
       " 3627: 389,\n",
       " 138127: 390,\n",
       " 499565: 391,\n",
       " 189112: 392,\n",
       " 55505: 393,\n",
       " 818150: 394,\n",
       " 402455: 395,\n",
       " 226541: 396,\n",
       " 499571: 397,\n",
       " 398276: 398,\n",
       " 751647: 399,\n",
       " 422559: 400,\n",
       " 62544: 401,\n",
       " 20778: 402,\n",
       " 80953: 403,\n",
       " 54442: 404,\n",
       " 616222: 405,\n",
       " 398777: 406,\n",
       " 166466: 407,\n",
       " 43168: 408,\n",
       " 164222: 409,\n",
       " 608512: 410,\n",
       " 692709: 411,\n",
       " 667520: 412,\n",
       " 528952: 413,\n",
       " 233088: 414,\n",
       " 685637: 415,\n",
       " 844451: 416,\n",
       " 325784: 417,\n",
       " 233093: 418,\n",
       " 586706: 419,\n",
       " 232364: 420,\n",
       " 808125: 421,\n",
       " 610038: 422,\n",
       " 231869: 423,\n",
       " 471376: 424,\n",
       " 116151: 425,\n",
       " 835793: 426,\n",
       " 224479: 427,\n",
       " 350816: 428,\n",
       " 467676: 429,\n",
       " 593242: 430,\n",
       " 92054: 431,\n",
       " 695295: 432,\n",
       " 106313: 433,\n",
       " 261184: 434,\n",
       " 457338: 435,\n",
       " 392975: 436,\n",
       " 187406: 437,\n",
       " 818235: 438,\n",
       " 788184: 439,\n",
       " 547987: 440,\n",
       " 90726: 441,\n",
       " 587688: 442,\n",
       " 813725: 443,\n",
       " 831581: 444,\n",
       " 119440: 445,\n",
       " 82412: 446,\n",
       " 467056: 447,\n",
       " 801428: 448,\n",
       " 737381: 449,\n",
       " 153479: 450,\n",
       " 542721: 451,\n",
       " 237334: 452,\n",
       " 723410: 453,\n",
       " 732165: 454,\n",
       " 654287: 455,\n",
       " 817724: 456,\n",
       " 606643: 457,\n",
       " 461583: 458,\n",
       " 337679: 459,\n",
       " 178427: 460,\n",
       " 183546: 461,\n",
       " 301060: 462,\n",
       " 179311: 463,\n",
       " 564444: 464,\n",
       " 369907: 465,\n",
       " 704429: 466,\n",
       " 466095: 467,\n",
       " 576935: 468,\n",
       " 648484: 469,\n",
       " 26786: 470,\n",
       " 26781: 471,\n",
       " 170172: 472,\n",
       " 783315: 473,\n",
       " 325027: 474,\n",
       " 427578: 475,\n",
       " 92959: 476,\n",
       " 39798: 477,\n",
       " 10617: 478,\n",
       " 22503: 479,\n",
       " 746106: 480,\n",
       " 448458: 481,\n",
       " 662207: 482,\n",
       " 338225: 483,\n",
       " 358308: 484,\n",
       " 339641: 485,\n",
       " 686956: 486,\n",
       " 746637: 487,\n",
       " 274520: 488,\n",
       " 396880: 489,\n",
       " 805342: 490,\n",
       " 721493: 491,\n",
       " 621954: 492,\n",
       " 743591: 493,\n",
       " 163986: 494,\n",
       " 771158: 495,\n",
       " 685591: 496,\n",
       " 805287: 497,\n",
       " 795994: 498,\n",
       " 219950: 499,\n",
       " 613327: 500,\n",
       " 143001: 501,\n",
       " 221502: 502,\n",
       " 686598: 503,\n",
       " 77784: 504,\n",
       " 70824: 505,\n",
       " 44083: 506,\n",
       " 62448: 507,\n",
       " 831368: 508,\n",
       " 571977: 509,\n",
       " 346353: 510,\n",
       " 427398: 511,\n",
       " 239291: 512,\n",
       " 802617: 513,\n",
       " 1991: 514,\n",
       " 319558: 515,\n",
       " 470374: 516,\n",
       " 802533: 517,\n",
       " 355423: 518,\n",
       " 612430: 519,\n",
       " 285225: 520,\n",
       " 612192: 521,\n",
       " 101236: 522,\n",
       " 285226: 523,\n",
       " 514632: 524,\n",
       " 225375: 525,\n",
       " 397026: 526,\n",
       " 451206: 527,\n",
       " 361266: 528,\n",
       " 180640: 529,\n",
       " 796170: 530,\n",
       " 448112: 531,\n",
       " 707723: 532,\n",
       " 463914: 533,\n",
       " 318514: 534,\n",
       " 678593: 535,\n",
       " 721593: 536,\n",
       " 134109: 537,\n",
       " 782256: 538,\n",
       " 807086: 539,\n",
       " 484066: 540,\n",
       " 484021: 541,\n",
       " 278269: 542,\n",
       " 730248: 543,\n",
       " 549163: 544,\n",
       " 228969: 545,\n",
       " 290962: 546,\n",
       " 451855: 547,\n",
       " 579504: 548,\n",
       " 813584: 549,\n",
       " 531745: 550,\n",
       " 84088: 551,\n",
       " 538938: 552,\n",
       " 673948: 553,\n",
       " 339654: 554,\n",
       " 637249: 555,\n",
       " 236205: 556,\n",
       " 565534: 557,\n",
       " 751437: 558,\n",
       " 462370: 559,\n",
       " 524623: 560,\n",
       " 131621: 561,\n",
       " 166295: 562,\n",
       " 146757: 563,\n",
       " 37591: 564,\n",
       " 37589: 565,\n",
       " 228819: 566,\n",
       " 157438: 567,\n",
       " 737833: 568,\n",
       " 331291: 569,\n",
       " 845920: 570,\n",
       " 766109: 571,\n",
       " 847340: 572,\n",
       " 95376: 573,\n",
       " 283474: 574,\n",
       " 484910: 575,\n",
       " 464142: 576,\n",
       " 484914: 577,\n",
       " 21527: 578,\n",
       " 139318: 579,\n",
       " 68262: 580,\n",
       " 744813: 581,\n",
       " 304719: 582,\n",
       " 455203: 583,\n",
       " 382491: 584,\n",
       " 462218: 585,\n",
       " 812355: 586,\n",
       " 602936: 587,\n",
       " 177621: 588,\n",
       " 633165: 589,\n",
       " 737465: 590,\n",
       " 439241: 591,\n",
       " 638834: 592,\n",
       " 745992: 593,\n",
       " 100581: 594,\n",
       " 600886: 595,\n",
       " 295538: 596,\n",
       " 737019: 597,\n",
       " 649639: 598,\n",
       " 433922: 599,\n",
       " 348994: 600,\n",
       " 325866: 601,\n",
       " 503810: 602,\n",
       " 168943: 603,\n",
       " 793984: 604,\n",
       " 288716: 605,\n",
       " 398993: 606,\n",
       " 602742: 607,\n",
       " 185590: 608,\n",
       " 737456: 609,\n",
       " 185451: 610,\n",
       " 179794: 611,\n",
       " 633205: 612,\n",
       " 507445: 613,\n",
       " 737108: 614,\n",
       " 492100: 615,\n",
       " 489573: 616,\n",
       " 426460: 617,\n",
       " 643719: 618,\n",
       " 381421: 619,\n",
       " 498898: 620,\n",
       " 86035: 621,\n",
       " 8044: 622,\n",
       " 584546: 623,\n",
       " 737770: 624,\n",
       " 457825: 625,\n",
       " 514057: 626,\n",
       " 351544: 627,\n",
       " 189859: 628,\n",
       " 737744: 629,\n",
       " 757621: 630,\n",
       " 812389: 631,\n",
       " 731144: 632,\n",
       " 737753: 633,\n",
       " 807229: 634,\n",
       " 296651: 635,\n",
       " 273453: 636,\n",
       " 588188: 637,\n",
       " 248898: 638,\n",
       " 813189: 639,\n",
       " 838160: 640,\n",
       " 373139: 641,\n",
       " 423749: 642,\n",
       " 775255: 643,\n",
       " 802474: 644,\n",
       " 2574: 645,\n",
       " 701460: 646,\n",
       " 731231: 647,\n",
       " 385727: 648,\n",
       " 405952: 649,\n",
       " 358419: 650,\n",
       " 516983: 651,\n",
       " 666218: 652,\n",
       " 396146: 653,\n",
       " 333489: 654,\n",
       " 462824: 655,\n",
       " 286237: 656,\n",
       " 587449: 657,\n",
       " 803232: 658,\n",
       " 143555: 659,\n",
       " 263449: 660,\n",
       " 141498: 661,\n",
       " 741797: 662,\n",
       " 175170: 663,\n",
       " 742014: 664,\n",
       " 156769: 665,\n",
       " 1959: 666,\n",
       " 130354: 667,\n",
       " 818172: 668,\n",
       " 818170: 669,\n",
       " 333607: 670,\n",
       " 826962: 671,\n",
       " 737200: 672,\n",
       " 125314: 673,\n",
       " 405643: 674,\n",
       " 363078: 675,\n",
       " 222557: 676,\n",
       " 675999: 677,\n",
       " 680819: 678,\n",
       " 8781: 679,\n",
       " 701610: 680,\n",
       " 496043: 681,\n",
       " 421603: 682,\n",
       " 197538: 683,\n",
       " 332857: 684,\n",
       " 574687: 685,\n",
       " 574728: 686,\n",
       " 347557: 687,\n",
       " 196508: 688,\n",
       " 303129: 689,\n",
       " 127472: 690,\n",
       " 563385: 691,\n",
       " 771558: 692,\n",
       " 349862: 693,\n",
       " 710755: 694,\n",
       " 27493: 695,\n",
       " 134810: 696,\n",
       " 59137: 697,\n",
       " 742702: 698,\n",
       " 482531: 699,\n",
       " 339054: 700,\n",
       " 142758: 701,\n",
       " 668157: 702,\n",
       " 699665: 703,\n",
       " 518765: 704,\n",
       " 7010: 705,\n",
       " 792983: 706,\n",
       " 637455: 707,\n",
       " 812091: 708,\n",
       " 736142: 709,\n",
       " 5671: 710,\n",
       " 763472: 711,\n",
       " 791368: 712,\n",
       " 719827: 713,\n",
       " 800276: 714,\n",
       " 156818: 715,\n",
       " 156821: 716,\n",
       " 678668: 717,\n",
       " 334785: 718,\n",
       " 62002: 719,\n",
       " 379743: 720,\n",
       " 63194: 721,\n",
       " 279649: 722,\n",
       " 174418: 723,\n",
       " 799721: 724,\n",
       " 673660: 725,\n",
       " 158936: 726,\n",
       " 147650: 727,\n",
       " 550249: 728,\n",
       " 523074: 729,\n",
       " 732025: 730,\n",
       " 268104: 731,\n",
       " 653293: 732,\n",
       " 255244: 733,\n",
       " 232737: 734,\n",
       " 689564: 735,\n",
       " 343289: 736,\n",
       " 64438: 737,\n",
       " 496201: 738,\n",
       " 295663: 739,\n",
       " 729276: 740,\n",
       " 449614: 741,\n",
       " 810725: 742,\n",
       " 681618: 743,\n",
       " 513766: 744,\n",
       " 688070: 745,\n",
       " 470469: 746,\n",
       " 824246: 747,\n",
       " 98085: 748,\n",
       " 674014: 749,\n",
       " 352123: 750,\n",
       " 467361: 751,\n",
       " 290426: 752,\n",
       " 77621: 753,\n",
       " 8143: 754,\n",
       " 357620: 755,\n",
       " 671211: 756,\n",
       " 807545: 757,\n",
       " 104938: 758,\n",
       " 446901: 759,\n",
       " 462910: 760,\n",
       " 450004: 761,\n",
       " 456907: 762,\n",
       " 539982: 763,\n",
       " 594892: 764,\n",
       " 684241: 765,\n",
       " 705211: 766,\n",
       " 547370: 767,\n",
       " 38078: 768,\n",
       " 661752: 769,\n",
       " 18096: 770,\n",
       " 34901: 771,\n",
       " 243436: 772,\n",
       " 666769: 773,\n",
       " 106113: 774,\n",
       " 337126: 775,\n",
       " 132486: 776,\n",
       " 221243: 777,\n",
       " 150551: 778,\n",
       " 109616: 779,\n",
       " 669572: 780,\n",
       " 411683: 781,\n",
       " 274759: 782,\n",
       " 302954: 783,\n",
       " 591447: 784,\n",
       " 46814: 785,\n",
       " 83872: 786,\n",
       " 224211: 787,\n",
       " 492664: 788,\n",
       " 679395: 789,\n",
       " 73461: 790,\n",
       " 706836: 791,\n",
       " 125551: 792,\n",
       " 601039: 793,\n",
       " 600923: 794,\n",
       " 134168: 795,\n",
       " 456811: 796,\n",
       " 366070: 797,\n",
       " 335108: 798,\n",
       " 226114: 799,\n",
       " 846665: 800,\n",
       " 91249: 801,\n",
       " 340190: 802,\n",
       " 780899: 803,\n",
       " 489294: 804,\n",
       " 489616: 805,\n",
       " 780898: 806,\n",
       " 31803: 807,\n",
       " 32543: 808,\n",
       " 32539: 809,\n",
       " 32546: 810,\n",
       " 305699: 811,\n",
       " 155435: 812,\n",
       " 787614: 813,\n",
       " 31880: 814,\n",
       " 604488: 815,\n",
       " 43292: 816,\n",
       " 140109: 817,\n",
       " 31871: 818,\n",
       " 450598: 819,\n",
       " 791897: 820,\n",
       " 784275: 821,\n",
       " 32541: 822,\n",
       " 95079: 823,\n",
       " 14957: 824,\n",
       " 747812: 825,\n",
       " 23085: 826,\n",
       " 699048: 827,\n",
       " 405748: 828,\n",
       " 847121: 829,\n",
       " 440300: 830,\n",
       " 183258: 831,\n",
       " 810085: 832,\n",
       " 394172: 833,\n",
       " 27852: 834,\n",
       " 447552: 835,\n",
       " 133610: 836,\n",
       " 810083: 837,\n",
       " 23082: 838,\n",
       " 191422: 839,\n",
       " 191427: 840,\n",
       " 191424: 841,\n",
       " 212054: 842,\n",
       " 154999: 843,\n",
       " 222951: 844,\n",
       " 101612: 845,\n",
       " 638673: 846,\n",
       " 578512: 847,\n",
       " 643030: 848,\n",
       " 259725: 849,\n",
       " 679889: 850,\n",
       " 108585: 851,\n",
       " 115889: 852,\n",
       " 113999: 853,\n",
       " 95077: 854,\n",
       " 825163: 855,\n",
       " 625310: 856,\n",
       " 352237: 857,\n",
       " 525279: 858,\n",
       " 58764: 859,\n",
       " 50185: 860,\n",
       " 428396: 861,\n",
       " 631492: 862,\n",
       " 814295: 863,\n",
       " 747182: 864,\n",
       " 343507: 865,\n",
       " 735510: 866,\n",
       " 561804: 867,\n",
       " 343675: 868,\n",
       " 527221: 869,\n",
       " 365009: 870,\n",
       " 727523: 871,\n",
       " 255857: 872,\n",
       " 354836: 873,\n",
       " 83748: 874,\n",
       " 359218: 875,\n",
       " 295051: 876,\n",
       " 465400: 877,\n",
       " 317252: 878,\n",
       " 338161: 879,\n",
       " 349436: 880,\n",
       " 120008: 881,\n",
       " 155128: 882,\n",
       " 111253: 883,\n",
       " 128018: 884,\n",
       " 149651: 885,\n",
       " 391579: 886,\n",
       " 85339: 887,\n",
       " 2310: 888,\n",
       " 178122: 889,\n",
       " 67884: 890,\n",
       " 615582: 891,\n",
       " 726154: 892,\n",
       " 719174: 893,\n",
       " 733764: 894,\n",
       " 134830: 895,\n",
       " 463058: 896,\n",
       " 463062: 897,\n",
       " 655621: 898,\n",
       " 750374: 899,\n",
       " 260824: 900,\n",
       " 125584: 901,\n",
       " 469647: 902,\n",
       " 444736: 903,\n",
       " 53376: 904,\n",
       " 724836: 905,\n",
       " 432644: 906,\n",
       " 128837: 907,\n",
       " 535774: 908,\n",
       " 286948: 909,\n",
       " 570870: 910,\n",
       " 201175: 911,\n",
       " 352958: 912,\n",
       " 128829: 913,\n",
       " 785097: 914,\n",
       " 7514: 915,\n",
       " 835836: 916,\n",
       " 8460: 917,\n",
       " 801491: 918,\n",
       " 754998: 919,\n",
       " 390491: 920,\n",
       " 716500: 921,\n",
       " 605825: 922,\n",
       " 574707: 923,\n",
       " 742651: 924,\n",
       " 530833: 925,\n",
       " 737665: 926,\n",
       " 481765: 927,\n",
       " 742654: 928,\n",
       " 671328: 929,\n",
       " 201595: 930,\n",
       " 722733: 931,\n",
       " 642112: 932,\n",
       " 647750: 933,\n",
       " 742311: 934,\n",
       " 742625: 935,\n",
       " 737808: 936,\n",
       " 190230: 937,\n",
       " 112365: 938,\n",
       " 195072: 939,\n",
       " 195071: 940,\n",
       " 689788: 941,\n",
       " 334695: 942,\n",
       " 167536: 943,\n",
       " 671828: 944,\n",
       " 563784: 945,\n",
       " 27708: 946,\n",
       " 350247: 947,\n",
       " 72324: 948,\n",
       " 72394: 949,\n",
       " 840047: 950,\n",
       " 33795: 951,\n",
       " 2376: 952,\n",
       " 772365: 953,\n",
       " 802906: 954,\n",
       " 19558: 955,\n",
       " 253332: 956,\n",
       " 547977: 957,\n",
       " 742747: 958,\n",
       " 677214: 959,\n",
       " 840541: 960,\n",
       " 826939: 961,\n",
       " 346356: 962,\n",
       " 320963: 963,\n",
       " 690246: 964,\n",
       " 567651: 965,\n",
       " 514547: 966,\n",
       " 193356: 967,\n",
       " 377673: 968,\n",
       " 526080: 969,\n",
       " 350581: 970,\n",
       " 536810: 971,\n",
       " 709293: 972,\n",
       " 710074: 973,\n",
       " 326193: 974,\n",
       " 677217: 975,\n",
       " 730706: 976,\n",
       " 654997: 977,\n",
       " 763454: 978,\n",
       " 313387: 979,\n",
       " 5197: 980,\n",
       " 812280: 981,\n",
       " 118621: 982,\n",
       " 835: 983,\n",
       " 538088: 984,\n",
       " 48019: 985,\n",
       " 677215: 986,\n",
       " 212710: 987,\n",
       " 203160: 988,\n",
       " 481045: 989,\n",
       " 458353: 990,\n",
       " 632139: 991,\n",
       " 295137: 992,\n",
       " 844453: 993,\n",
       " 302856: 994,\n",
       " 244483: 995,\n",
       " 538085: 996,\n",
       " 9991: 997,\n",
       " 465895: 998,\n",
       " 599577: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_c_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45612ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pd_c'] = data['pd_c'].map(lambda x: [pd_c_dic[nm] for nm in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187085f7",
   "metadata": {},
   "source": [
    "- 클라이언트 별 각 대 중 소 분류 검색 누적 숫자 => matrix 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d8d9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_nm_dic = {}\n",
    "for i, nm in enumerate(df['CLAC1_NM'].unique()):\n",
    "    clac1_nm_dic[nm] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7927b003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'생활/주방가전': 0,\n",
       " '침구/수예': 1,\n",
       " '시즌스포츠': 2,\n",
       " '화장품/뷰티케어': 3,\n",
       " '건강식품': 4,\n",
       " '속옷/양말/홈웨어': 5,\n",
       " '스포츠패션': 6,\n",
       " '패션잡화': 7,\n",
       " '주방잡화': 8,\n",
       " '유아동의류': 9,\n",
       " '식기/조리기구': 10,\n",
       " '세제/위생': 11,\n",
       " '청소/세탁/욕실용품': 12,\n",
       " '출산/육아용품': 13,\n",
       " '냉장/세탁가전': 14,\n",
       " '퍼스널케어': 15,\n",
       " '구기/필드스포츠': 16,\n",
       " '원예/애완': 17,\n",
       " '음료': 18,\n",
       " '여성의류': 19,\n",
       " '남성의류': 20,\n",
       " '계절가전': 21,\n",
       " '냉장식품': 22,\n",
       " '아웃도어/레저': 23,\n",
       " '냉동식품': 24,\n",
       " '가구': 25,\n",
       " '완구': 26,\n",
       " '헬스/피트니스': 27,\n",
       " '축산물': 28,\n",
       " '컴퓨터': 29,\n",
       " '모바일': 30,\n",
       " '문구/사무용품': 31,\n",
       " '인테리어/조명': 32,\n",
       " '상품권': 33,\n",
       " '과일': 34,\n",
       " '자동차용품': 35,\n",
       " '영상/음향가전': 36}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac1_nm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f11c974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clac1_nm'] = data['clac1_nm'].map(lambda x: [clac1_nm_dic[nm] for nm in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44e1bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_matrix = np.zeros((len(data), len(clac1_nm_dic)))\n",
    "for i in range(len(data)):\n",
    "    for j in data['clac1_nm'][i]:\n",
    "        clac1_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdffe91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 2., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 3., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac1_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "821f522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac1_nm_' + str(i) for i in range(len(clac1_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35ada5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_df = pd.DataFrame(clac1_matrix)\n",
    "clac1_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0015532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clac1_nm_0</th>\n",
       "      <th>clac1_nm_1</th>\n",
       "      <th>clac1_nm_2</th>\n",
       "      <th>clac1_nm_3</th>\n",
       "      <th>clac1_nm_4</th>\n",
       "      <th>clac1_nm_5</th>\n",
       "      <th>clac1_nm_6</th>\n",
       "      <th>clac1_nm_7</th>\n",
       "      <th>clac1_nm_8</th>\n",
       "      <th>clac1_nm_9</th>\n",
       "      <th>...</th>\n",
       "      <th>clac1_nm_27</th>\n",
       "      <th>clac1_nm_28</th>\n",
       "      <th>clac1_nm_29</th>\n",
       "      <th>clac1_nm_30</th>\n",
       "      <th>clac1_nm_31</th>\n",
       "      <th>clac1_nm_32</th>\n",
       "      <th>clac1_nm_33</th>\n",
       "      <th>clac1_nm_34</th>\n",
       "      <th>clac1_nm_35</th>\n",
       "      <th>clac1_nm_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clac1_nm_0  clac1_nm_1  clac1_nm_2  clac1_nm_3  clac1_nm_4  \\\n",
       "0              1.0         1.0         0.0         0.0         0.0   \n",
       "1              0.0         0.0         2.0         6.0         1.0   \n",
       "2              0.0         0.0         0.0         0.0         0.0   \n",
       "3              0.0         0.0         0.0         0.0         0.0   \n",
       "4              0.0         0.0         0.0         0.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "149995         0.0         0.0         0.0         0.0         0.0   \n",
       "149996         0.0         0.0         0.0         1.0         0.0   \n",
       "149997         0.0         0.0         0.0         0.0         0.0   \n",
       "149998         0.0         0.0         0.0         0.0         0.0   \n",
       "149999         0.0         0.0         3.0         1.0         0.0   \n",
       "\n",
       "        clac1_nm_5  clac1_nm_6  clac1_nm_7  clac1_nm_8  clac1_nm_9  ...  \\\n",
       "0              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "2              3.0         1.0         0.0         0.0         0.0  ...   \n",
       "3              2.0         0.0         0.0         0.0         0.0  ...   \n",
       "4             10.0         0.0         3.0         1.0         1.0  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "149995         0.0         0.0         1.0         0.0         0.0  ...   \n",
       "149996         0.0         0.0         0.0         0.0         1.0  ...   \n",
       "149997         0.0         3.0         0.0         0.0         0.0  ...   \n",
       "149998         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149999         0.0         0.0         1.0         0.0         1.0  ...   \n",
       "\n",
       "        clac1_nm_27  clac1_nm_28  clac1_nm_29  clac1_nm_30  clac1_nm_31  \\\n",
       "0               0.0          0.0          0.0          0.0          0.0   \n",
       "1               0.0          0.0          0.0          0.0          0.0   \n",
       "2               0.0          0.0          0.0          0.0          0.0   \n",
       "3               0.0          0.0          0.0          0.0          0.0   \n",
       "4               0.0          0.0          0.0          0.0          0.0   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "149995          0.0          0.0          0.0          0.0          0.0   \n",
       "149996          0.0          0.0          0.0          0.0          0.0   \n",
       "149997          0.0          0.0          0.0          0.0          0.0   \n",
       "149998          0.0          0.0          0.0          0.0          1.0   \n",
       "149999          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "        clac1_nm_32  clac1_nm_33  clac1_nm_34  clac1_nm_35  clac1_nm_36  \n",
       "0               0.0          0.0          0.0          0.0          0.0  \n",
       "1               0.0          0.0          0.0          0.0          0.0  \n",
       "2               0.0          0.0          0.0          0.0          0.0  \n",
       "3               0.0          0.0          0.0          0.0          0.0  \n",
       "4               0.0          0.0          0.0          0.0          0.0  \n",
       "...             ...          ...          ...          ...          ...  \n",
       "149995          0.0          0.0          0.0          0.0          0.0  \n",
       "149996          0.0          0.0          0.0          0.0          0.0  \n",
       "149997          0.0          0.0          0.0          0.0          0.0  \n",
       "149998          0.0          0.0          0.0          0.0          0.0  \n",
       "149999          0.0          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[150000 rows x 37 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef700454",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_nm_dic = {}\n",
    "for i, nm in enumerate(df['CLAC2_NM'].unique()):\n",
    "    clac2_nm_dic[nm] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2765a70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'주방가전': 0,\n",
       " '수예소품': 1,\n",
       " '수영/물놀이': 2,\n",
       " '스킨케어': 3,\n",
       " '선케어': 4,\n",
       " '홍삼/인삼가공식품': 5,\n",
       " '메이크업': 6,\n",
       " '여성속옷': 7,\n",
       " '여성스포츠화': 8,\n",
       " '유아동속옷': 9,\n",
       " '유아동양말류': 10,\n",
       " '여성화': 11,\n",
       " '조리도구': 12,\n",
       " '유아의류전신': 13,\n",
       " '모자': 14,\n",
       " '조리기구': 15,\n",
       " '화장지/티슈': 16,\n",
       " '정리용품': 17,\n",
       " '유아스킨/바디케어': 18,\n",
       " '냉장/냉동고': 19,\n",
       " '핸드/풋케어': 20,\n",
       " '남성일반스포츠의류': 21,\n",
       " '골프': 22,\n",
       " '남성지갑': 23,\n",
       " '남성스포츠화': 24,\n",
       " '애견용품': 25,\n",
       " '생수': 26,\n",
       " '여성일반스포츠의류': 27,\n",
       " '건강진액': 28,\n",
       " '남성케어': 29,\n",
       " '우산/양산류': 30,\n",
       " '스포츠잡화': 31,\n",
       " '남성속옷': 32,\n",
       " '여성의류상의': 33,\n",
       " '여성의류전신': 34,\n",
       " '유아동침구': 35,\n",
       " '남성의류상의': 36,\n",
       " '남성의류하의': 37,\n",
       " '여성의류아우터': 38,\n",
       " '냉방가전': 39,\n",
       " '유아의류상의': 40,\n",
       " '여아의류상의': 41,\n",
       " '여성위생용품': 42,\n",
       " '유아위생용품': 43,\n",
       " '영양제': 44,\n",
       " '포장반찬': 45,\n",
       " '남성등산/아웃도어의류': 46,\n",
       " '유아동스포츠화': 47,\n",
       " '헤어케어': 48,\n",
       " '캠핑': 49,\n",
       " '등산': 50,\n",
       " '여성가방': 51,\n",
       " '유아의류하의': 52,\n",
       " '고양이용품': 53,\n",
       " '구강케어': 54,\n",
       " '남성의류아우터': 55,\n",
       " '냉동간편식': 56,\n",
       " '수납가구': 57,\n",
       " '사무용/학생용가구': 58,\n",
       " '수유/이유용품': 59,\n",
       " '유아발육용품': 60,\n",
       " '유아동화': 61,\n",
       " '여성의류하의': 62,\n",
       " '교육완구': 63,\n",
       " '피트니스': 64,\n",
       " '그릇/식기': 65,\n",
       " '남성골프의류': 66,\n",
       " '여성골프의류': 67,\n",
       " '거실가구': 68,\n",
       " '닭고기류': 69,\n",
       " '남아의류상의': 70,\n",
       " '홈웨어': 71,\n",
       " '주방가구': 72,\n",
       " '밀폐/보관용기': 73,\n",
       " '시계': 74,\n",
       " '바디케어': 75,\n",
       " '여행용가방류': 76,\n",
       " '기능성음료': 77,\n",
       " '캐쥬얼가방': 78,\n",
       " '컴퓨터/노트북': 79,\n",
       " '침실가구': 80,\n",
       " '모바일액세서리': 81,\n",
       " '성인침구': 82,\n",
       " '일반문구/사무용품': 83,\n",
       " '필기도구': 84,\n",
       " '안경/선글라스': 85,\n",
       " '여아의류하의': 86,\n",
       " '남아의류하의': 87,\n",
       " '커튼/블라인드류': 88,\n",
       " '여성지갑': 89,\n",
       " '욕실용품': 90,\n",
       " '남아완구': 91,\n",
       " '세탁세제': 92,\n",
       " '여성등산/아웃도어의류': 93,\n",
       " '패션액세서리': 94,\n",
       " '컴퓨터주변기기': 95,\n",
       " '남아의류세트': 96,\n",
       " '청소기': 97,\n",
       " '여성양말류': 98,\n",
       " '미용소품': 99,\n",
       " '여아완구': 100,\n",
       " '유아안전용품': 101,\n",
       " '모바일상품권': 102,\n",
       " '남성화': 103,\n",
       " '이미용가전': 104,\n",
       " '향수': 105,\n",
       " '주방정리용품/소모품': 106,\n",
       " '보석': 107,\n",
       " '남성가방': 108,\n",
       " '남성양말류': 109,\n",
       " '공기청정/가습/제습': 110,\n",
       " '여아의류아우터': 111,\n",
       " '건강보조식품': 112,\n",
       " '유아동가구': 113,\n",
       " '인라인/스케이트보드/킥보드': 114,\n",
       " '두유': 115,\n",
       " '견과류': 116,\n",
       " '자동차음향/가전기기': 117,\n",
       " '유아동일반스포츠의류': 118,\n",
       " '국산과일': 119,\n",
       " '세탁기': 120,\n",
       " '모바일기기': 121,\n",
       " '유아의류아우터': 122,\n",
       " '남성의류세트': 123,\n",
       " '카메라/캠코더': 124,\n",
       " 'TV': 125,\n",
       " '축산선물세트': 126,\n",
       " '시공/DIY가구': 127}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac2_nm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb9c54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clac2_nm'] = data['clac2_nm'].map(lambda x: [clac2_nm_dic[nm] for nm in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82d60cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_matrix = np.zeros((len(data), len(clac2_nm_dic)))\n",
    "for i in range(len(data)):\n",
    "    for j in data['clac2_nm'][i]:\n",
    "        clac2_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7774fc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 2., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 3., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac2_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2378f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac2_nm_' + str(i) for i in range(len(clac2_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f3cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_df = pd.DataFrame(clac2_matrix)\n",
    "clac2_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb1662aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clac2_nm_0</th>\n",
       "      <th>clac2_nm_1</th>\n",
       "      <th>clac2_nm_2</th>\n",
       "      <th>clac2_nm_3</th>\n",
       "      <th>clac2_nm_4</th>\n",
       "      <th>clac2_nm_5</th>\n",
       "      <th>clac2_nm_6</th>\n",
       "      <th>clac2_nm_7</th>\n",
       "      <th>clac2_nm_8</th>\n",
       "      <th>clac2_nm_9</th>\n",
       "      <th>...</th>\n",
       "      <th>clac2_nm_118</th>\n",
       "      <th>clac2_nm_119</th>\n",
       "      <th>clac2_nm_120</th>\n",
       "      <th>clac2_nm_121</th>\n",
       "      <th>clac2_nm_122</th>\n",
       "      <th>clac2_nm_123</th>\n",
       "      <th>clac2_nm_124</th>\n",
       "      <th>clac2_nm_125</th>\n",
       "      <th>clac2_nm_126</th>\n",
       "      <th>clac2_nm_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clac2_nm_0  clac2_nm_1  clac2_nm_2  clac2_nm_3  clac2_nm_4  \\\n",
       "0              1.0         1.0         0.0         0.0         0.0   \n",
       "1              0.0         0.0         2.0         4.0         1.0   \n",
       "2              0.0         0.0         0.0         0.0         0.0   \n",
       "3              0.0         0.0         0.0         0.0         0.0   \n",
       "4              0.0         0.0         0.0         0.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "149995         0.0         0.0         0.0         0.0         0.0   \n",
       "149996         0.0         0.0         0.0         1.0         0.0   \n",
       "149997         0.0         0.0         0.0         0.0         0.0   \n",
       "149998         0.0         0.0         0.0         0.0         0.0   \n",
       "149999         0.0         0.0         3.0         1.0         0.0   \n",
       "\n",
       "        clac2_nm_5  clac2_nm_6  clac2_nm_7  clac2_nm_8  clac2_nm_9  ...  \\\n",
       "0              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1              1.0         1.0         0.0         0.0         0.0  ...   \n",
       "2              0.0         0.0         3.0         1.0         0.0  ...   \n",
       "3              0.0         0.0         0.0         0.0         2.0  ...   \n",
       "4              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "149995         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149996         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149997         0.0         0.0         0.0         1.0         0.0  ...   \n",
       "149998         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149999         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "        clac2_nm_118  clac2_nm_119  clac2_nm_120  clac2_nm_121  clac2_nm_122  \\\n",
       "0                0.0           0.0           0.0           0.0           0.0   \n",
       "1                0.0           0.0           0.0           0.0           0.0   \n",
       "2                0.0           0.0           0.0           0.0           0.0   \n",
       "3                0.0           0.0           0.0           0.0           0.0   \n",
       "4                0.0           0.0           0.0           0.0           0.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "149995           0.0           0.0           0.0           0.0           0.0   \n",
       "149996           0.0           0.0           0.0           0.0           0.0   \n",
       "149997           0.0           0.0           0.0           0.0           0.0   \n",
       "149998           0.0           0.0           0.0           0.0           0.0   \n",
       "149999           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        clac2_nm_123  clac2_nm_124  clac2_nm_125  clac2_nm_126  clac2_nm_127  \n",
       "0                0.0           0.0           0.0           0.0           0.0  \n",
       "1                0.0           0.0           0.0           0.0           0.0  \n",
       "2                0.0           0.0           0.0           0.0           0.0  \n",
       "3                0.0           0.0           0.0           0.0           0.0  \n",
       "4                0.0           0.0           0.0           0.0           0.0  \n",
       "...              ...           ...           ...           ...           ...  \n",
       "149995           0.0           0.0           0.0           0.0           0.0  \n",
       "149996           0.0           0.0           0.0           0.0           0.0  \n",
       "149997           0.0           0.0           0.0           0.0           0.0  \n",
       "149998           0.0           0.0           0.0           0.0           0.0  \n",
       "149999           0.0           0.0           0.0           0.0           0.0  \n",
       "\n",
       "[150000 rows x 128 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f259a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_nm_dic = {}\n",
    "for i, nm in enumerate(df['CLAC3_NM'].unique()):\n",
    "    clac3_nm_dic[nm] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a06779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'블랜더': 0,\n",
       " '거실수예소품': 1,\n",
       " '남성수영복': 2,\n",
       " '페이셜클렌저': 3,\n",
       " '선크림류': 4,\n",
       " '여성비치웨어': 5,\n",
       " '홍삼액': 6,\n",
       " 'BB/파운데이션/컴팩트류': 7,\n",
       " '에센스/세럼': 8,\n",
       " '여성속옷세트': 9,\n",
       " '브래지어': 10,\n",
       " '여성팬티': 11,\n",
       " '여성스포츠샌들/슬리퍼': 12,\n",
       " '유아동팬티': 13,\n",
       " '유아동일반양말': 14,\n",
       " '여성샌들': 15,\n",
       " '유아동타이즈': 16,\n",
       " '주방칼/가위': 17,\n",
       " '영유아점프수트/오버롤': 18,\n",
       " '아동모': 19,\n",
       " '프라이팬': 20,\n",
       " '롤티슈': 21,\n",
       " '플라스틱서랍장': 22,\n",
       " '유아용화장품': 23,\n",
       " '일반형냉장고': 24,\n",
       " '핸드로션/크림': 25,\n",
       " '남성스포츠티셔츠': 26,\n",
       " '크림/밤/오일': 27,\n",
       " '골프공': 28,\n",
       " '골프연습장비': 29,\n",
       " '립글로즈/틴트': 30,\n",
       " '남성일반지갑': 31,\n",
       " '남성런닝/트레이닝화': 32,\n",
       " '애견주거/실내용품': 33,\n",
       " '생수': 34,\n",
       " '여성트레이닝복': 35,\n",
       " '여성런닝셔츠/캐미솔': 36,\n",
       " '채소즙': 37,\n",
       " '남성용스킨케어류': 38,\n",
       " '3단우산': 39,\n",
       " '스포츠가방': 40,\n",
       " '남성팬티': 41,\n",
       " '여성남방셔츠': 42,\n",
       " '여성원피스': 43,\n",
       " '유아동이불/이불커버': 44,\n",
       " '남성티셔츠': 45,\n",
       " '남성캐주얼바지': 46,\n",
       " '여성코트': 47,\n",
       " '남성청바지': 48,\n",
       " '기타여성속옷': 49,\n",
       " '기타냉방가전': 50,\n",
       " '영유아티셔츠/탑': 51,\n",
       " '여아티셔츠/탑': 52,\n",
       " '생리대': 53,\n",
       " '유아용기저귀': 54,\n",
       " '유산균/프로바이오틱스': 55,\n",
       " '김치류': 56,\n",
       " '남성등산바지': 57,\n",
       " '유아동스포츠샌들/슬리퍼': 58,\n",
       " '골프패션잡화': 59,\n",
       " '염모제': 60,\n",
       " '장우산': 61,\n",
       " '골프필드용품': 62,\n",
       " '텐트': 63,\n",
       " '기타에어컨': 64,\n",
       " '여성스니커즈': 65,\n",
       " '남성정장셔츠': 66,\n",
       " '토스터/제빵기': 67,\n",
       " '선풍기': 68,\n",
       " '유아동런닝셔츠': 69,\n",
       " '배낭': 70,\n",
       " '여성크로스백': 71,\n",
       " '남성런닝셔츠': 72,\n",
       " '남성남방셔츠': 73,\n",
       " '여성스웨터/풀오버': 74,\n",
       " '영유아스커트': 75,\n",
       " '여아가디건': 76,\n",
       " '아동수영복': 77,\n",
       " '미스트': 78,\n",
       " '스킨/토너': 79,\n",
       " '애견장난감/훈련': 80,\n",
       " '고양이캣타워/실내용품': 81,\n",
       " '기타구강관리용품': 82,\n",
       " '남성등산티셔츠': 83,\n",
       " '남성점퍼': 84,\n",
       " '팬티라이너': 85,\n",
       " '여성로퍼': 86,\n",
       " '여성티셔츠/탑': 87,\n",
       " '냉동국탕류': 88,\n",
       " '서랍장/수납장': 89,\n",
       " '책상의자': 90,\n",
       " '스킨케어세트': 91,\n",
       " '페이셜팩류': 92,\n",
       " '출산/신생아용품세트': 93,\n",
       " '아기띠/캐리어': 94,\n",
       " '여성스포츠티셔츠/탑': 95,\n",
       " '유아동샌들': 96,\n",
       " '여성바지': 97,\n",
       " '영유아원피스': 98,\n",
       " '남성정장바지': 99,\n",
       " '남성일반스포츠바지': 100,\n",
       " '미술/창작완구': 101,\n",
       " '기타요가/필라테스소품': 102,\n",
       " '숟가락/젓가락': 103,\n",
       " '아쿠아슈즈': 104,\n",
       " '여성재킷': 105,\n",
       " '영유아바지': 106,\n",
       " '남성골프바지': 107,\n",
       " '유아동침구세트': 108,\n",
       " '유아/아동용치약': 109,\n",
       " '스포츠모자': 110,\n",
       " '유아동슬리퍼': 111,\n",
       " '여성골프패딩': 112,\n",
       " '여성숄더백': 113,\n",
       " '야구모자': 114,\n",
       " '유아동스니커즈': 115,\n",
       " '헤어에센스': 116,\n",
       " '탁자': 117,\n",
       " '닭가슴살': 118,\n",
       " '유아동내의': 119,\n",
       " '남아티셔츠/탑': 120,\n",
       " '오리발/스노클링': 121,\n",
       " '남아잠옷': 122,\n",
       " '식탁의자': 123,\n",
       " '유아용물티슈': 124,\n",
       " '애견간식': 125,\n",
       " '여성플랫': 126,\n",
       " '애견사료': 127,\n",
       " '반찬통/밀폐용기': 128,\n",
       " '어린이홍삼': 129,\n",
       " '스포츠시계': 130,\n",
       " '고양이모래/배변용품': 131,\n",
       " '남성스포츠샌들/슬리퍼': 132,\n",
       " '혼합즙': 133,\n",
       " '아이브로우': 134,\n",
       " '아이케어': 135,\n",
       " '바디워시': 136,\n",
       " '유아용샴푸/바디워시': 137,\n",
       " '샴푸': 138,\n",
       " '남성가디건': 139,\n",
       " '여성가디건': 140,\n",
       " '캐리어': 141,\n",
       " '한방음료': 142,\n",
       " '아동용가방': 143,\n",
       " '여성일반스포츠바지': 144,\n",
       " '노트북': 145,\n",
       " '메이크업세트': 146,\n",
       " '여성임부속옷': 147,\n",
       " '접시': 148,\n",
       " '반상기세트/홈세트': 149,\n",
       " '장롱': 150,\n",
       " '매트리스': 151,\n",
       " '여성점퍼': 152,\n",
       " '홈웨어세트': 153,\n",
       " '남성골프티셔츠': 154,\n",
       " '여성스웨트셔츠/후드/집업': 155,\n",
       " '남성비치웨어': 156,\n",
       " '기타모바일액세서리': 157,\n",
       " '성인침구속통/솜': 158,\n",
       " '바구니': 159,\n",
       " '테이프': 160,\n",
       " '칼/가위': 161,\n",
       " '수정용품': 162,\n",
       " '유아동선글라스': 163,\n",
       " '여성클러치백': 164,\n",
       " '영유아청바지': 165,\n",
       " '캠핑테이블/의자': 166,\n",
       " '여아바지': 167,\n",
       " '남아청바지': 168,\n",
       " '고양이사료': 169,\n",
       " '커튼': 170,\n",
       " '기타물놀이용품': 171,\n",
       " '여성신발부속품': 172,\n",
       " '노트북가방': 173,\n",
       " '여성카드/명함지갑': 174,\n",
       " '책상': 175,\n",
       " '여성스커트': 176,\n",
       " '욕실발판': 177,\n",
       " '마스카라': 178,\n",
       " '남성시계': 179,\n",
       " '남성패딩': 180,\n",
       " '식탁세트': 181,\n",
       " '피규어': 182,\n",
       " '욕실소품': 183,\n",
       " '롤플레잉완구': 184,\n",
       " '기타캠핑용품': 185,\n",
       " '분말표백제': 186,\n",
       " '풀': 187,\n",
       " '종합영양제': 188,\n",
       " '피트니스용품': 189,\n",
       " '스툴/리빙의자': 190,\n",
       " '책장': 191,\n",
       " '칫솔': 192,\n",
       " '수건': 193,\n",
       " '액상세탁세제': 194,\n",
       " '영유아블라우스': 195,\n",
       " '남아바지': 196,\n",
       " '헤어케어선물세트': 197,\n",
       " '여성등산티셔츠/탑': 198,\n",
       " '남성베스트': 199,\n",
       " '썬캡': 200,\n",
       " '스카프': 201,\n",
       " '블러셔/쉐이딩/하이라이터': 202,\n",
       " '여아레깅스': 203,\n",
       " '애견목욕/위생용품': 204,\n",
       " '기타일반문구/사무용품': 205,\n",
       " '린스/컨디셔너': 206,\n",
       " '샴푸/린스세트': 207,\n",
       " '미용비누': 208,\n",
       " '성인매트리스커버': 209,\n",
       " '스냅백': 210,\n",
       " '기타컴퓨터액세서리': 211,\n",
       " '유아동플랫': 212,\n",
       " '기타영양제': 213,\n",
       " '여아남방셔츠': 214,\n",
       " '남아의류세트': 215,\n",
       " '탄산수': 216,\n",
       " '일반청소기': 217,\n",
       " '손싸개/발싸개': 218,\n",
       " '유아동런닝/트레이닝화': 219,\n",
       " '여성토트백': 220,\n",
       " '여성일반양말': 221,\n",
       " '여성런닝/트레이닝화': 222,\n",
       " '치약': 223,\n",
       " '샤워/목욕도구/목욕헤어밴드': 224,\n",
       " '봉제인형': 225,\n",
       " '유아동베개/베개커버': 226,\n",
       " '놀이방매트': 227,\n",
       " '식음료모바일상품권': 228,\n",
       " '여아베스트': 229,\n",
       " '성인베개/베개커버': 230,\n",
       " '이유식용품': 231,\n",
       " '아이섀도우': 232,\n",
       " '남성샌들': 233,\n",
       " '기타이미용가전': 234,\n",
       " '요가/필라테스복': 235,\n",
       " '여성향수': 236,\n",
       " '기타정리용품': 237,\n",
       " '트리트먼트/팩': 238,\n",
       " '욕실청소용품': 239,\n",
       " '기타주방정리용품/소모품': 240,\n",
       " '여아청바지': 241,\n",
       " '기름종이': 242,\n",
       " '아이라이너': 243,\n",
       " '홍삼/인삼혼합세트': 244,\n",
       " '여성시계': 245,\n",
       " '손수건': 246,\n",
       " '팔찌': 247,\n",
       " '남성숄더/크로스백': 248,\n",
       " '지퍼백/비닐백': 249,\n",
       " '성인패드/스프레드': 250,\n",
       " '여성펌프스': 251,\n",
       " '구강청정제': 252,\n",
       " '남성일반양말': 253,\n",
       " '여성오픈토': 254,\n",
       " '공기청정기': 255,\n",
       " '여성등산바지': 256,\n",
       " '커튼링/커튼봉/부속품': 257,\n",
       " '메이크업베이스/프라이머': 258,\n",
       " '여아점퍼': 259,\n",
       " '남성등산점퍼/재킷': 260,\n",
       " '유아동슬립온': 261,\n",
       " '인삼가공식품': 262,\n",
       " '여성덧신류': 263,\n",
       " '냉동핫도그': 264,\n",
       " '여성블라우스': 265,\n",
       " '식기건조대/수저통': 266,\n",
       " '국자/뒤지개/주걱': 267,\n",
       " '여성부츠': 268,\n",
       " '여성베스트': 269,\n",
       " '에멀젼/로션': 270,\n",
       " '기타조리도구': 271,\n",
       " '바디보습': 272,\n",
       " '여성패딩': 273,\n",
       " '성인이불/이불커버': 274,\n",
       " '솥': 275,\n",
       " '이불/옷압축팩': 276,\n",
       " '섬유유연제/향기지속제': 277,\n",
       " '양산': 278,\n",
       " '여성수영복': 279,\n",
       " '남성내의': 280,\n",
       " '기타등산용품': 281,\n",
       " '유아용세척용품': 282,\n",
       " '도마': 283,\n",
       " '생활모바일상품권': 284,\n",
       " '젖병/젖꼭지': 285,\n",
       " '아동우산': 286,\n",
       " '케이스/보호필름': 287,\n",
       " '남성스킨케어세트': 288,\n",
       " '여성백팩': 289,\n",
       " '커피머신': 290,\n",
       " '방석/방석커버': 291,\n",
       " '장식장/진열장': 292,\n",
       " '다이어트보조식품': 293,\n",
       " '남성스니커즈': 294,\n",
       " '남성용클렌저': 295,\n",
       " '소품가방': 296,\n",
       " '변기시트/커버': 297,\n",
       " '헤드웨어': 298,\n",
       " '여행용소품': 299,\n",
       " '목걸이': 300,\n",
       " '미용보조식품': 301,\n",
       " '제빵용품': 302,\n",
       " 'PC부품': 303,\n",
       " '등산화': 304,\n",
       " '젤네일/케어류': 305,\n",
       " '핸디형청소기': 306,\n",
       " '주방선반/걸이대': 307,\n",
       " '옷걸이': 308,\n",
       " '유아동침대': 309,\n",
       " '로봇청소기': 310,\n",
       " '헤어드라이어': 311,\n",
       " '레저모바일상품권': 312,\n",
       " '스폰지/퍼프': 313,\n",
       " '커피용품': 314,\n",
       " '커피잔': 315,\n",
       " '저장장치': 316,\n",
       " '우주복': 317,\n",
       " '립스틱/립라이너': 318,\n",
       " '조립/프라모델': 319,\n",
       " '스케이트보드/킥보드': 320,\n",
       " '남성로퍼': 321,\n",
       " '여성쪼리': 322,\n",
       " '여성트렌치코트': 323,\n",
       " '남성정장재킷': 324,\n",
       " '골프화': 325,\n",
       " '남성트레이닝복': 326,\n",
       " '전기찜기': 327,\n",
       " '남성향수': 328,\n",
       " '일반비타민': 329,\n",
       " '여성슬링백': 330,\n",
       " '촉각놀이/오뚝이': 331,\n",
       " '기타패션잡화': 332,\n",
       " '데오도란트': 333,\n",
       " '수영모자': 334,\n",
       " '여성슬리퍼': 335,\n",
       " '고무장갑': 336,\n",
       " '일반두유': 337,\n",
       " '속눈썹/쌍꺼풀': 338,\n",
       " '물안경': 339,\n",
       " '기타여행용가방': 340,\n",
       " '남성트렌치코트': 341,\n",
       " '발찌': 342,\n",
       " '남성스웨터/풀오버': 343,\n",
       " '호두': 344,\n",
       " '캠핑침구': 345,\n",
       " '아동비치웨어': 346,\n",
       " '애견의류/악세서리': 347,\n",
       " '성인침구세트': 348,\n",
       " '남성등산패딩': 349,\n",
       " '냉동만두': 350,\n",
       " '냄비': 351,\n",
       " '남성캐주얼재킷': 352,\n",
       " '승마운동기': 353,\n",
       " '바디케어세트': 354,\n",
       " '거들': 355,\n",
       " '성인요/요커버': 356,\n",
       " '여성내의': 357,\n",
       " '루테인': 358,\n",
       " '여성청바지': 359,\n",
       " '여성잠옷': 360,\n",
       " '인덕션/가스레인지': 361,\n",
       " '캠핑취사': 362,\n",
       " '마우스': 363,\n",
       " '블랙박스': 364,\n",
       " '포크/나이프': 365,\n",
       " '남성속옷세트': 366,\n",
       " '여성슬립온': 367,\n",
       " '오메가3/기타추출오일': 368,\n",
       " '헤어세팅기': 369,\n",
       " '키보드': 370,\n",
       " '모바일배터리/충전기': 371,\n",
       " '채반/바구니/쟁반': 372,\n",
       " '선반장/행거': 373,\n",
       " '안경테': 374,\n",
       " '여성골프바지': 375,\n",
       " '커피메이커/포트': 376,\n",
       " '유아동스포츠티셔츠/탑': 377,\n",
       " '유아동스포츠스웨트셔츠/후드/집업': 378,\n",
       " '고양이간식': 379,\n",
       " '사무용/학생용가구세트': 380,\n",
       " '벽걸이형에어컨': 381,\n",
       " '여성등산점퍼/재킷': 382,\n",
       " '홍삼정/분말/환': 383,\n",
       " '토마토': 384,\n",
       " '스킨케어디바이스': 385,\n",
       " '입욕제/스파제품': 386,\n",
       " '과일즙': 387,\n",
       " '전기튀김기': 388,\n",
       " '성인담요': 389,\n",
       " '귀걸이': 390,\n",
       " '소파': 391,\n",
       " '행주': 392,\n",
       " '여성골프남방셔츠': 393,\n",
       " '영유아남방셔츠': 394,\n",
       " '스텝퍼/트위스트': 395,\n",
       " '여성등산패딩': 396,\n",
       " '식탁': 397,\n",
       " '전기밥솥': 398,\n",
       " '대접/볼': 399,\n",
       " '밥공기': 400,\n",
       " '찬기/종지': 401,\n",
       " '여성발가락양말': 402,\n",
       " '역할놀이': 403,\n",
       " '유아용카시트/매트': 404,\n",
       " '젖병소독/건조용품': 405,\n",
       " '유아/아동용칫솔': 406,\n",
       " '기타냉동간편식': 407,\n",
       " '유아목욕용품': 408,\n",
       " '유아동트레이닝복': 409,\n",
       " '여아잠옷': 410,\n",
       " '선반/걸이': 411,\n",
       " '여성양말선물세트': 412,\n",
       " '물티슈': 413,\n",
       " '남성코트': 414,\n",
       " '분말세탁세제': 415,\n",
       " '수유패드/보조용품': 416,\n",
       " '유아동의자': 417,\n",
       " '학생용가방': 418,\n",
       " '남성스포츠점퍼/재킷': 419,\n",
       " '유아공부상/디딤대': 420,\n",
       " '잉크/토너': 421,\n",
       " '여성향수세트': 422,\n",
       " '펜던트': 423,\n",
       " '여성일반지갑': 424,\n",
       " '보드게임': 425,\n",
       " '레고': 426,\n",
       " '유아동스포츠점퍼/재킷': 427,\n",
       " '치약/칫솔세트': 428,\n",
       " '수영가방': 429,\n",
       " '패션인형': 430,\n",
       " '도시락/찬합': 431,\n",
       " '발효원액': 432,\n",
       " '남성등산베스트': 433,\n",
       " '여성선글라스': 434,\n",
       " '여성점프수트/오버롤': 435,\n",
       " '치아발육기/딸랑이': 436,\n",
       " '남성카드/명함지갑': 437,\n",
       " '남성용선크림/메이크업류': 438,\n",
       " '남성골프점퍼/재킷': 439,\n",
       " '여성골프티셔츠/탑': 440,\n",
       " '기타국산과일류': 441,\n",
       " '여아스커트': 442,\n",
       " '건조기': 443,\n",
       " '기타기능성음료': 444,\n",
       " '스피커': 445,\n",
       " '얼음/빙수용품': 446,\n",
       " '스타킹': 447,\n",
       " '보온병/텀블러': 448,\n",
       " '전동칫솔/칫솔모': 449,\n",
       " '여아스웨트셔츠/후드/집업': 450,\n",
       " '혼합견과': 451,\n",
       " '볼펜': 452,\n",
       " '필통': 453,\n",
       " '샤프/샤프심': 454,\n",
       " '필기구세트': 455,\n",
       " '엽산/철분': 456,\n",
       " '유아패션잡화': 457,\n",
       " '휴대폰': 458,\n",
       " '각티슈/미용티슈': 459,\n",
       " '골프가방': 460,\n",
       " '여성타이즈': 461,\n",
       " '요가/스포츠매트': 462,\n",
       " '여성골프스커트': 463,\n",
       " '골프장갑': 464,\n",
       " '여성골프니트/가디건': 465,\n",
       " '여성골프베스트': 466,\n",
       " '영유아점퍼': 467,\n",
       " '영유아가디건': 468,\n",
       " '남성스웨트셔츠/후드/집업': 469,\n",
       " '사인펜': 470,\n",
       " '남성선글라스': 471,\n",
       " '반지': 472,\n",
       " '이어폰/헤드폰': 473,\n",
       " '조리도구세트': 474,\n",
       " '키친타올': 475,\n",
       " '남녀공용향수': 476,\n",
       " '유아동레인부츠/슈즈': 477,\n",
       " '유아건강보조제': 478,\n",
       " '여성가운': 479,\n",
       " '남성잠옷': 480,\n",
       " '유아동스포츠패딩': 481,\n",
       " '여아패딩': 482,\n",
       " '전통/종교장신구': 483,\n",
       " '복근/벨트마사지기구': 484,\n",
       " '벙거지': 485,\n",
       " '슬립': 486,\n",
       " '만년필': 487,\n",
       " '공병/모델링팩전용도구': 488,\n",
       " '화장대': 489,\n",
       " '핸드카트': 490,\n",
       " '여성레인부츠/슈즈': 491,\n",
       " '퍼즐': 492,\n",
       " '캐쥬얼크로스백': 493,\n",
       " '음악/악기완구': 494,\n",
       " '아기체육관/러닝홈': 495,\n",
       " '면봉/화장솜': 496,\n",
       " '남성골프남방셔츠': 497,\n",
       " '수예소품속통/솜': 498,\n",
       " '쿠션/쿠션커버': 499,\n",
       " '붙박이장': 500,\n",
       " '기타견과류': 501,\n",
       " '아몬드': 502,\n",
       " '여성등산베스트': 503,\n",
       " '영유아레깅스': 504,\n",
       " '여성컴포트화': 505,\n",
       " '남성정장화': 506,\n",
       " '블라인드/버티컬': 507,\n",
       " '스포츠두건/머플러/마스크': 508,\n",
       " '남성골프패딩': 509,\n",
       " '스포츠양말': 510,\n",
       " '남성정장세트': 511,\n",
       " '음료용컵': 512,\n",
       " '인라인/스케이트보드/킥보드안전용품': 513,\n",
       " '애견식기/물병': 514,\n",
       " '복숭아': 515,\n",
       " '글루코사민': 516,\n",
       " '헤어브러쉬/롤': 517,\n",
       " '거실화/실내화': 518,\n",
       " '유아동담요': 519,\n",
       " '고데기': 520,\n",
       " '칼슘/미네랄': 521,\n",
       " '주방수예소품': 522,\n",
       " '무선조종': 523,\n",
       " '수세미/솔': 524,\n",
       " '유모차': 525,\n",
       " '남성덧신류': 526,\n",
       " '참외': 527,\n",
       " '사과': 528,\n",
       " '제습기': 529,\n",
       " '양문형냉장고': 530,\n",
       " '메이크업브러쉬': 531,\n",
       " '가습기': 532,\n",
       " '유아동요/요커버': 533,\n",
       " '구명조끼/안전용품': 534,\n",
       " '네일케어도구': 535,\n",
       " '애견건강용품': 536,\n",
       " '오븐/전자레인지': 537,\n",
       " '압력솥': 538,\n",
       " '기타유아동화': 539,\n",
       " '유아동일반스포츠바지': 540,\n",
       " '여성세정제': 541,\n",
       " '비닐장갑': 542,\n",
       " '스포츠선글라스': 543,\n",
       " '미니자동차': 544,\n",
       " '전자교육완구': 545,\n",
       " '수박': 546,\n",
       " '바디슬리밍/리프팅': 547,\n",
       " '남아셔츠': 548,\n",
       " '헤어무스/젤': 549,\n",
       " '남아실내복': 550,\n",
       " '풋케어': 551,\n",
       " '여아재킷': 552,\n",
       " '제기': 553,\n",
       " '일반교육완구': 554,\n",
       " '올인원': 555,\n",
       " '유축기': 556,\n",
       " '욕실화': 557,\n",
       " '필기도구소모품': 558,\n",
       " '남성머니클립': 559,\n",
       " '헤어스프레이': 560,\n",
       " '스팀청소기': 561,\n",
       " '여성스포츠점퍼/재킷': 562,\n",
       " '기타보석류': 563,\n",
       " '자두': 564,\n",
       " '메론': 565,\n",
       " '멀티형에어컨': 566,\n",
       " '기타모자': 567,\n",
       " '유아동패드/스프레드': 568,\n",
       " '카메라액세서리': 569,\n",
       " '전기면도기': 570,\n",
       " '유아동방한화': 571,\n",
       " '남성서류가방': 572,\n",
       " '책상정리용품': 573,\n",
       " '비니': 574,\n",
       " '남성슬립온': 575,\n",
       " '디저트포크/스푼': 576,\n",
       " '목욕용장난감': 577,\n",
       " '우비': 578,\n",
       " '주방수납장': 579,\n",
       " '유아동수납장': 580,\n",
       " '냉동떡볶이': 581,\n",
       " '건강보조식품세트': 582,\n",
       " '특수용세탁세제': 583,\n",
       " '여성레깅스': 584,\n",
       " '집게/클립': 585,\n",
       " '캐노피': 586,\n",
       " '핸드워시/손세정제': 587,\n",
       " '유아용욕조': 588,\n",
       " '모유보관용품': 589,\n",
       " '바운서/쏘서/보행기': 590,\n",
       " '발포비타민': 591,\n",
       " '여성스포츠베스트': 592,\n",
       " '드럼세탁기': 593,\n",
       " '고양이건강용품': 594,\n",
       " '스탠드형에어컨': 595,\n",
       " '남성신발부속품': 596,\n",
       " '유아동속옷세트': 597,\n",
       " '자연유래영양제': 598,\n",
       " '조리기구세트': 599,\n",
       " '남성골프스웨트셔츠/후드/집업': 600,\n",
       " '여성방한화': 601,\n",
       " 'LED': 602,\n",
       " 'UHD': 603,\n",
       " '냉동튀김': 604,\n",
       " '캐쥬얼백팩': 605,\n",
       " '욕실수납용품': 606,\n",
       " '연필깎이': 607,\n",
       " '연필': 608,\n",
       " '탐폰': 609,\n",
       " '운동보조식품': 610,\n",
       " '남성백팩': 611,\n",
       " '유아동로퍼': 612,\n",
       " '헤어왁스': 613,\n",
       " '배냇저고리': 614,\n",
       " '영유아베스트': 615,\n",
       " '고양이장난감': 616,\n",
       " '고양이목욕/위생용품': 617,\n",
       " '여성스포츠스웨트셔츠/후드/집업': 618,\n",
       " '국그릇': 619,\n",
       " '남성힙색': 620,\n",
       " '남성스포츠화부속품': 621,\n",
       " '여아블라우스': 622,\n",
       " '기타주방가전': 623,\n",
       " '남성스포츠스웨트셔츠/후드/집업': 624,\n",
       " '서류정리용품': 625,\n",
       " '숙취해소음료': 626,\n",
       " '배': 627,\n",
       " '영화/문화모바일상품권': 628,\n",
       " '남성스포츠속옷': 629,\n",
       " '보온도시락': 630,\n",
       " '남아스웨트셔츠/후드/집업': 631,\n",
       " '홍삼절편': 632,\n",
       " '침실가구세트': 633,\n",
       " '일반네일/케어류': 634,\n",
       " '남성슬리퍼': 635,\n",
       " '시계세트': 636,\n",
       " '한우선물세트': 637,\n",
       " '남성클러치백': 638,\n",
       " '붕붕카/스프링카/흔들말': 639,\n",
       " '이발기': 640,\n",
       " '삼계탕용닭': 641,\n",
       " '남아레깅스': 642,\n",
       " '블록': 643,\n",
       " '기타청소기': 644,\n",
       " '남성양말선물세트': 645,\n",
       " '남성캐쥬얼스포츠양말': 646,\n",
       " '목욕타올': 647,\n",
       " '여성골프스웨트셔츠/후드/집업': 648,\n",
       " '호일/랩/기름종이': 649,\n",
       " '파일/바인더': 650,\n",
       " '기타피트니스기구': 651,\n",
       " '영양제세트': 652,\n",
       " '튜브/보트': 653,\n",
       " '에어로빅복': 654,\n",
       " '여성사파리': 655,\n",
       " '러닝/워킹머신': 656,\n",
       " '롤스크린': 657,\n",
       " '애견이동장': 658,\n",
       " '액상표백제': 659,\n",
       " '야외용돗자리': 660,\n",
       " '침대': 661,\n",
       " '여성등산전신/원피스': 662,\n",
       " '메탈미용소도구': 663,\n",
       " '모빌': 664,\n",
       " '주전자': 665,\n",
       " '주류잔': 666,\n",
       " '오븐팬/피자팬': 667,\n",
       " '홍삼근': 668,\n",
       " '남성사파리': 669,\n",
       " '여성골프점퍼/재킷': 670,\n",
       " '형광펜': 671,\n",
       " '독서대': 672,\n",
       " '보석세트': 673,\n",
       " '열쇠고리': 674,\n",
       " '기타여성의류아우터': 675,\n",
       " '영유아코트': 676,\n",
       " '군모': 677,\n",
       " '헬스바이크': 678,\n",
       " '남성등산/아웃도어세트': 679,\n",
       " '남성등산전신': 680,\n",
       " '유아동부츠': 681,\n",
       " '남성컴포트화': 682,\n",
       " '영유아스웨터/풀오버': 683,\n",
       " '스탠드형김치냉장고': 684,\n",
       " '부분세탁제': 685,\n",
       " '닭윗날개(봉)': 686,\n",
       " '샤워커튼': 687,\n",
       " '골프채': 688,\n",
       " '미러리스': 689,\n",
       " '기타유아안전용품': 690,\n",
       " '영유아재킷': 691,\n",
       " '등산지팡이/스틱': 692,\n",
       " '땅콩': 693,\n",
       " '냉동밥': 694,\n",
       " '스포츠아대/헤어밴드': 695,\n",
       " '순금/순은/장식품': 696,\n",
       " '가발/부분가발': 697,\n",
       " '여성등산/아웃도어세트': 698,\n",
       " '전기그릴': 699,\n",
       " '그릴/구이불판': 700,\n",
       " '컵/행주살균기': 701,\n",
       " '뚝배기': 702,\n",
       " '기타유아동양말류': 703,\n",
       " '유아변기/배변훈련기': 704,\n",
       " '여성골프전신/원피스': 705,\n",
       " '무릎담요': 706,\n",
       " '태블릿PC': 707,\n",
       " '캐슈넛': 708,\n",
       " '남성스포츠패딩': 709,\n",
       " '싱크대/배수구용품': 710,\n",
       " '여성스포츠속옷': 711,\n",
       " '교자상/다용도상': 712,\n",
       " '캐쥬얼힙색': 713,\n",
       " '매직/보드마카': 714,\n",
       " '영유아스웨트셔츠/후드/집업': 715,\n",
       " '남성골프베스트': 716,\n",
       " '여성스포츠스커트': 717,\n",
       " '자/제도용품': 718,\n",
       " '문구세트': 719,\n",
       " '남성수면양말': 720,\n",
       " '남아스웨터/풀오버': 721,\n",
       " '일반세탁기': 722,\n",
       " '캐쥬얼숄더백': 723,\n",
       " '이불/옷커버류': 724,\n",
       " '전기냄비/뚝배기': 725,\n",
       " '피스타치오': 726,\n",
       " '돼지고기선물세트': 727,\n",
       " '전자계산기': 728,\n",
       " '힙색/사이드백': 729,\n",
       " '머플러': 730,\n",
       " '넥워머': 731,\n",
       " '젓갈': 732,\n",
       " '세탁비누': 733,\n",
       " '목욕가운': 734,\n",
       " '남성발가락양말': 735,\n",
       " '공유기': 736,\n",
       " '협탁': 737,\n",
       " '성인침대커버/스커트': 738,\n",
       " '명함정리용품': 739,\n",
       " '절임반찬': 740,\n",
       " '과실주병': 741,\n",
       " '립밤/립스크럽': 742,\n",
       " '제모용품': 743,\n",
       " '제모기': 744,\n",
       " '계량도구': 745,\n",
       " '보드류': 746,\n",
       " '프린터/복합기/스캐너': 747,\n",
       " '양념통': 748,\n",
       " '방울토마토': 749,\n",
       " '밤': 750,\n",
       " '스포츠목걸이/팔찌': 751,\n",
       " '고양이식기/급수': 752,\n",
       " '그늘막/타프': 753,\n",
       " '기타모바일기기': 754,\n",
       " '유아동옷장': 755,\n",
       " '남아가디건': 756,\n",
       " '테이블데코': 757,\n",
       " '여성스포츠전신/원피스': 758,\n",
       " '냅킨': 759,\n",
       " '바란스': 760,\n",
       " '뚜껑형김치냉장고': 761,\n",
       " '남성골프니트/가디건': 762,\n",
       " '여아코트': 763,\n",
       " '유아동매트리스커버': 764,\n",
       " '여성스포츠패딩': 765,\n",
       " '다기류': 766,\n",
       " '컴팩트': 767,\n",
       " '2단우산': 768,\n",
       " '기타냉장고': 769,\n",
       " '물병': 770,\n",
       " '데스크탑/올인원PC': 771,\n",
       " '기타카메라': 772,\n",
       " '마카다미아': 773,\n",
       " '냉동부침': 774,\n",
       " '브로치': 775,\n",
       " '남아베스트': 776,\n",
       " '여행용세트': 777,\n",
       " '귤류': 778,\n",
       " '하이앤드': 779,\n",
       " '항아리/쌀독류': 780,\n",
       " '헤어롤': 781,\n",
       " '여아스웨터/풀오버': 782,\n",
       " '냉동고': 783,\n",
       " '하이브리드': 784,\n",
       " '기타여성양말류': 785,\n",
       " '패션액세서리세트': 786,\n",
       " '기타영유아아우터': 787,\n",
       " '잣': 788,\n",
       " '스포츠음료': 789,\n",
       " '스테이플러': 790,\n",
       " '영유아패딩': 791,\n",
       " '기타배낭소품': 792,\n",
       " '시공가구': 793,\n",
       " 'DIY가구': 794,\n",
       " '살구': 795,\n",
       " '여성수면양말': 796,\n",
       " '유아동침구매트': 797,\n",
       " '기타남성양말류': 798,\n",
       " '정수기': 799,\n",
       " '여아실내복': 800,\n",
       " '모니터': 801,\n",
       " '유아동침구속통/솜': 802,\n",
       " '전동보드/전동킥보드': 803,\n",
       " '공간박스': 804,\n",
       " '하이패스': 805,\n",
       " '신발장': 806,\n",
       " 'DSLR': 807,\n",
       " '남성실내복': 808,\n",
       " '기타남성화': 809,\n",
       " '네비게이션': 810,\n",
       " '전기프라이팬': 811,\n",
       " '여성실내복': 812,\n",
       " '오프너/와인스크류': 813,\n",
       " '유아동시계': 814,\n",
       " '환풍기': 815,\n",
       " '볶음반찬': 816,\n",
       " '파티션': 817,\n",
       " '냉온풍기': 818,\n",
       " '펀치류': 819,\n",
       " '냉동피자': 820,\n",
       " '기차/레일완구': 821,\n",
       " '인라인/롤러스케이트': 822,\n",
       " '매실': 823,\n",
       " '주방용탈수기': 824,\n",
       " '유아동침대커버/스커트': 825,\n",
       " '기타자동차가전기기': 826,\n",
       " '여성캐쥬얼스포츠양말': 827,\n",
       " '네일세트': 828,\n",
       " '남성스포츠베스트': 829,\n",
       " '채칼/강판/절구': 830,\n",
       " '캐쥬얼시계': 831,\n",
       " '니삭스/오버니삭스': 832,\n",
       " '싸인물/자석/압핀': 833,\n",
       " '고양이의류/악세서리': 834,\n",
       " '비타민/에너지음료': 835,\n",
       " '에어워셔': 836,\n",
       " '냉장/냉동가전소모품': 837,\n",
       " '남성부츠': 838,\n",
       " '물걸레청소기': 839,\n",
       " '음식물건조기': 840,\n",
       " '요구르트/청국장제조기': 841,\n",
       " '골프채세트': 842,\n",
       " '고양이이동장': 843,\n",
       " '냉동면': 844,\n",
       " '소프트웨어': 845,\n",
       " '캠코더': 846,\n",
       " '무화과': 847,\n",
       " 'OLED': 848,\n",
       " '탈수기': 849,\n",
       " '육가공품선물세트': 850,\n",
       " '딸기': 851,\n",
       " '식기세척기': 852,\n",
       " '차량용충전기': 853,\n",
       " '유아두유': 854,\n",
       " '닭근위': 855,\n",
       " '닭아랫날개(윙)': 856,\n",
       " '안경소품': 857,\n",
       " '여성가방액세서리': 858,\n",
       " '태닝/애프터선케어': 859,\n",
       " '유아동스포츠스커트': 860,\n",
       " '카메라렌즈': 861,\n",
       " '닭안심': 862,\n",
       " '포도': 863,\n",
       " '볶음탕용닭': 864,\n",
       " '콜렉션인형': 865,\n",
       " 'LCD': 866,\n",
       " '리모컨/액세서리': 867,\n",
       " '반죽기/제면기': 868,\n",
       " '식기건조기': 869,\n",
       " '단무지': 870,\n",
       " '닭다리': 871,\n",
       " '감': 872,\n",
       " '오리고기': 873,\n",
       " '침구청소기': 874,\n",
       " '싱크대': 875,\n",
       " '미용거울': 876,\n",
       " '남녀공용향수세트': 877,\n",
       " '인라인/스케이트보드/킥보드기타액세서리': 878,\n",
       " '남성등산스웨트셔츠/후드/집업': 879,\n",
       " '커튼류세트': 880,\n",
       " '오토캠핑용품세트': 881,\n",
       " '수도용품': 882}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac3_nm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ae81abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clac3_nm'] = data['clac3_nm'].map(lambda x: [clac3_nm_dic[nm] for nm in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "796fa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_matrix = np.zeros((len(data), len(clac3_nm_dic)))\n",
    "for i in range(len(data)):\n",
    "    for j in data['clac3_nm'][i]:\n",
    "        clac3_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77adeb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac3_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85eae180",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac3_nm_' + str(i) for i in range(len(clac3_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6969bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_df = pd.DataFrame(clac3_matrix)\n",
    "clac3_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53023efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clac3_nm_0</th>\n",
       "      <th>clac3_nm_1</th>\n",
       "      <th>clac3_nm_2</th>\n",
       "      <th>clac3_nm_3</th>\n",
       "      <th>clac3_nm_4</th>\n",
       "      <th>clac3_nm_5</th>\n",
       "      <th>clac3_nm_6</th>\n",
       "      <th>clac3_nm_7</th>\n",
       "      <th>clac3_nm_8</th>\n",
       "      <th>clac3_nm_9</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_nm_873</th>\n",
       "      <th>clac3_nm_874</th>\n",
       "      <th>clac3_nm_875</th>\n",
       "      <th>clac3_nm_876</th>\n",
       "      <th>clac3_nm_877</th>\n",
       "      <th>clac3_nm_878</th>\n",
       "      <th>clac3_nm_879</th>\n",
       "      <th>clac3_nm_880</th>\n",
       "      <th>clac3_nm_881</th>\n",
       "      <th>clac3_nm_882</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 883 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clac3_nm_0  clac3_nm_1  clac3_nm_2  clac3_nm_3  clac3_nm_4  \\\n",
       "0              1.0         1.0         0.0         0.0         0.0   \n",
       "1              0.0         0.0         1.0         1.0         1.0   \n",
       "2              0.0         0.0         0.0         0.0         0.0   \n",
       "3              0.0         0.0         0.0         0.0         0.0   \n",
       "4              0.0         0.0         0.0         0.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "149995         0.0         0.0         0.0         0.0         0.0   \n",
       "149996         0.0         0.0         0.0         0.0         0.0   \n",
       "149997         0.0         0.0         0.0         0.0         0.0   \n",
       "149998         0.0         0.0         0.0         0.0         0.0   \n",
       "149999         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        clac3_nm_5  clac3_nm_6  clac3_nm_7  clac3_nm_8  clac3_nm_9  ...  \\\n",
       "0              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1              1.0         1.0         1.0         3.0         0.0  ...   \n",
       "2              0.0         0.0         0.0         0.0         1.0  ...   \n",
       "3              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "4              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "149995         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149996         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149997         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149998         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "149999         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "        clac3_nm_873  clac3_nm_874  clac3_nm_875  clac3_nm_876  clac3_nm_877  \\\n",
       "0                0.0           0.0           0.0           0.0           0.0   \n",
       "1                0.0           0.0           0.0           0.0           0.0   \n",
       "2                0.0           0.0           0.0           0.0           0.0   \n",
       "3                0.0           0.0           0.0           0.0           0.0   \n",
       "4                0.0           0.0           0.0           0.0           0.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "149995           0.0           0.0           0.0           0.0           0.0   \n",
       "149996           0.0           0.0           0.0           0.0           0.0   \n",
       "149997           0.0           0.0           0.0           0.0           0.0   \n",
       "149998           0.0           0.0           0.0           0.0           0.0   \n",
       "149999           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        clac3_nm_878  clac3_nm_879  clac3_nm_880  clac3_nm_881  clac3_nm_882  \n",
       "0                0.0           0.0           0.0           0.0           0.0  \n",
       "1                0.0           0.0           0.0           0.0           0.0  \n",
       "2                0.0           0.0           0.0           0.0           0.0  \n",
       "3                0.0           0.0           0.0           0.0           0.0  \n",
       "4                0.0           0.0           0.0           0.0           0.0  \n",
       "...              ...           ...           ...           ...           ...  \n",
       "149995           0.0           0.0           0.0           0.0           0.0  \n",
       "149996           0.0           0.0           0.0           0.0           0.0  \n",
       "149997           0.0           0.0           0.0           0.0           0.0  \n",
       "149998           0.0           0.0           0.0           0.0           0.0  \n",
       "149999           0.0           0.0           0.0           0.0           0.0  \n",
       "\n",
       "[150000 rows x 883 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bd5d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([data.iloc[:, :-6], clac1_df, clac2_df, clac3_df, data.iloc[:, -1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc80f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_nm_874</th>\n",
       "      <th>clac3_nm_875</th>\n",
       "      <th>clac3_nm_876</th>\n",
       "      <th>clac3_nm_877</th>\n",
       "      <th>clac3_nm_878</th>\n",
       "      <th>clac3_nm_879</th>\n",
       "      <th>clac3_nm_880</th>\n",
       "      <th>clac3_nm_881</th>\n",
       "      <th>clac3_nm_882</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43250</td>\n",
       "      <td>86500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>922</td>\n",
       "      <td>1844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>77777.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>132.333</td>\n",
       "      <td>1191</td>\n",
       "      <td>1311.11</td>\n",
       "      <td>11800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>24225</td>\n",
       "      <td>96900</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.75</td>\n",
       "      <td>87</td>\n",
       "      <td>297.25</td>\n",
       "      <td>1189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10550</td>\n",
       "      <td>21100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>498</td>\n",
       "      <td>5049</td>\n",
       "      <td>10098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14325.6</td>\n",
       "      <td>229210</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>144.938</td>\n",
       "      <td>2319</td>\n",
       "      <td>4187.25</td>\n",
       "      <td>66996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>263094</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>263095</td>\n",
       "      <td>2</td>\n",
       "      <td>122000</td>\n",
       "      <td>244000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220.5</td>\n",
       "      <td>441</td>\n",
       "      <td>1828</td>\n",
       "      <td>3656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>263096</td>\n",
       "      <td>3</td>\n",
       "      <td>28500</td>\n",
       "      <td>85500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>4237</td>\n",
       "      <td>12711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>263102</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>1812</td>\n",
       "      <td>1812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>263103</td>\n",
       "      <td>7</td>\n",
       "      <td>58628.6</td>\n",
       "      <td>410400</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>280</td>\n",
       "      <td>1960</td>\n",
       "      <td>3249.43</td>\n",
       "      <td>22746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 1060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clnt_id num_shopping avg_price total_price avg_ct total_ct  \\\n",
       "0            0            2     43250       86500      1        2   \n",
       "1            1            9   77777.8      700000      1        9   \n",
       "2            6            4     24225       96900      1        4   \n",
       "3            9            2     10550       21100      1        2   \n",
       "4           12           16   14325.6      229210      1       16   \n",
       "...        ...          ...       ...         ...    ...      ...   \n",
       "149995  263094            1     10000       10000      1        1   \n",
       "149996  263095            2    122000      244000      1        2   \n",
       "149997  263096            3     28500       85500      1        3   \n",
       "149998  263102            1      1080        1080      1        1   \n",
       "149999  263103            7   58628.6      410400      1        7   \n",
       "\n",
       "       avg_sess_view total_sess_view avg_sess_hr total_sess_hr  ...  \\\n",
       "0                 59             118         922          1844  ...   \n",
       "1            132.333            1191     1311.11         11800  ...   \n",
       "2              21.75              87      297.25          1189  ...   \n",
       "3                249             498        5049         10098  ...   \n",
       "4            144.938            2319     4187.25         66996  ...   \n",
       "...              ...             ...         ...           ...  ...   \n",
       "149995            66              66         513           513  ...   \n",
       "149996         220.5             441        1828          3656  ...   \n",
       "149997           256             768        4237         12711  ...   \n",
       "149998           188             188        1812          1812  ...   \n",
       "149999           280            1960     3249.43         22746  ...   \n",
       "\n",
       "       clac3_nm_874  clac3_nm_875  clac3_nm_876  clac3_nm_877  clac3_nm_878  \\\n",
       "0               0.0           0.0           0.0           0.0           0.0   \n",
       "1               0.0           0.0           0.0           0.0           0.0   \n",
       "2               0.0           0.0           0.0           0.0           0.0   \n",
       "3               0.0           0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "149995          0.0           0.0           0.0           0.0           0.0   \n",
       "149996          0.0           0.0           0.0           0.0           0.0   \n",
       "149997          0.0           0.0           0.0           0.0           0.0   \n",
       "149998          0.0           0.0           0.0           0.0           0.0   \n",
       "149999          0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        clac3_nm_879  clac3_nm_880  clac3_nm_881  clac3_nm_882  label  \n",
       "0                0.0           0.0           0.0           0.0    F20  \n",
       "1                0.0           0.0           0.0           0.0    F30  \n",
       "2                0.0           0.0           0.0           0.0    F20  \n",
       "3                0.0           0.0           0.0           0.0    F30  \n",
       "4                0.0           0.0           0.0           0.0    F30  \n",
       "...              ...           ...           ...           ...    ...  \n",
       "149995           0.0           0.0           0.0           0.0    F30  \n",
       "149996           0.0           0.0           0.0           0.0    F30  \n",
       "149997           0.0           0.0           0.0           0.0    F30  \n",
       "149998           0.0           0.0           0.0           0.0    F30  \n",
       "149999           0.0           0.0           0.0           0.0    F30  \n",
       "\n",
       "[150000 rows x 1060 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cd30213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat.to_csv('./train_preprocessed.csv', index=False)\n",
    "data_concat = pd.read_csv('./train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97b675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac1 = []\n",
    "for i in range(37):\n",
    "    # clac1_nm_number 이 1 이상인 것들 라벨 별(6차원) value count => 라벨별 분류 별 개수 파악\n",
    "    prob = data_concat[data_concat['clac1_nm_' + str(i)] >= 1].groupby('label')['label'].value_counts().values\n",
    "    if len(prob) != 6:\n",
    "        print(i, prob)\n",
    "    lookup_table_clac1.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4540370",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac1 = np.stack(lookup_table_clac1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7dcf2",
   "metadata": {},
   "source": [
    "- 가중치 스케일링 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ad957ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.37857506,  1.        ,  1.15318854, 23.14219474,  7.53074312,\n",
       "        6.04725363])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([59892/17727, 59892/59892, 59892/51936, 59892/2588, 59892/7953, 59892/9904])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a28dfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac1 = lookup_table_clac1 * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1077dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac1 = lookup_table_clac1 / lookup_table_clac1.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f4c75c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1196019 , 0.15351727, 0.20977359, 0.12166872, 0.17288697,\n",
       "        0.22255155],\n",
       "       [0.10090549, 0.22714818, 0.27848079, 0.07186492, 0.14375322,\n",
       "        0.1778474 ],\n",
       "       [0.10631361, 0.2387599 , 0.22268107, 0.0900885 , 0.15848887,\n",
       "        0.18366804],\n",
       "       [0.29039753, 0.19554586, 0.18492875, 0.11494716, 0.10232984,\n",
       "        0.11185087],\n",
       "       [0.12042409, 0.17029651, 0.21638294, 0.08393391, 0.18585456,\n",
       "        0.223108  ],\n",
       "       [0.13488386, 0.23263313, 0.22147735, 0.09935707, 0.14373666,\n",
       "        0.16791193],\n",
       "       [0.11902816, 0.13211609, 0.16521248, 0.21401495, 0.17611567,\n",
       "        0.19351265],\n",
       "       [0.16240187, 0.19808438, 0.20762432, 0.1376104 , 0.14092544,\n",
       "        0.1533536 ],\n",
       "       [0.07940145, 0.22461032, 0.27383925, 0.05948637, 0.1576259 ,\n",
       "        0.2050367 ],\n",
       "       [0.03879911, 0.36162852, 0.26285742, 0.01136482, 0.1382575 ,\n",
       "        0.18709264],\n",
       "       [0.08528045, 0.2160113 , 0.33747026, 0.03723632, 0.11662744,\n",
       "        0.20737422],\n",
       "       [0.09358846, 0.18638675, 0.24438927, 0.09532372, 0.16983156,\n",
       "        0.21048024],\n",
       "       [0.09206891, 0.20384676, 0.25386732, 0.06491919, 0.1679978 ,\n",
       "        0.21730001],\n",
       "       [0.10342799, 0.33434196, 0.14533046, 0.04690085, 0.23776732,\n",
       "        0.13223142],\n",
       "       [0.08571612, 0.13047683, 0.22820432, 0.03355022, 0.18014104,\n",
       "        0.34191147],\n",
       "       [0.17141221, 0.1971363 , 0.22892891, 0.09959467, 0.12696112,\n",
       "        0.17596679],\n",
       "       [0.06222505, 0.08604227, 0.23216874, 0.12038342, 0.13869779,\n",
       "        0.36048272],\n",
       "       [0.22324304, 0.15132509, 0.21897612, 0.11280584, 0.12399265,\n",
       "        0.16965727],\n",
       "       [0.09232229, 0.15829274, 0.22398933, 0.08735568, 0.20083988,\n",
       "        0.23720008],\n",
       "       [0.15518083, 0.23827301, 0.35983805, 0.03133611, 0.06798093,\n",
       "        0.14739108],\n",
       "       [0.07570349, 0.11247887, 0.15227928, 0.22193144, 0.22689   ,\n",
       "        0.21071693],\n",
       "       [0.08260026, 0.11442791, 0.23484849, 0.12832265, 0.18221544,\n",
       "        0.25758525],\n",
       "       [0.06496974, 0.11974998, 0.31650811, 0.05057075, 0.11519424,\n",
       "        0.33300719],\n",
       "       [0.05506505, 0.13947588, 0.20192598, 0.08704121, 0.21007141,\n",
       "        0.30642047],\n",
       "       [0.1021726 , 0.16848741, 0.26515277, 0.05554371, 0.17351595,\n",
       "        0.23512756],\n",
       "       [0.1075171 , 0.16963273, 0.19924108, 0.13591302, 0.18616776,\n",
       "        0.20152831],\n",
       "       [0.05438879, 0.28590838, 0.15388338, 0.03694675, 0.26049635,\n",
       "        0.20837634],\n",
       "       [0.17495297, 0.19306772, 0.23370193, 0.10849474, 0.12998832,\n",
       "        0.15979432],\n",
       "       [0.15856251, 0.12967989, 0.15168173, 0.17149013, 0.19066678,\n",
       "        0.19791896],\n",
       "       [0.08792574, 0.08498125, 0.12449074, 0.2230608 , 0.22501851,\n",
       "        0.25452295],\n",
       "       [0.14436981, 0.09515721, 0.10600739, 0.26868961, 0.19830566,\n",
       "        0.18747033],\n",
       "       [0.07729805, 0.18127121, 0.22229937, 0.11675443, 0.1661101 ,\n",
       "        0.23626684],\n",
       "       [0.08819849, 0.1800361 , 0.29377603, 0.08332861, 0.14235959,\n",
       "        0.21230117],\n",
       "       [0.15508448, 0.12116081, 0.10063624, 0.3026265 , 0.17685887,\n",
       "        0.1436331 ],\n",
       "       [0.07460569, 0.13838052, 0.27962674, 0.08760444, 0.14253759,\n",
       "        0.27724502],\n",
       "       [0.05972663, 0.06089107, 0.07248401, 0.18182619, 0.3993866 ,\n",
       "        0.22568551],\n",
       "       [0.10097066, 0.11264563, 0.11576269, 0.10640274, 0.30008079,\n",
       "        0.26413749]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table_clac1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f34723",
   "metadata": {},
   "source": [
    "- 룩업 테이블 중 6차원이 되지 못하는 것들 결측치 보완해 6차원 만들어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3db7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 [133 607 646  27  64]\n",
      "52 [  42 1780 1083   87  134]\n",
      "86 [  18 1216 1003   58  147]\n",
      "111 [  7 605 370  34  39]\n",
      "120 [ 21  90 124  21  35]\n",
      "122 [ 20 759 471  47  63]\n",
      "127 [ 1  9 10  4  4]\n"
     ]
    }
   ],
   "source": [
    "lookup_table_clac2 = []\n",
    "for i in range(128):\n",
    "    prob = data_concat[data_concat['clac2_nm_' + str(i)] >= 1].groupby('label')['label'].value_counts().values\n",
    "    if len(prob) != 6:\n",
    "        print(i, prob)\n",
    "    lookup_table_clac2.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "760401ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  label\n",
       "F20    F20        18\n",
       "F30    F30      1216\n",
       "F40    F40      1003\n",
       "M30    M30        58\n",
       "M40    M40       147\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat[data_concat['clac2_nm_' + str(86)] >= 1].groupby('label')['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8374f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac2[13] = np.array([56, 1238, 504, 0, 58, 71])\n",
    "lookup_table_clac2[42] = np.array([109, 519, 550, 0, 21, 52])\n",
    "lookup_table_clac2[52] = np.array([23, 1036, 685, 0, 52, 75])\n",
    "lookup_table_clac2[86] = np.array([9, 724, 644, 0, 39, 90])\n",
    "lookup_table_clac2[111] = np.array([5, 420, 261, 0, 28, 29])\n",
    "lookup_table_clac2[120] = np.array([18, 88, 121, 0, 20, 35])\n",
    "lookup_table_clac2[122] = np.array([18, 535, 349, 0, 37, 44])\n",
    "lookup_table_clac2[127] = np.array([1, 9, 10, 0, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b451fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac2 = np.stack(lookup_table_clac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57287fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 167,  791, 1075,   19,  100,  193],\n",
       "       [  71,  454,  706,    7,   45,   86],\n",
       "       [ 776, 5888, 4762,   96,  519,  749],\n",
       "       [2576, 8291, 7464,  175,  595,  777],\n",
       "       [ 347, 1245, 1276,   18,   86,  152],\n",
       "       [ 324, 1687, 1673,   36,  257,  343],\n",
       "       [5173, 9270, 6888,  160,  339,  613],\n",
       "       [1158, 4240, 4284,   28,  160,  401],\n",
       "       [ 741, 2125, 2624,  134,  373,  439],\n",
       "       [  75, 3239, 1694,    3,  149,  233],\n",
       "       [  59, 1537,  578,    2,   64,   92],\n",
       "       [1046, 4946, 5185,   47,  276,  482],\n",
       "       [  96,  887, 1001,   10,   78,  143],\n",
       "       [  56, 1238,  504,    0,   58,   71],\n",
       "       [ 181, 1942, 1187,   25,  169,  182],\n",
       "       [  72,  697, 1094,    4,   55,  134],\n",
       "       [  89,  535,  702,   15,   80,  124],\n",
       "       [ 103,  800,  845,    8,   78,  125],\n",
       "       [ 131, 1686,  846,    4,  131,  122],\n",
       "       [  18,   97,  162,    2,   16,   47],\n",
       "       [ 158,  654,  554,   11,   54,   69],\n",
       "       [ 755, 2113, 2934,  400,  772,  842],\n",
       "       [ 131,  612, 1432,   37,  131,  424],\n",
       "       [ 201,  251,  301,   49,   74,   67],\n",
       "       [ 916, 2915, 3431,  280,  636,  756],\n",
       "       [ 368,  931, 1218,   27,  112,  194],\n",
       "       [ 176, 1073, 1191,   32,  210,  298],\n",
       "       [ 911, 2243, 2646,   68,  156,  355],\n",
       "       [ 110,  482,  658,    8,   53,  123],\n",
       "       [ 175,  708,  719,   72,  210,  221],\n",
       "       [ 168, 1059, 1204,   15,   78,  149],\n",
       "       [ 366, 1225, 1554,   78,  255,  298],\n",
       "       [ 243, 1047, 1350,  120,  344,  378],\n",
       "       [1158, 6383, 9230,   33,  236,  723],\n",
       "       [ 849, 4607, 5286,   22,  140,  366],\n",
       "       [  74,  865,  282,    7,   65,   37],\n",
       "       [1409, 6914, 7984,  580, 1790, 1975],\n",
       "       [ 441, 2995, 3678,  284,  873, 1065],\n",
       "       [ 321, 1590, 2651,    5,   46,  180],\n",
       "       [  97,  454,  808,   22,   96,  169],\n",
       "       [ 111, 3567, 1951,    5,  172,  266],\n",
       "       [  55, 2762, 1891,    2,  131,  256],\n",
       "       [ 109,  519,  550,    0,   21,   52],\n",
       "       [ 178, 2684, 1138,    9,  255,  218],\n",
       "       [ 364, 1916, 2233,   38,  280,  433],\n",
       "       [  44,  274,  628,    5,   35,  126],\n",
       "       [ 292, 1630, 1980,  112,  459,  821],\n",
       "       [ 142, 3073, 1538,   13,  230,  242],\n",
       "       [ 411, 1656, 2061,   48,  143,  316],\n",
       "       [  35,  400,  377,   11,   97,  113],\n",
       "       [ 114,  779, 1238,   24,  151,  362],\n",
       "       [ 694, 1750, 2069,   50,   97,  181],\n",
       "       [  23, 1036,  685,    0,   52,   75],\n",
       "       [ 272,  558,  652,   19,   51,   73],\n",
       "       [ 113,  860,  953,   25,  104,  189],\n",
       "       [  88,  533, 1047,   41,  170,  330],\n",
       "       [  63,  351,  479,    5,   48,   81],\n",
       "       [  65,  268,  345,   11,   31,   52],\n",
       "       [  41,  211,  255,   12,   36,   58],\n",
       "       [ 242, 2458,  559,    9,  197,   84],\n",
       "       [  94,  743,  162,   11,   93,   44],\n",
       "       [ 159, 4015, 2016,    7,  249,  309],\n",
       "       [ 735, 3917, 5331,   19,  146,  415],\n",
       "       [  41,  891,  421,    4,   88,  109],\n",
       "       [ 243,  906,  951,   22,   81,  124],\n",
       "       [ 144,  956, 1367,    8,   50,  133],\n",
       "       [  47,  352,  766,   19,  118,  336],\n",
       "       [  40,  325, 1111,    9,   14,  102],\n",
       "       [  38,  177,  247,   12,   38,   45],\n",
       "       [  59,  166,  144,   10,   27,   25],\n",
       "       [  54, 1965, 1470,    2,  103,  201],\n",
       "       [  85,  963, 1099,    8,   63,  129],\n",
       "       [  16,  114,  171,    2,   10,   14],\n",
       "       [  60,  698,  801,    4,   59,  106],\n",
       "       [ 163,  325,  412,   31,   35,   58],\n",
       "       [ 615, 2143, 1953,   38,  170,  242],\n",
       "       [ 141,  411,  560,    9,   50,   89],\n",
       "       [  46,  499,  776,   10,   71,  143],\n",
       "       [  65,  746,  664,   13,   70,  111],\n",
       "       [  15,   35,   62,    6,   24,   21],\n",
       "       [  75,  262,  376,   10,   46,   70],\n",
       "       [ 347,  754,  724,   92,  199,  238],\n",
       "       [ 201, 1383, 1930,   21,  109,  228],\n",
       "       [ 160, 1410, 1481,   38,  167,  294],\n",
       "       [  43,  244,  282,    6,   28,   65],\n",
       "       [  66,  363,  419,    5,   44,   66],\n",
       "       [   9,  724,  644,    0,   39,   90],\n",
       "       [  32, 2532, 1868,    1,  123,  247],\n",
       "       [  29,  200,  283,    4,   21,   39],\n",
       "       [ 310,  515,  605,   38,   43,   71],\n",
       "       [ 109,  829,  951,   15,   96,  168],\n",
       "       [  19,  793,  461,    3,  104,  129],\n",
       "       [ 195, 1401, 1539,   28,  154,  234],\n",
       "       [ 128,  843, 1487,   17,   79,  201],\n",
       "       [ 289, 1027, 1218,   40,  105,  164],\n",
       "       [ 153,  496,  618,   56,  166,  244],\n",
       "       [  28, 1128,  780,    5,   77,  102],\n",
       "       [  55,  333,  370,    8,   55,   73],\n",
       "       [ 244, 1383, 1493,   19,  122,  221],\n",
       "       [ 505, 1467, 1173,    8,   79,  147],\n",
       "       [  69,  734,  269,    6,   89,   53],\n",
       "       [  48,  580,  152,   10,   74,   29],\n",
       "       [ 172,  454,  327,   49,   88,   89],\n",
       "       [ 103,  558,  765,   69,  232,  300],\n",
       "       [ 142,  430,  516,   26,   70,  108],\n",
       "       [ 549, 1127, 1011,   71,  136,  160],\n",
       "       [ 112, 1159, 1165,   11,  107,  163],\n",
       "       [ 501, 1016, 1116,   50,   78,  132],\n",
       "       [ 178,  303,  447,   43,   84,   95],\n",
       "       [  39,  249,  331,   19,   71,   77],\n",
       "       [  59,  281,  228,   11,   50,   68],\n",
       "       [   5,  420,  261,    0,   28,   29],\n",
       "       [ 125,  429,  592,   14,   50,   85],\n",
       "       [  25,  370,   82,    1,   40,   31],\n",
       "       [   9,  206,  115,    1,   27,   25],\n",
       "       [ 133,  455,  568,    6,   59,   68],\n",
       "       [  79,  454,  739,   11,   50,  131],\n",
       "       [   9,   31,   32,    4,   27,   19],\n",
       "       [  22, 1116,  821,    1,   65,  122],\n",
       "       [  27,  213,  463,    8,   41,   96],\n",
       "       [  18,   88,  121,    0,   20,   35],\n",
       "       [  11,   45,   49,    6,   23,   23],\n",
       "       [  18,  535,  349,    0,   37,   44],\n",
       "       [  11,   69,   94,   25,   83,   99],\n",
       "       [  30,  107,   71,    5,   37,   34],\n",
       "       [   9,   40,   60,    2,   15,   23],\n",
       "       [  17,   44,   70,    2,   14,   28],\n",
       "       [   1,    9,   10,    0,    4,    4]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table_clac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a85a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac2 = lookup_table_clac2 * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e634cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac2 = lookup_table_clac2 / lookup_table_clac2.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "082bf5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11387393, 0.15964331, 0.25019754, 0.08874265, 0.15198897,\n",
       "        0.2355536 ],\n",
       "       [0.09485229, 0.17951954, 0.32192959, 0.0640558 , 0.13400044,\n",
       "        0.20564233],\n",
       "       [0.10631361, 0.2387599 , 0.22268107, 0.0900885 , 0.15848887,\n",
       "        0.18366804],\n",
       "       [0.22413044, 0.21351497, 0.22166308, 0.10429512, 0.11539214,\n",
       "        0.12100425],\n",
       "       [0.19964605, 0.21201521, 0.25058131, 0.07093731, 0.11028945,\n",
       "        0.15653067],\n",
       "       [0.11457987, 0.17658134, 0.20194169, 0.08720407, 0.20258192,\n",
       "        0.2171111 ],\n",
       "       [0.39140263, 0.20760004, 0.17788575, 0.08292247, 0.05717224,\n",
       "        0.08301687],\n",
       "       [0.22523187, 0.24409201, 0.28440517, 0.03730356, 0.06936582,\n",
       "        0.13960156],\n",
       "       [0.15435505, 0.1310171 , 0.1865663 , 0.19119582, 0.17318717,\n",
       "        0.16367855],\n",
       "       [0.03149144, 0.40253967, 0.24277919, 0.00862827, 0.13945107,\n",
       "        0.17511036],\n",
       "       [0.05715761, 0.4407196 , 0.19112463, 0.01327159, 0.13819945,\n",
       "        0.15952712],\n",
       "       [0.1720522 , 0.2407959 , 0.29110124, 0.05295383, 0.101191  ,\n",
       "        0.14190582],\n",
       "       [0.08009934, 0.21905226, 0.28507459, 0.05715163, 0.14506296,\n",
       "        0.21355922],\n",
       "       [0.06581918, 0.4306768 , 0.20219094, 0.        , 0.15194859,\n",
       "        0.14936449],\n",
       "       [0.08895892, 0.28250529, 0.1991262 , 0.08416314, 0.1851407 ,\n",
       "        0.16010575],\n",
       "       [0.06912809, 0.19807116, 0.35851399, 0.02630589, 0.1177034 ,\n",
       "        0.23027747],\n",
       "       [0.08990184, 0.15995535, 0.24203737, 0.10378648, 0.18012451,\n",
       "        0.22419445],\n",
       "       [0.09531764, 0.21912527, 0.26690671, 0.0507104 , 0.16089217,\n",
       "        0.20704782],\n",
       "       [0.08993877, 0.34260968, 0.19824979, 0.01881077, 0.20047083,\n",
       "        0.14992017],\n",
       "       [0.07643565, 0.12191626, 0.23480385, 0.0581734 , 0.15144248,\n",
       "        0.35722836],\n",
       "       [0.18374676, 0.22511622, 0.21990703, 0.08762464, 0.13997827,\n",
       "        0.14362707],\n",
       "       [0.09042372, 0.07490337, 0.11993952, 0.32814546, 0.20609004,\n",
       "        0.18049789],\n",
       "       [0.06222505, 0.08604227, 0.23216874, 0.12038342, 0.13869779,\n",
       "        0.36048272],\n",
       "       [0.20129571, 0.07440097, 0.10288965, 0.33612863, 0.16518646,\n",
       "        0.12009858],\n",
       "       [0.11991786, 0.11295186, 0.15331189, 0.25108305, 0.18558794,\n",
       "        0.1771474 ],\n",
       "       [0.19987876, 0.14967006, 0.22580464, 0.10045084, 0.1355942 ,\n",
       "        0.18860151],\n",
       "       [0.08298891, 0.14975232, 0.19168402, 0.10335425, 0.22071455,\n",
       "        0.25150596],\n",
       "       [0.23198729, 0.16906026, 0.22998653, 0.1186112 , 0.08854717,\n",
       "        0.16180755],\n",
       "       [0.1263869 , 0.16391656, 0.2580489 , 0.06296081, 0.13573427,\n",
       "        0.25295257],\n",
       "       [0.08808163, 0.10547438, 0.12352161, 0.24822801, 0.2355976 ,\n",
       "        0.19909676],\n",
       "       [0.1170163 , 0.218323  , 0.28624001, 0.07156478, 0.12109772,\n",
       "        0.18575819],\n",
       "       [0.12642292, 0.12524121, 0.18321562, 0.18454841, 0.19633113,\n",
       "        0.18424071],\n",
       "       [0.07410828, 0.09450909, 0.1405274 , 0.25067597, 0.23384236,\n",
       "        0.2063369 ],\n",
       "       [0.14046852, 0.22917209, 0.38215442, 0.02741924, 0.0638097 ,\n",
       "        0.15697603],\n",
       "       [0.16534633, 0.26556541, 0.35138302, 0.02934814, 0.06077419,\n",
       "        0.12758293],\n",
       "       [0.10797639, 0.37357656, 0.14044715, 0.06996262, 0.21140473,\n",
       "        0.09663255],\n",
       "       [0.07970245, 0.11575946, 0.15415158, 0.22472928, 0.22569295,\n",
       "        0.19996427],\n",
       "       [0.0526235 , 0.1057802 , 0.14980269, 0.23212956, 0.23219863,\n",
       "        0.22746541],\n",
       "       [0.14892673, 0.21833893, 0.4198016 , 0.01588944, 0.04756962,\n",
       "        0.14947368],\n",
       "       [0.08260026, 0.11442791, 0.23484849, 0.12832265, 0.18221544,\n",
       "        0.25758525],\n",
       "       [0.04071252, 0.38723499, 0.24424691, 0.01256163, 0.14061698,\n",
       "        0.17462697],\n",
       "       [0.02410322, 0.35826348, 0.28285946, 0.00600362, 0.12796406,\n",
       "        0.20080615],\n",
       "       [0.18467518, 0.26026503, 0.31806176, 0.        , 0.07930592,\n",
       "        0.15769212],\n",
       "       [0.0747562 , 0.33363849, 0.16313089, 0.02589051, 0.23871057,\n",
       "        0.16387334],\n",
       "       [0.10856926, 0.16914822, 0.22733221, 0.07763545, 0.18615204,\n",
       "        0.23116283],\n",
       "       [0.06496974, 0.11974998, 0.31650811, 0.05057075, 0.11519424,\n",
       "        0.33300719],\n",
       "       [0.06199536, 0.10243075, 0.14348559, 0.16287909, 0.21721674,\n",
       "        0.31199247],\n",
       "       [0.05437754, 0.34830542, 0.20102697, 0.03409931, 0.19631946,\n",
       "        0.16587129],\n",
       "       [0.14586122, 0.17395013, 0.24965642, 0.11668371, 0.11311972,\n",
       "        0.20072881],\n",
       "       [0.04510974, 0.15259091, 0.16584804, 0.09711044, 0.27866232,\n",
       "        0.26067856],\n",
       "       [0.05949789, 0.1203374 , 0.22053835, 0.08579835, 0.17566204,\n",
       "        0.33816597],\n",
       "       [0.24778347, 0.18493424, 0.25213904, 0.12227955, 0.07719494,\n",
       "        0.11566875],\n",
       "       [0.02826967, 0.37689392, 0.28737585, 0.        , 0.1424625 ,\n",
       "        0.16499806],\n",
       "       [0.26300913, 0.15969913, 0.21518711, 0.12584225, 0.10991991,\n",
       "        0.12634248],\n",
       "       [0.07879122, 0.17748607, 0.22680835, 0.11940166, 0.16163559,\n",
       "        0.23587711],\n",
       "       [0.0474765 , 0.08511178, 0.19280108, 0.15151333, 0.20443216,\n",
       "        0.31866516],\n",
       "       [0.1021726 , 0.16848741, 0.26515277, 0.05554371, 0.17351595,\n",
       "        0.23512756],\n",
       "       [0.13010442, 0.15877419, 0.23570268, 0.15081424, 0.13830715,\n",
       "        0.18629733],\n",
       "       [0.08976614, 0.13673433, 0.19056169, 0.17996204, 0.17568531,\n",
       "        0.2272905 ],\n",
       "       [0.13359609, 0.40163051, 0.10533118, 0.03403234, 0.24240908,\n",
       "        0.0830008 ],\n",
       "       [0.12866043, 0.30100409, 0.0756831 , 0.103129  , 0.28372942,\n",
       "        0.10779396],\n",
       "       [0.0498196 , 0.37235319, 0.21560577, 0.01502353, 0.17390285,\n",
       "        0.17329506],\n",
       "       [0.14962327, 0.23601076, 0.37041386, 0.02649332, 0.06624741,\n",
       "        0.15121139],\n",
       "       [0.04728605, 0.30415382, 0.1657288 , 0.03159949, 0.22622265,\n",
       "        0.22500919],\n",
       "       [0.17495297, 0.19306772, 0.23370193, 0.10849474, 0.12998832,\n",
       "        0.15979432],\n",
       "       [0.11095275, 0.21802178, 0.35950987, 0.04222178, 0.08587165,\n",
       "        0.18342217],\n",
       "       [0.03339958, 0.07403758, 0.18579699, 0.09248424, 0.18690866,\n",
       "        0.42737296],\n",
       "       [0.05058002, 0.12163786, 0.47951234, 0.07795293, 0.03945947,\n",
       "        0.23085738],\n",
       "       [0.09001799, 0.12410389, 0.19971441, 0.19471433, 0.20064741,\n",
       "        0.19080196],\n",
       "       [0.17840406, 0.14856867, 0.14862161, 0.20712079, 0.18197878,\n",
       "        0.13530609],\n",
       "       [0.03102731, 0.33417918, 0.28829326, 0.00787139, 0.1319143 ,\n",
       "        0.20671456],\n",
       "       [0.07257117, 0.24335369, 0.32026513, 0.04678495, 0.11989195,\n",
       "        0.1971331 ],\n",
       "       [0.09458732, 0.19947304, 0.34504503, 0.08098673, 0.13177019,\n",
       "        0.14813769],\n",
       "       [0.06751951, 0.23248765, 0.30766444, 0.03083252, 0.14799066,\n",
       "        0.21350523],\n",
       "       [0.20529292, 0.12115355, 0.17711295, 0.26743549, 0.09825591,\n",
       "        0.13074918],\n",
       "       [0.20580528, 0.21226089, 0.22307473, 0.08710357, 0.12680447,\n",
       "        0.14495105],\n",
       "       [0.17934696, 0.15473307, 0.24312503, 0.07841306, 0.14175852,\n",
       "        0.20262336],\n",
       "       [0.04887015, 0.1569108 , 0.28139368, 0.07277075, 0.16813126,\n",
       "        0.27192336],\n",
       "       [0.0679779 , 0.23091898, 0.2370223 , 0.09312552, 0.16317615,\n",
       "        0.20777915],\n",
       "       [0.08393841, 0.05797009, 0.11842078, 0.22998087, 0.29935395,\n",
       "        0.2103359 ],\n",
       "       [0.12993614, 0.13434961, 0.22234291, 0.11866965, 0.17763592,\n",
       "        0.21706577],\n",
       "       [0.14976144, 0.09631819, 0.10665368, 0.27197522, 0.19143788,\n",
       "        0.18385359],\n",
       "       [0.09738401, 0.19832625, 0.31916528, 0.06969183, 0.11771244,\n",
       "        0.1977202 ],\n",
       "       [0.07137796, 0.18617857, 0.22551008, 0.11611778, 0.16605994,\n",
       "        0.23475567],\n",
       "       [0.09969284, 0.16743713, 0.22315745, 0.09528351, 0.14469643,\n",
       "        0.26973264],\n",
       "       [0.11642021, 0.18952107, 0.25226977, 0.06041231, 0.17299812,\n",
       "        0.20837854],\n",
       "       [0.01302228, 0.31006259, 0.31805117, 0.        , 0.12578048,\n",
       "        0.23308348],\n",
       "       [0.01493836, 0.34985104, 0.29764368, 0.0031976 , 0.12798599,\n",
       "        0.20638333],\n",
       "       [0.08819849, 0.1800361 , 0.29377603, 0.08332861, 0.14235959,\n",
       "        0.21230117],\n",
       "       [0.26906271, 0.13230172, 0.17923134, 0.22591569, 0.08318874,\n",
       "        0.11029981],\n",
       "       [0.08407927, 0.18927071, 0.25038581, 0.07925464, 0.16505852,\n",
       "        0.23195105],\n",
       "       [0.02124516, 0.26244961, 0.17594381, 0.02297728, 0.25920532,\n",
       "        0.25817883],\n",
       "       [0.09335259, 0.19851637, 0.25147634, 0.09181651, 0.16432996,\n",
       "        0.20050824],\n",
       "       [0.0832595 , 0.16229975, 0.3301426 , 0.07574322, 0.11453948,\n",
       "        0.23401545],\n",
       "       [0.15964406, 0.16791589, 0.22965133, 0.15135121, 0.1292851 ,\n",
       "        0.1621524 ],\n",
       "       [0.08994345, 0.08630307, 0.12400333, 0.2254951 , 0.21751563,\n",
       "        0.25673942],\n",
       "       [0.02754419, 0.3284335 , 0.26189865, 0.03369092, 0.16883672,\n",
       "        0.17959602],\n",
       "       [0.09355262, 0.16765014, 0.21481357, 0.09320822, 0.20852599,\n",
       "        0.22224946],\n",
       "       [0.12445275, 0.20878692, 0.25992092, 0.06638031, 0.13870074,\n",
       "        0.20175837],\n",
       "       [0.27541769, 0.23680834, 0.21835604, 0.02988556, 0.0960355 ,\n",
       "        0.14349686],\n",
       "       [0.09685464, 0.30495365, 0.12888144, 0.05768907, 0.27846179,\n",
       "        0.1331594 ],\n",
       "       [0.08619164, 0.30826082, 0.09316102, 0.1229971 , 0.29618284,\n",
       "        0.09320657],\n",
       "       [0.15508448, 0.12116081, 0.10063624, 0.3026265 , 0.17685887,\n",
       "        0.1436331 ],\n",
       "       [0.05009762, 0.08033051, 0.12700127, 0.22987934, 0.25151977,\n",
       "        0.26117148],\n",
       "       [0.14596695, 0.13082811, 0.18104337, 0.18306719, 0.16038675,\n",
       "        0.19870763],\n",
       "       [0.23833294, 0.14481117, 0.14980614, 0.21112567, 0.1315997 ,\n",
       "        0.12432438],\n",
       "       [0.07680261, 0.23523819, 0.27267834, 0.051668  , 0.16354829,\n",
       "        0.20006457],\n",
       "       [0.25888198, 0.15539042, 0.1968317 , 0.17697221, 0.0898386 ,\n",
       "        0.12208509],\n",
       "       [0.16603492, 0.08365434, 0.14231599, 0.27473808, 0.17464774,\n",
       "        0.15860893],\n",
       "       [0.05982513, 0.11305372, 0.17330608, 0.1996382 , 0.24276254,\n",
       "        0.21141432],\n",
       "       [0.11163667, 0.15737206, 0.1472504 , 0.14256684, 0.21087697,\n",
       "        0.23029706],\n",
       "       [0.01502783, 0.37363016, 0.26775246, 0.        , 0.18758085,\n",
       "        0.1560087 ],\n",
       "       [0.15365239, 0.15608207, 0.24838065, 0.11787679, 0.13699464,\n",
       "        0.18701345],\n",
       "       [0.07961858, 0.34877278, 0.08913639, 0.02181451, 0.28394791,\n",
       "        0.17670984],\n",
       "       [0.04072331, 0.27588887, 0.17760906, 0.03099356, 0.27231311,\n",
       "        0.20247208],\n",
       "       [0.17595768, 0.17816993, 0.25649072, 0.05437244, 0.17398542,\n",
       "        0.16102381],\n",
       "       [0.08907588, 0.15151488, 0.28440957, 0.08495651, 0.12566296,\n",
       "        0.2643802 ],\n",
       "       [0.05972663, 0.06089107, 0.07248401, 0.18182619, 0.3993866 ,\n",
       "        0.22568551],\n",
       "       [0.02194203, 0.32944631, 0.27948849, 0.00683164, 0.14450126,\n",
       "        0.21779027],\n",
       "       [0.04769548, 0.11136776, 0.27916515, 0.09679979, 0.16143644,\n",
       "        0.30353537],\n",
       "       [0.09347154, 0.13525583, 0.21446628, 0.        , 0.23149475,\n",
       "        0.3253116 ],\n",
       "       [0.06300986, 0.07629477, 0.09580289, 0.23541711, 0.2936621 ,\n",
       "        0.23581328],\n",
       "       [0.03941322, 0.34672855, 0.26083241, 0.        , 0.18058238,\n",
       "        0.17244344],\n",
       "       [0.01842693, 0.03421179, 0.05374708, 0.28686082, 0.30991501,\n",
       "        0.29683838],\n",
       "       [0.11386041, 0.12019923, 0.09197644, 0.12998477, 0.31300946,\n",
       "        0.2309697 ],\n",
       "       [0.06943374, 0.09133862, 0.15799597, 0.10568881, 0.25794288,\n",
       "        0.31759998],\n",
       "       [0.11414176, 0.08744093, 0.16042071, 0.09198068, 0.20952118,\n",
       "        0.33649474],\n",
       "       [0.04319189, 0.11505649, 0.14742425, 0.        , 0.38509371,\n",
       "        0.30923367]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table_clac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55ae14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac3 = np.zeros((883, 6))\n",
    "# 888*6의 zero nd array를 생성 initialize\n",
    "\n",
    "for i in range(883):\n",
    "    try:\n",
    "        prob = data_concat[data_concat['clac3_nm_' + str(i)] >= 1].groupby('label')['label'].value_counts()\n",
    "        for j in range(len(prob.keys())):\n",
    "            if prob.keys()[j][0] == 'F20':\n",
    "                lookup_table_clac3[i, 0] = prob.values[j]\n",
    "            elif prob.keys()[j][0] == 'F30':\n",
    "                lookup_table_clac3[i, 1] = prob.values[j]\n",
    "            elif prob.keys()[j][0] == 'F40':\n",
    "                lookup_table_clac3[i, 2] = prob.values[j]\n",
    "            elif prob.keys()[j][0] == 'M20':\n",
    "                lookup_table_clac3[i, 3] = prob.values[j]\n",
    "            elif prob.keys()[j][0] == 'M30':\n",
    "                lookup_table_clac3[i, 4] = prob.values[j]\n",
    "            elif prob.keys()[j][0] == 'M40':\n",
    "                lookup_table_clac3[i, 5] = prob.values[j]\n",
    "    except:\n",
    "        lookup_table_clac3[i] = 1/weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f75cb593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.800e+01, 1.350e+02, 2.320e+02, 3.000e+00, 1.700e+01, 3.300e+01],\n",
       "       [2.400e+01, 2.210e+02, 2.980e+02, 0.000e+00, 1.800e+01, 3.900e+01],\n",
       "       [1.620e+02, 1.093e+03, 1.021e+03, 4.000e+01, 1.040e+02, 1.860e+02],\n",
       "       ...,\n",
       "       [0.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table_clac3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec24c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac3 = lookup_table_clac3 * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12e19c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac3 = lookup_table_clac3 / lookup_table_clac3.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0c38bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13835664, 0.14548446, 0.28831758, 0.07481844, 0.13796521,\n",
       "        0.21505768],\n",
       "       [0.07972002, 0.21727755, 0.33786185, 0.        , 0.13327016,\n",
       "        0.23187043],\n",
       "       [0.09684827, 0.1934031 , 0.2083384 , 0.1637977 , 0.13858443,\n",
       "        0.1990281 ],\n",
       "       ...,\n",
       "       [0.        , 0.30244584, 0.69755416, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table_clac3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9aaae565",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac1 = np.array(data_concat.iloc[:, 11:48]).dot(lookup_table_clac1)\n",
    "mat_clac1 = mat_clac1 / mat_clac1.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bbfa4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac1 = pd.DataFrame(mat_clac1)\n",
    "mat_clac1 = mat_clac1.rename(columns={0: 'given_clac1_F20_prob', 1:'given_clac1_F30_prob', 2:'given_clac1_F40_prob', 3:'given_clac1_M20_prob', 4:'given_clac1_M30_prob', 5:'given_clac1_M40_prob'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7fff0",
   "metadata": {},
   "source": [
    "- 본격 룩업 테이블에서 벡터 뽑아내는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e13efea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac1 = np.where(np.array(data_concat.iloc[:, 11:48]) >= 1, 1, 0).dot(lookup_table_clac1)\n",
    "mat_buy_clac1 = mat_buy_clac1 / mat_buy_clac1.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22d1e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac1 = pd.DataFrame(mat_buy_clac1)\n",
    "mat_buy_clac1 = mat_buy_clac1.rename(columns={0: 'buy_clac1_F20_prob', 1:'buy_clac1_F30_prob', 2:'buy_clac1_F40_prob', 3:'buy_clac1_M20_prob', 4:'buy_clac1_M30_prob', 5:'buy_clac1_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89da948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac2 = np.array(data_concat.iloc[:, 48:-884]).dot(lookup_table_clac2)\n",
    "mat_clac2 = mat_clac2 / mat_clac2.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a8826549",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac2 = pd.DataFrame(mat_clac2)\n",
    "mat_clac2 = mat_clac2.rename(columns={0: 'given_clac2_F20_prob', 1:'given_clac2_F30_prob', 2:'given_clac2_F40_prob', 3:'given_clac2_M20_prob', 4:'given_clac2_M30_prob', 5:'given_clac2_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da822240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac2 = np.where(np.array(data_concat.iloc[:, 48:-884]) >= 1, 1, 0).dot(lookup_table_clac2)\n",
    "mat_buy_clac2 = mat_buy_clac2 / mat_buy_clac2.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "895cfda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac2 = pd.DataFrame(mat_buy_clac2)\n",
    "mat_buy_clac2 = mat_buy_clac2.rename(columns={0: 'buy_clac2_F20_prob', 1:'buy_clac2_F30_prob', 2:'buy_clac2_F40_prob', 3:'buy_clac2_M20_prob', 4:'buy_clac2_M30_prob', 5:'buy_clac2_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45cbf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac3 = np.array(data_concat.iloc[:, -884:-1]).dot(lookup_table_clac3)\n",
    "mat_clac3 = mat_clac3 / mat_clac3.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de76bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac3 = pd.DataFrame(mat_clac3)\n",
    "mat_clac3 = mat_clac3.rename(columns={0: 'given_clac3_F20_prob', 1:'given_clac3_F30_prob', 2:'given_clac3_F40_prob', 3:'given_clac3_M20_prob', 4:'given_clac3_M30_prob', 5:'given_clac3_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "986f3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac3 = np.where(np.array(data_concat.iloc[:, -884:-1]) >= 1, 1, 0).dot(lookup_table_clac3)\n",
    "mat_buy_clac3 = mat_buy_clac3 / mat_buy_clac3.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca32dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac3 = pd.DataFrame(mat_buy_clac3)\n",
    "mat_buy_clac3 = mat_buy_clac3.rename(columns={0: 'buy_clac3_F20_prob', 1:'buy_clac3_F30_prob', 2:'buy_clac3_F40_prob', 3:'buy_clac3_M20_prob', 4:'buy_clac3_M30_prob', 5:'buy_clac3_M40_prob'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1531cc",
   "metadata": {},
   "source": [
    "clac1_embed = np.load('C:/Users/user/Desktop/DHCN-main/datasets/clac1_nm/embedding.npy')\n",
    "\n",
    "train_clac1_mean = np.array(data_concat.iloc[:, 11:48]).dot(clac1_embed)\n",
    "train_clac1_mean = train_clac1_mean / train_clac1_mean.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac1_weight = np.where(np.array(data_concat.iloc[:, 11:48]) >= 1, 1, 0).dot(clac1_embed)\n",
    "train_clac1_weight = train_clac1_weight / train_clac1_weight.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac1_mean = pd.DataFrame(train_clac1_mean)\n",
    "train_clac1_weight = pd.DataFrame(train_clac1_weight)\n",
    "train_clac1_mean.columns = ['clac1_mean_'+str(i) for i in range(5)]\n",
    "train_clac1_weight.columns = ['clac1_weight_'+str(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37faee51",
   "metadata": {},
   "source": [
    "clac2_embed = np.load('C:/Users/user/Desktop/DHCN-main/datasets/clac2_nm/embedding.npy')\n",
    "\n",
    "train_clac2_mean = np.array(data_concat.iloc[:, 48:-884]).dot(clac2_embed)\n",
    "train_clac2_mean = train_clac2_mean / train_clac2_mean.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac2_weight = np.where(np.array(data_concat.iloc[:, 48:-884]) >= 1, 1, 0).dot(clac2_embed)\n",
    "train_clac2_weight = train_clac2_weight / train_clac2_weight.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac2_mean = pd.DataFrame(train_clac2_mean)\n",
    "train_clac2_weight = pd.DataFrame(train_clac2_weight)\n",
    "train_clac2_mean.columns = ['clac2_mean_'+str(i) for i in range(10)]\n",
    "train_clac2_weight.columns = ['clac2_weight_'+str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e230e8c",
   "metadata": {},
   "source": [
    "clac3_embed = np.load('C:/Users/user/Desktop/DHCN-main/datasets/clac3_nm/embedding.npy')\n",
    "\n",
    "train_clac3_mean = np.array(data_concat.iloc[:, -884:-1]).dot(clac3_embed[:883])\n",
    "train_clac3_mean = train_clac3_mean / train_clac3_mean.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac3_weight = np.where(np.array(data_concat.iloc[:, -884:-1]) >= 1, 1, 0).dot(clac3_embed[:883])\n",
    "train_clac3_weight = train_clac3_weight / train_clac3_weight.sum(1).reshape(-1, 1)\n",
    "\n",
    "train_clac3_mean = pd.DataFrame(train_clac3_mean)\n",
    "train_clac3_weight = pd.DataFrame(train_clac3_weight)\n",
    "train_clac3_mean.columns = ['clac3_mean_'+str(i) for i in range(30)]\n",
    "train_clac3_weight.columns = ['clac3_weight_'+str(i) for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ff2ea6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat['gender'] = data_concat['label'].map(lambda x: x[:1])\n",
    "data_concat['age'] = data_concat['label'].map(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d95b222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_nm_876</th>\n",
       "      <th>clac3_nm_877</th>\n",
       "      <th>clac3_nm_878</th>\n",
       "      <th>clac3_nm_879</th>\n",
       "      <th>clac3_nm_880</th>\n",
       "      <th>clac3_nm_881</th>\n",
       "      <th>clac3_nm_882</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43250.000000</td>\n",
       "      <td>86500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>1844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F20</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>77777.777778</td>\n",
       "      <td>700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1311.111111</td>\n",
       "      <td>11800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>24225.000000</td>\n",
       "      <td>96900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>297.250000</td>\n",
       "      <td>1189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F20</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10550.000000</td>\n",
       "      <td>21100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>10098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>14325.625000</td>\n",
       "      <td>229210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>144.937500</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>4187.250000</td>\n",
       "      <td>66996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>263094</td>\n",
       "      <td>1</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>263095</td>\n",
       "      <td>2</td>\n",
       "      <td>122000.000000</td>\n",
       "      <td>244000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1828.000000</td>\n",
       "      <td>3656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>263096</td>\n",
       "      <td>3</td>\n",
       "      <td>28500.000000</td>\n",
       "      <td>85500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>768.0</td>\n",
       "      <td>4237.000000</td>\n",
       "      <td>12711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>263102</td>\n",
       "      <td>1</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1812.000000</td>\n",
       "      <td>1812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>263103</td>\n",
       "      <td>7</td>\n",
       "      <td>58628.571429</td>\n",
       "      <td>410400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3249.428571</td>\n",
       "      <td>22746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F30</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 1062 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  num_shopping      avg_price  total_price  avg_ct  total_ct  \\\n",
       "0             0             2   43250.000000        86500     1.0         2   \n",
       "1             1             9   77777.777778       700000     1.0         9   \n",
       "2             6             4   24225.000000        96900     1.0         4   \n",
       "3             9             2   10550.000000        21100     1.0         2   \n",
       "4            12            16   14325.625000       229210     1.0        16   \n",
       "...         ...           ...            ...          ...     ...       ...   \n",
       "149995   263094             1   10000.000000        10000     1.0         1   \n",
       "149996   263095             2  122000.000000       244000     1.0         2   \n",
       "149997   263096             3   28500.000000        85500     1.0         3   \n",
       "149998   263102             1    1080.000000         1080     1.0         1   \n",
       "149999   263103             7   58628.571429       410400     1.0         7   \n",
       "\n",
       "        avg_sess_view  total_sess_view  avg_sess_hr  total_sess_hr  ...  \\\n",
       "0           59.000000            118.0   922.000000           1844  ...   \n",
       "1          132.333333           1191.0  1311.111111          11800  ...   \n",
       "2           21.750000             87.0   297.250000           1189  ...   \n",
       "3          249.000000            498.0  5049.000000          10098  ...   \n",
       "4          144.937500           2319.0  4187.250000          66996  ...   \n",
       "...               ...              ...          ...            ...  ...   \n",
       "149995      66.000000             66.0   513.000000            513  ...   \n",
       "149996     220.500000            441.0  1828.000000           3656  ...   \n",
       "149997     256.000000            768.0  4237.000000          12711  ...   \n",
       "149998     188.000000            188.0  1812.000000           1812  ...   \n",
       "149999     280.000000           1960.0  3249.428571          22746  ...   \n",
       "\n",
       "        clac3_nm_876  clac3_nm_877  clac3_nm_878  clac3_nm_879  clac3_nm_880  \\\n",
       "0                0.0           0.0           0.0           0.0           0.0   \n",
       "1                0.0           0.0           0.0           0.0           0.0   \n",
       "2                0.0           0.0           0.0           0.0           0.0   \n",
       "3                0.0           0.0           0.0           0.0           0.0   \n",
       "4                0.0           0.0           0.0           0.0           0.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "149995           0.0           0.0           0.0           0.0           0.0   \n",
       "149996           0.0           0.0           0.0           0.0           0.0   \n",
       "149997           0.0           0.0           0.0           0.0           0.0   \n",
       "149998           0.0           0.0           0.0           0.0           0.0   \n",
       "149999           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        clac3_nm_881  clac3_nm_882  label  gender  age  \n",
       "0                0.0           0.0    F20       F   20  \n",
       "1                0.0           0.0    F30       F   30  \n",
       "2                0.0           0.0    F20       F   20  \n",
       "3                0.0           0.0    F30       F   30  \n",
       "4                0.0           0.0    F30       F   30  \n",
       "...              ...           ...    ...     ...  ...  \n",
       "149995           0.0           0.0    F30       F   30  \n",
       "149996           0.0           0.0    F30       F   30  \n",
       "149997           0.0           0.0    F30       F   30  \n",
       "149998           0.0           0.0    F30       F   30  \n",
       "149999           0.0           0.0    F30       F   30  \n",
       "\n",
       "[150000 rows x 1062 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5cfc02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {}\n",
    "for i, label in enumerate(['F20', 'F30', 'F40', 'M20', 'M30', 'M40']):\n",
    "    label_dic[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "067dc2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F20': 0, 'F30': 1, 'F40': 2, 'M20': 3, 'M30': 4, 'M40': 5}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "82967b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dic = {}\n",
    "for i, gender in enumerate(['F', 'M']):\n",
    "    gender_dic[gender] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92794e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': 0, 'M': 1}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb275122",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dic = {}\n",
    "for i, age in enumerate(['20', '30', '40']):\n",
    "    age_dic[age] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32f7ae4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20': 0, '30': 1, '40': 2}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c58fe205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat['label'] = data_concat['label'].map(lambda x: label_dic[x])\n",
    "data_concat['gender'] = data_concat['gender'].map(lambda x: gender_dic[x])\n",
    "data_concat['age'] = data_concat['age'].map(lambda x: age_dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b2fc77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52069"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_clac1).argmax(1) == data_concat['label'].values).sum()  # 50456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c9d74e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52940"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_buy_clac1).argmax(1) == data_concat['label'].values).sum()  # 51031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6510edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57561"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_clac2).argmax(1) == data_concat['label'].values).sum()  # 55530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9da88f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58263"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_buy_clac2).argmax(1) == data_concat['label'].values).sum()  # 55932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ff254c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58976"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_clac3).argmax(1) == data_concat['label'].values).sum()  # 56845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c684dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59451"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mat_buy_clac3).argmax(1) == data_concat['label'].values).sum()  # 57160"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e8948",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf37ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "679fa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(x, n):\n",
    "    lst = []\n",
    "    for i in x:\n",
    "        tmp = []\n",
    "        for j in range(n):\n",
    "            random.shuffle(i)\n",
    "            tmp += list(i)\n",
    "        lst.append(tmp)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a801d",
   "metadata": {},
   "source": [
    "#### Product code Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "679172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PD_C'] = df['PD_C'].astype('string')\n",
    "df_test['PD_C'] = df_test['PD_C'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ef437af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd_w2v = list(df.groupby('CLNT_ID')['PD_C'].unique()[y['CLNT_ID'].values])\n",
    "test_pd_w2v = list(df_test.groupby('CLNT_ID')['PD_C'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a77a7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['PD_C'].value_counts()[y['CLNT_ID'].values]\n",
    "kk = y['CLNT_ID'].values\n",
    "ww = df.groupby(['CLNT_ID', 'PD_C'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8cfd28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd_w2v.extend(test_pd_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4b75268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_w2v_input = oversample(train_pd_w2v, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "84351e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product code word2vec\n",
    "pd_w2v = word2vec.Word2Vec(sentences=pd_w2v_input,\n",
    "                           size=256,\n",
    "                           window=3,\n",
    "                           min_count=1,\n",
    "                           sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "599ab4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:05<00:00, 28873.49it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_pd_w2v[:-len(test_pd_w2v)]):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        pd_mean_vector.append(tmp)\n",
    "        \n",
    "pd_mean_vector = np.array(pd_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "caa8d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [04:30, 553.55it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_pd_w2v[:-len(test_pd_w2v)])):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        pd_unweight_vector.append(tmp)\n",
    "        \n",
    "pd_unweight_vector = np.array(pd_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55735eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [12:04, 207.08it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_pd_w2v[:-len(test_pd_w2v)])):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        pd_weight_vector.append(tmp)\n",
    "        \n",
    "pd_weight_vector = np.array(pd_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d265b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd_mean = pd_mean_vector\n",
    "train_pd_unweight = pd_unweight_vector\n",
    "train_pd_weight = pd_weight_vector\n",
    "\n",
    "train_pd_mean = pd.DataFrame(train_pd_mean)\n",
    "train_pd_unweight = pd.DataFrame(train_pd_unweight)\n",
    "train_pd_weight = pd.DataFrame(train_pd_weight)\n",
    "\n",
    "train_pd_mean.columns = ['pd_mean_'+str(i) for i in range(256)]\n",
    "train_pd_unweight.columns = ['pd_unweight_'+str(i) for i in range(256)]\n",
    "train_pd_weight.columns = ['pd_weight_'+str(i) for i in range(256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b898ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PD_BRA_NM'] = df['PD_BRA_NM'].astype('string')\n",
    "df_test['PD_BRA_NM'] = df_test['PD_BRA_NM'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca9b03",
   "metadata": {},
   "source": [
    "#### brand name word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a7332d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bra_w2v = list(df.groupby('CLNT_ID')['PD_BRA_NM'].unique()[y['CLNT_ID'].values])\n",
    "test_bra_w2v = list(df_test.groupby('CLNT_ID')['PD_BRA_NM'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ed975b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['PD_BRA_NM'].value_counts()[y['CLNT_ID'].values]\n",
    "## tt : kk에 해당하는 product name count 값\n",
    "kk = y['CLNT_ID'].values\n",
    "## kk : client id list\n",
    "ww = df.groupby(['CLNT_ID', 'PD_BRA_NM'])['KWD_NM'].count()\n",
    "## client id, brand name로 그룹핑한 keyword들마다의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43024593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bra_w2v.extend(test_bra_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "79b0e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bra_w2v_input = oversample(train_bra_w2v, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0eb2afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bra_w2v = word2vec.Word2Vec(sentences=bra_w2v_input,\n",
    "                           size=128,\n",
    "                           window=3,\n",
    "                           min_count=1,\n",
    "                           sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2f6e043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:03<00:00, 40477.85it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_bra_w2v[:-len(test_bra_w2v)]):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        bra_mean_vector.append(tmp)\n",
    "        \n",
    "bra_mean_vector = np.array(bra_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "15843fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [03:17, 758.58it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_bra_w2v[:-len(test_bra_w2v)])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        bra_unweight_vector.append(tmp)\n",
    "        \n",
    "bra_unweight_vector = np.array(bra_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8c681e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [08:57, 278.88it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_bra_w2v[:-len(test_bra_w2v)])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        bra_weight_vector.append(tmp)\n",
    "        \n",
    "bra_weight_vector = np.array(bra_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f2588b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bra_mean = bra_mean_vector\n",
    "train_bra_unweight = bra_unweight_vector\n",
    "train_bra_weight = bra_weight_vector\n",
    "\n",
    "train_bra_mean = pd.DataFrame(train_bra_mean)\n",
    "train_bra_unweight = pd.DataFrame(train_bra_unweight)\n",
    "train_bra_weight = pd.DataFrame(train_bra_weight)\n",
    "\n",
    "train_bra_mean.columns = ['bra_mean_'+str(i) for i in range(128)]\n",
    "train_bra_unweight.columns = ['bra_unweight_'+str(i) for i in range(128)]\n",
    "train_bra_weight.columns = ['bra_weight_'+str(i) for i in range(128)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112577d",
   "metadata": {},
   "source": [
    "#### keyword_name word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "94381590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KWD_NM'] = df['KWD_NM'].astype('string')\n",
    "df_test['KWD_NM'] = df_test['KWD_NM'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "57f72872",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwd_w2v = list(df.groupby('CLNT_ID')['KWD_NM'].unique()[y['CLNT_ID'].values])\n",
    "test_kwd_w2v = list(df_test.groupby('CLNT_ID')['KWD_NM'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9f92b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['KWD_NM'].value_counts()[y['CLNT_ID'].values]\n",
    "kk = y['CLNT_ID'].values\n",
    "ww = df.groupby(['CLNT_ID', 'KWD_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2d5c3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwd_w2v.extend(test_kwd_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "56b24183",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_w2v_input = oversample(train_kwd_w2v, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ff2ebe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_w2v = word2vec.Word2Vec(sentences=kwd_w2v_input,\n",
    "                           size=128,\n",
    "                           window=3,\n",
    "                           min_count=1,\n",
    "                           sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4f36884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:06<00:00, 23661.92it/s]\n"
     ]
    }
   ],
   "source": [
    "kwd_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_kwd_w2v[:-len(test_kwd_w2v)]):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        kwd_mean_vector.append(tmp)\n",
    "        \n",
    "kwd_mean_vector = np.array(kwd_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "419f4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [05:42, 437.61it/s]\n"
     ]
    }
   ],
   "source": [
    "kwd_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_kwd_w2v[:-len(test_kwd_w2v)])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        kwd_unweight_vector.append(tmp)\n",
    "        \n",
    "kwd_unweight_vector = np.array(kwd_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1d118501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [15:38, 159.76it/s]\n"
     ]
    }
   ],
   "source": [
    "kwd_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_kwd_w2v[:-len(test_kwd_w2v)])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        kwd_weight_vector.append(tmp)\n",
    "        \n",
    "kwd_weight_vector = np.array(kwd_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5c4506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwd_mean = kwd_mean_vector\n",
    "train_kwd_unweight = kwd_unweight_vector\n",
    "train_kwd_weight = kwd_weight_vector\n",
    "\n",
    "train_kwd_mean = pd.DataFrame(train_kwd_mean)\n",
    "train_kwd_unweight = pd.DataFrame(train_kwd_unweight)\n",
    "train_kwd_weight = pd.DataFrame(train_kwd_weight)\n",
    "\n",
    "train_kwd_mean.columns = ['kwd_mean_'+str(i) for i in range(128)]\n",
    "train_kwd_weight.columns = ['kwd_unweight_'+str(i) for i in range(128)]\n",
    "train_kwd_weight.columns = ['kwd_weight_'+str(i) for i in range(128)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e8e07",
   "metadata": {},
   "source": [
    "#### CLAC3_NM word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "07245d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLAC3_NM'] = df['CLAC3_NM'].astype('string')\n",
    "df_test['CLAC3_NM'] = df_test['CLAC3_NM'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0510c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac3_w2v = list(df.groupby('CLNT_ID')['CLAC3_NM'].unique()[y['CLNT_ID'].values])\n",
    "test_clac3_w2v = list(df_test.groupby('CLNT_ID')['CLAC3_NM'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c6f369c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['CLAC3_NM'].value_counts()[y['CLNT_ID'].values]\n",
    "kk = y['CLNT_ID'].values\n",
    "ww = df.groupby(['CLNT_ID', 'CLAC3_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "437b89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac3_w2v.extend(test_clac3_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "02cba583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_w2v_input = oversample(train_clac3_w2v, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f149751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_w2v = word2vec.Word2Vec(sentences=clac3_w2v_input,\n",
    "                              size=30,\n",
    "                              window=3,\n",
    "                              min_count=1,\n",
    "                              sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b1578c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:03<00:00, 40631.44it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac3_w2v[:-len(test_clac3_w2v)]):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        clac3_mean_vector.append(tmp)\n",
    "        \n",
    "clac3_mean_vector = np.array(clac3_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "92a067f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:05, 26368.42it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac3_w2v[:-len(test_clac3_w2v)])):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word] * clac3_matrix[i, clac3_nm_dic[word]]\n",
    "                cnt += clac3_matrix[i, clac3_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac3_unweight_vector.append(tmp)\n",
    "        \n",
    "clac3_unweight_vector = np.array(clac3_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7730c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [08:58, 278.79it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac3_w2v[:-len(test_clac3_w2v)])):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac3_weight_vector.append(tmp)\n",
    "        \n",
    "clac3_weight_vector = np.array(clac3_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "004d7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac3_mean = clac3_mean_vector\n",
    "train_clac3_unweight = clac3_unweight_vector\n",
    "train_clac3_weight = clac3_weight_vector\n",
    "\n",
    "train_clac3_mean = pd.DataFrame(train_clac3_mean)\n",
    "train_clac3_unweight = pd.DataFrame(train_clac3_unweight)\n",
    "train_clac3_weight = pd.DataFrame(train_clac3_weight)\n",
    "\n",
    "train_clac3_mean.columns = ['clac3_mean_'+str(i) for i in range(30)]\n",
    "train_clac3_unweight.columns = ['clac3_unweight_'+str(i) for i in range(30)]\n",
    "train_clac3_weight.columns = ['clac3_weight_'+str(i) for i in range(30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028e695",
   "metadata": {},
   "source": [
    "#### CLAC2_NM word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ecadbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLAC2_NM'] = df['CLAC2_NM'].astype('string')\n",
    "df_test['CLAC2_NM'] = df_test['CLAC2_NM'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a59ae34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac2_w2v = list(df.groupby('CLNT_ID')['CLAC2_NM'].unique()[y['CLNT_ID'].values])\n",
    "test_clac2_w2v = list(df_test.groupby('CLNT_ID')['CLAC2_NM'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b60cfa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['CLAC2_NM'].value_counts()[y['CLNT_ID'].values]\n",
    "kk = y['CLNT_ID'].values\n",
    "ww = df.groupby(['CLNT_ID', 'CLAC2_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cf4ceae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac2_w2v.extend(test_clac2_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2863af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_w2v_input = oversample(train_clac2_w2v, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2d9b95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_w2v = word2vec.Word2Vec(sentences=clac2_w2v_input,\n",
    "                              size=10,\n",
    "                              window=3,\n",
    "                              min_count=1,\n",
    "                              sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d5ff3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:03<00:00, 45694.59it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac2_w2v[:-len(test_clac2_w2v)]):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac2_mean_vector.append(tmp)\n",
    "        \n",
    "clac2_mean_vector = np.array(clac2_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ec10150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:04, 31135.69it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac2_w2v[:-len(test_clac2_w2v)])):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word] * clac2_matrix[i, clac2_nm_dic[word]]\n",
    "                cnt += clac2_matrix[i, clac2_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac2_unweight_vector.append(tmp)\n",
    "        \n",
    "clac2_unweight_vector = np.array(clac2_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6fa51fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [07:40, 325.76it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac2_w2v[:-len(test_clac2_w2v)])):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac2_weight_vector.append(tmp)\n",
    "        \n",
    "clac2_weight_vector = np.array(clac2_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fd98bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac2_mean = clac2_mean_vector\n",
    "train_clac2_unweight = clac2_unweight_vector\n",
    "train_clac2_weight = clac2_weight_vector\n",
    "\n",
    "train_clac2_mean = pd.DataFrame(train_clac2_mean)\n",
    "train_clac2_unweight = pd.DataFrame(train_clac2_unweight)\n",
    "train_clac2_weight = pd.DataFrame(train_clac2_weight)\n",
    "\n",
    "train_clac2_mean.columns = ['clac2_mean_'+str(i) for i in range(10)]\n",
    "train_clac2_unweight.columns = ['clac2_unweight_'+str(i) for i in range(10)]\n",
    "train_clac2_weight.columns = ['clac2_weight_'+str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6504e",
   "metadata": {},
   "source": [
    "#### CLAC1_NM word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "367ecb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLAC1_NM'] = df['CLAC1_NM'].astype('string')\n",
    "df_test['CLAC1_NM'] = df_test['CLAC1_NM'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ac8f8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac1_w2v = list(df.groupby('CLNT_ID')['CLAC1_NM'].unique()[y['CLNT_ID'].values])\n",
    "test_clac1_w2v = list(df_test.groupby('CLNT_ID')['CLAC1_NM'].unique()[df_test['CLNT_ID'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aea18506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df.groupby('CLNT_ID')['CLAC1_NM'].value_counts()[y['CLNT_ID'].values]\n",
    "kk = y['CLNT_ID'].values\n",
    "ww = df.groupby(['CLNT_ID', 'CLAC1_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0beede32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac1_w2v.extend(test_clac1_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fbb3d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_w2v_input = oversample(train_clac1_w2v, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5a12b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_w2v = word2vec.Word2Vec(sentences=clac1_w2v_input,\n",
    "                              size=5,\n",
    "                              window=3,\n",
    "                              min_count=1,\n",
    "                              sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fbc46c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:02<00:00, 56621.56it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac1_w2v[:-len(test_clac1_w2v)]):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac1_mean_vector.append(tmp)\n",
    "        \n",
    "clac1_mean_vector = np.array(clac1_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "719d5d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:03, 38266.09it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac1_w2v[:-len(test_clac1_w2v)])):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word] * clac1_matrix[i, clac1_nm_dic[word]]\n",
    "                cnt += clac1_matrix[i, clac1_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac1_unweight_vector.append(tmp)\n",
    "        \n",
    "clac1_unweight_vector = np.array(clac1_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0bc1c0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [05:59, 416.81it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac1_w2v[:-len(test_clac1_w2v)])):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac1_weight_vector.append(tmp)\n",
    "        \n",
    "clac1_weight_vector = np.array(clac1_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "31d2ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clac1_mean = clac1_mean_vector\n",
    "train_clac1_unweight = clac1_unweight_vector\n",
    "train_clac1_weight = clac1_weight_vector\n",
    "\n",
    "train_clac1_mean = pd.DataFrame(train_clac1_mean)\n",
    "train_clac1_unweight = pd.DataFrame(train_clac1_unweight)\n",
    "train_clac1_weight = pd.DataFrame(train_clac1_weight)\n",
    "\n",
    "train_clac1_mean.columns = ['clac1_mean_'+str(i) for i in range(5)]\n",
    "train_clac1_unweight.columns = ['clac1_unweight_'+str(i) for i in range(5)]\n",
    "train_clac1_weight.columns = ['clac1_weight_'+str(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "06233ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([data_concat.iloc[:, 1:11], mat_clac1, mat_buy_clac1, mat_clac2, mat_buy_clac2, mat_clac3, mat_buy_clac3, train_pd_mean, train_bra_mean, train_kwd_mean, train_clac1_mean, train_clac2_mean, train_clac3_mean, train_pd_unweight, train_bra_unweight, train_kwd_unweight, train_clac1_unweight, train_clac2_unweight, train_clac3_unweight, train_pd_weight, train_bra_weight, train_kwd_weight, train_clac1_weight, train_clac2_weight, train_clac3_weight, data_concat.iloc[:, -3:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5ac08b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>avg_shopping_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_weight_23</th>\n",
       "      <th>clac3_weight_24</th>\n",
       "      <th>clac3_weight_25</th>\n",
       "      <th>clac3_weight_26</th>\n",
       "      <th>clac3_weight_27</th>\n",
       "      <th>clac3_weight_28</th>\n",
       "      <th>clac3_weight_29</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>43250.000000</td>\n",
       "      <td>86500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025476</td>\n",
       "      <td>-0.358678</td>\n",
       "      <td>-0.186819</td>\n",
       "      <td>0.192818</td>\n",
       "      <td>0.434122</td>\n",
       "      <td>-0.107545</td>\n",
       "      <td>0.063859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>77777.777778</td>\n",
       "      <td>700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1311.111111</td>\n",
       "      <td>11800</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513720</td>\n",
       "      <td>0.286228</td>\n",
       "      <td>0.180560</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.273483</td>\n",
       "      <td>0.445723</td>\n",
       "      <td>-0.301021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24225.000000</td>\n",
       "      <td>96900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>297.250000</td>\n",
       "      <td>1189</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164428</td>\n",
       "      <td>0.047147</td>\n",
       "      <td>0.298240</td>\n",
       "      <td>-0.305354</td>\n",
       "      <td>0.558061</td>\n",
       "      <td>0.195794</td>\n",
       "      <td>0.031537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10550.000000</td>\n",
       "      <td>21100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>10098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527290</td>\n",
       "      <td>-0.260950</td>\n",
       "      <td>0.230153</td>\n",
       "      <td>-0.477711</td>\n",
       "      <td>-0.060666</td>\n",
       "      <td>-0.118800</td>\n",
       "      <td>-0.559288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>14325.625000</td>\n",
       "      <td>229210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>144.937500</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>4187.250000</td>\n",
       "      <td>66996</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257740</td>\n",
       "      <td>-0.554550</td>\n",
       "      <td>-0.216515</td>\n",
       "      <td>-0.312947</td>\n",
       "      <td>-0.201764</td>\n",
       "      <td>0.072622</td>\n",
       "      <td>-0.378338</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>513</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105944</td>\n",
       "      <td>-1.130829</td>\n",
       "      <td>0.387124</td>\n",
       "      <td>0.286016</td>\n",
       "      <td>0.126334</td>\n",
       "      <td>0.426996</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>2</td>\n",
       "      <td>122000.000000</td>\n",
       "      <td>244000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1828.000000</td>\n",
       "      <td>3656</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719438</td>\n",
       "      <td>-0.272537</td>\n",
       "      <td>-0.384826</td>\n",
       "      <td>-0.215291</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>-0.127866</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>3</td>\n",
       "      <td>28500.000000</td>\n",
       "      <td>85500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>768.0</td>\n",
       "      <td>4237.000000</td>\n",
       "      <td>12711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675275</td>\n",
       "      <td>-0.445863</td>\n",
       "      <td>-0.125119</td>\n",
       "      <td>0.457581</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>-0.033372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1812.000000</td>\n",
       "      <td>1812</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113508</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.235095</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.776254</td>\n",
       "      <td>-0.536355</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>7</td>\n",
       "      <td>58628.571429</td>\n",
       "      <td>410400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3249.428571</td>\n",
       "      <td>22746</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240615</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>-0.318051</td>\n",
       "      <td>0.228597</td>\n",
       "      <td>0.180339</td>\n",
       "      <td>0.140052</td>\n",
       "      <td>-0.201356</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 1720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_shopping      avg_price  total_price  avg_ct  total_ct  \\\n",
       "0                  2   43250.000000        86500     1.0         2   \n",
       "1                  9   77777.777778       700000     1.0         9   \n",
       "2                  4   24225.000000        96900     1.0         4   \n",
       "3                  2   10550.000000        21100     1.0         2   \n",
       "4                 16   14325.625000       229210     1.0        16   \n",
       "...              ...            ...          ...     ...       ...   \n",
       "149995             1   10000.000000        10000     1.0         1   \n",
       "149996             2  122000.000000       244000     1.0         2   \n",
       "149997             3   28500.000000        85500     1.0         3   \n",
       "149998             1    1080.000000         1080     1.0         1   \n",
       "149999             7   58628.571429       410400     1.0         7   \n",
       "\n",
       "        avg_sess_view  total_sess_view  avg_sess_hr  total_sess_hr  \\\n",
       "0           59.000000            118.0   922.000000           1844   \n",
       "1          132.333333           1191.0  1311.111111          11800   \n",
       "2           21.750000             87.0   297.250000           1189   \n",
       "3          249.000000            498.0  5049.000000          10098   \n",
       "4          144.937500           2319.0  4187.250000          66996   \n",
       "...               ...              ...          ...            ...   \n",
       "149995      66.000000             66.0   513.000000            513   \n",
       "149996     220.500000            441.0  1828.000000           3656   \n",
       "149997     256.000000            768.0  4237.000000          12711   \n",
       "149998     188.000000            188.0  1812.000000           1812   \n",
       "149999     280.000000           1960.0  3249.428571          22746   \n",
       "\n",
       "        avg_shopping_interval  ...  clac3_weight_23  clac3_weight_24  \\\n",
       "0                    0.000000  ...        -0.025476        -0.358678   \n",
       "1                    3.625000  ...        -0.513720         0.286228   \n",
       "2                    5.666667  ...        -0.164428         0.047147   \n",
       "3                    0.000000  ...        -0.527290        -0.260950   \n",
       "4                    4.200000  ...        -0.257740        -0.554550   \n",
       "...                       ...  ...              ...              ...   \n",
       "149995             183.000000  ...        -0.105944        -1.130829   \n",
       "149996              83.000000  ...        -0.719438        -0.272537   \n",
       "149997               0.000000  ...        -0.675275        -0.445863   \n",
       "149998             183.000000  ...         0.113508         0.063089   \n",
       "149999               4.666667  ...        -0.240615         0.007781   \n",
       "\n",
       "        clac3_weight_25  clac3_weight_26  clac3_weight_27  clac3_weight_28  \\\n",
       "0             -0.186819         0.192818         0.434122        -0.107545   \n",
       "1              0.180560         0.383307         0.273483         0.445723   \n",
       "2              0.298240        -0.305354         0.558061         0.195794   \n",
       "3              0.230153        -0.477711        -0.060666        -0.118800   \n",
       "4             -0.216515        -0.312947        -0.201764         0.072622   \n",
       "...                 ...              ...              ...              ...   \n",
       "149995         0.387124         0.286016         0.126334         0.426996   \n",
       "149996        -0.384826        -0.215291        -0.045238        -0.005138   \n",
       "149997        -0.125119         0.457581         0.359894         0.512207   \n",
       "149998         0.235095         0.160695         0.016483         0.776254   \n",
       "149999        -0.318051         0.228597         0.180339         0.140052   \n",
       "\n",
       "        clac3_weight_29  label  gender  age  \n",
       "0              0.063859      0       0    0  \n",
       "1             -0.301021      1       0    1  \n",
       "2              0.031537      0       0    0  \n",
       "3             -0.559288      1       0    1  \n",
       "4             -0.378338      1       0    1  \n",
       "...                 ...    ...     ...  ...  \n",
       "149995         0.029120      1       0    1  \n",
       "149996        -0.127866      1       0    1  \n",
       "149997        -0.033372      1       0    1  \n",
       "149998        -0.536355      1       0    1  \n",
       "149999        -0.201356      1       0    1  \n",
       "\n",
       "[150000 rows x 1720 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bf63c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = data_concat.loc[:, list(data_concat.columns[:-3].values) + ['gender', 'age', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6b28671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>avg_shopping_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_weight_23</th>\n",
       "      <th>clac3_weight_24</th>\n",
       "      <th>clac3_weight_25</th>\n",
       "      <th>clac3_weight_26</th>\n",
       "      <th>clac3_weight_27</th>\n",
       "      <th>clac3_weight_28</th>\n",
       "      <th>clac3_weight_29</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>43250.000000</td>\n",
       "      <td>86500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025476</td>\n",
       "      <td>-0.358678</td>\n",
       "      <td>-0.186819</td>\n",
       "      <td>0.192818</td>\n",
       "      <td>0.434122</td>\n",
       "      <td>-0.107545</td>\n",
       "      <td>0.063859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>77777.777778</td>\n",
       "      <td>700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1311.111111</td>\n",
       "      <td>11800</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513720</td>\n",
       "      <td>0.286228</td>\n",
       "      <td>0.180560</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.273483</td>\n",
       "      <td>0.445723</td>\n",
       "      <td>-0.301021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24225.000000</td>\n",
       "      <td>96900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>297.250000</td>\n",
       "      <td>1189</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164428</td>\n",
       "      <td>0.047147</td>\n",
       "      <td>0.298240</td>\n",
       "      <td>-0.305354</td>\n",
       "      <td>0.558061</td>\n",
       "      <td>0.195794</td>\n",
       "      <td>0.031537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10550.000000</td>\n",
       "      <td>21100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>10098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527290</td>\n",
       "      <td>-0.260950</td>\n",
       "      <td>0.230153</td>\n",
       "      <td>-0.477711</td>\n",
       "      <td>-0.060666</td>\n",
       "      <td>-0.118800</td>\n",
       "      <td>-0.559288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>14325.625000</td>\n",
       "      <td>229210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>144.937500</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>4187.250000</td>\n",
       "      <td>66996</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257740</td>\n",
       "      <td>-0.554550</td>\n",
       "      <td>-0.216515</td>\n",
       "      <td>-0.312947</td>\n",
       "      <td>-0.201764</td>\n",
       "      <td>0.072622</td>\n",
       "      <td>-0.378338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>513</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105944</td>\n",
       "      <td>-1.130829</td>\n",
       "      <td>0.387124</td>\n",
       "      <td>0.286016</td>\n",
       "      <td>0.126334</td>\n",
       "      <td>0.426996</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>2</td>\n",
       "      <td>122000.000000</td>\n",
       "      <td>244000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1828.000000</td>\n",
       "      <td>3656</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719438</td>\n",
       "      <td>-0.272537</td>\n",
       "      <td>-0.384826</td>\n",
       "      <td>-0.215291</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>-0.127866</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>3</td>\n",
       "      <td>28500.000000</td>\n",
       "      <td>85500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>768.0</td>\n",
       "      <td>4237.000000</td>\n",
       "      <td>12711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675275</td>\n",
       "      <td>-0.445863</td>\n",
       "      <td>-0.125119</td>\n",
       "      <td>0.457581</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>-0.033372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1812.000000</td>\n",
       "      <td>1812</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113508</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.235095</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.776254</td>\n",
       "      <td>-0.536355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>7</td>\n",
       "      <td>58628.571429</td>\n",
       "      <td>410400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3249.428571</td>\n",
       "      <td>22746</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240615</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>-0.318051</td>\n",
       "      <td>0.228597</td>\n",
       "      <td>0.180339</td>\n",
       "      <td>0.140052</td>\n",
       "      <td>-0.201356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 1720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_shopping      avg_price  total_price  avg_ct  total_ct  \\\n",
       "0                  2   43250.000000        86500     1.0         2   \n",
       "1                  9   77777.777778       700000     1.0         9   \n",
       "2                  4   24225.000000        96900     1.0         4   \n",
       "3                  2   10550.000000        21100     1.0         2   \n",
       "4                 16   14325.625000       229210     1.0        16   \n",
       "...              ...            ...          ...     ...       ...   \n",
       "149995             1   10000.000000        10000     1.0         1   \n",
       "149996             2  122000.000000       244000     1.0         2   \n",
       "149997             3   28500.000000        85500     1.0         3   \n",
       "149998             1    1080.000000         1080     1.0         1   \n",
       "149999             7   58628.571429       410400     1.0         7   \n",
       "\n",
       "        avg_sess_view  total_sess_view  avg_sess_hr  total_sess_hr  \\\n",
       "0           59.000000            118.0   922.000000           1844   \n",
       "1          132.333333           1191.0  1311.111111          11800   \n",
       "2           21.750000             87.0   297.250000           1189   \n",
       "3          249.000000            498.0  5049.000000          10098   \n",
       "4          144.937500           2319.0  4187.250000          66996   \n",
       "...               ...              ...          ...            ...   \n",
       "149995      66.000000             66.0   513.000000            513   \n",
       "149996     220.500000            441.0  1828.000000           3656   \n",
       "149997     256.000000            768.0  4237.000000          12711   \n",
       "149998     188.000000            188.0  1812.000000           1812   \n",
       "149999     280.000000           1960.0  3249.428571          22746   \n",
       "\n",
       "        avg_shopping_interval  ...  clac3_weight_23  clac3_weight_24  \\\n",
       "0                    0.000000  ...        -0.025476        -0.358678   \n",
       "1                    3.625000  ...        -0.513720         0.286228   \n",
       "2                    5.666667  ...        -0.164428         0.047147   \n",
       "3                    0.000000  ...        -0.527290        -0.260950   \n",
       "4                    4.200000  ...        -0.257740        -0.554550   \n",
       "...                       ...  ...              ...              ...   \n",
       "149995             183.000000  ...        -0.105944        -1.130829   \n",
       "149996              83.000000  ...        -0.719438        -0.272537   \n",
       "149997               0.000000  ...        -0.675275        -0.445863   \n",
       "149998             183.000000  ...         0.113508         0.063089   \n",
       "149999               4.666667  ...        -0.240615         0.007781   \n",
       "\n",
       "        clac3_weight_25  clac3_weight_26  clac3_weight_27  clac3_weight_28  \\\n",
       "0             -0.186819         0.192818         0.434122        -0.107545   \n",
       "1              0.180560         0.383307         0.273483         0.445723   \n",
       "2              0.298240        -0.305354         0.558061         0.195794   \n",
       "3              0.230153        -0.477711        -0.060666        -0.118800   \n",
       "4             -0.216515        -0.312947        -0.201764         0.072622   \n",
       "...                 ...              ...              ...              ...   \n",
       "149995         0.387124         0.286016         0.126334         0.426996   \n",
       "149996        -0.384826        -0.215291        -0.045238        -0.005138   \n",
       "149997        -0.125119         0.457581         0.359894         0.512207   \n",
       "149998         0.235095         0.160695         0.016483         0.776254   \n",
       "149999        -0.318051         0.228597         0.180339         0.140052   \n",
       "\n",
       "        clac3_weight_29  gender  age  label  \n",
       "0              0.063859       0    0      0  \n",
       "1             -0.301021       0    1      1  \n",
       "2              0.031537       0    0      0  \n",
       "3             -0.559288       0    1      1  \n",
       "4             -0.378338       0    1      1  \n",
       "...                 ...     ...  ...    ...  \n",
       "149995         0.029120       0    1      1  \n",
       "149996        -0.127866       0    1      1  \n",
       "149997        -0.033372       0    1      1  \n",
       "149998        -0.536355       0    1      1  \n",
       "149999        -0.201356       0    1      1  \n",
       "\n",
       "[150000 rows x 1720 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2b57866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23f65054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_concat = pd.read_csv('train.csv')\n",
    "train_stat = pd.read_csv('stat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "593218cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([train_stat.iloc[:, 1:], data_concat.iloc[:, 10:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474f362",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "356e787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6243c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22f65ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data_concat.iloc[:, :-1], data_concat.iloc[:, -1], test_size=0.2, stratify=data_concat.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "809ce01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.iloc[:, :-2])\n",
    "X_valid_scaled = scaler.transform(X_valid.iloc[:, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a75201ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 14us/sample - loss: 1.2876 - accuracy: 0.4757 - val_loss: 1.1988 - val_accuracy: 0.5098\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.2033 - accuracy: 0.5061 - val_loss: 1.1858 - val_accuracy: 0.5216\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1860 - accuracy: 0.5135 - val_loss: 1.1775 - val_accuracy: 0.5181\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1728 - accuracy: 0.5189 - val_loss: 1.1708 - val_accuracy: 0.5203\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1614 - accuracy: 0.5215 - val_loss: 1.1714 - val_accuracy: 0.5197\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1547 - accuracy: 0.5244 - val_loss: 1.1686 - val_accuracy: 0.5238\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1477 - accuracy: 0.5273 - val_loss: 1.1698 - val_accuracy: 0.5240\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1396 - accuracy: 0.5285 - val_loss: 1.1671 - val_accuracy: 0.5233\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1311 - accuracy: 0.5331 - val_loss: 1.1669 - val_accuracy: 0.5263\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1241 - accuracy: 0.5363 - val_loss: 1.1680 - val_accuracy: 0.5226\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1168 - accuracy: 0.5394 - val_loss: 1.1749 - val_accuracy: 0.5262\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1100 - accuracy: 0.5412 - val_loss: 1.1693 - val_accuracy: 0.5222\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0998 - accuracy: 0.5455 - val_loss: 1.1746 - val_accuracy: 0.5241\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0928 - accuracy: 0.5491 - val_loss: 1.1764 - val_accuracy: 0.5183\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0833 - accuracy: 0.5515 - val_loss: 1.1762 - val_accuracy: 0.5215\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0752 - accuracy: 0.5545 - val_loss: 1.1845 - val_accuracy: 0.5182\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0647 - accuracy: 0.5591 - val_loss: 1.1855 - val_accuracy: 0.5202\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0572 - accuracy: 0.5630 - val_loss: 1.1898 - val_accuracy: 0.5177\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0477 - accuracy: 0.5668 - val_loss: 1.1938 - val_accuracy: 0.5160\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0414 - accuracy: 0.5679 - val_loss: 1.1938 - val_accuracy: 0.5190\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0305 - accuracy: 0.5741 - val_loss: 1.1996 - val_accuracy: 0.5205\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0219 - accuracy: 0.5776 - val_loss: 1.2094 - val_accuracy: 0.5138\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0132 - accuracy: 0.5825 - val_loss: 1.2100 - val_accuracy: 0.5175\n",
      "Epoch 24/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0028 - accuracy: 0.5836 - val_loss: 1.2150 - val_accuracy: 0.5166\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model1.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))  # 1.1643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c80cd38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 20us/sample - loss: 1.2883 - accuracy: 0.4768 - val_loss: 1.1937 - val_accuracy: 0.5115\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2037 - accuracy: 0.5047 - val_loss: 1.1856 - val_accuracy: 0.5169\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1870 - accuracy: 0.5116 - val_loss: 1.1714 - val_accuracy: 0.5220\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1753 - accuracy: 0.5175 - val_loss: 1.1733 - val_accuracy: 0.5183\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1671 - accuracy: 0.5186 - val_loss: 1.1650 - val_accuracy: 0.5235\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1574 - accuracy: 0.5222 - val_loss: 1.1639 - val_accuracy: 0.5215\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1482 - accuracy: 0.5269 - val_loss: 1.1697 - val_accuracy: 0.5242\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1407 - accuracy: 0.5287 - val_loss: 1.1659 - val_accuracy: 0.5224\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1326 - accuracy: 0.5319 - val_loss: 1.1650 - val_accuracy: 0.5239\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1299 - accuracy: 0.5336 - val_loss: 1.1712 - val_accuracy: 0.5198\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1207 - accuracy: 0.5364 - val_loss: 1.1685 - val_accuracy: 0.5249\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1113 - accuracy: 0.5391 - val_loss: 1.1700 - val_accuracy: 0.5238\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1016 - accuracy: 0.5449 - val_loss: 1.1721 - val_accuracy: 0.5237\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0938 - accuracy: 0.5469 - val_loss: 1.1760 - val_accuracy: 0.5224\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0920 - accuracy: 0.5491 - val_loss: 1.1775 - val_accuracy: 0.5231\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0815 - accuracy: 0.5513 - val_loss: 1.1788 - val_accuracy: 0.5232\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0699 - accuracy: 0.5575 - val_loss: 1.1816 - val_accuracy: 0.5170\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0605 - accuracy: 0.5599 - val_loss: 1.1851 - val_accuracy: 0.5183\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0544 - accuracy: 0.5630 - val_loss: 1.1870 - val_accuracy: 0.5181\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0445 - accuracy: 0.5677 - val_loss: 1.1968 - val_accuracy: 0.5166\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0313 - accuracy: 0.5734 - val_loss: 1.1980 - val_accuracy: 0.5177\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model2.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc024788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 13us/sample - loss: 1.2943 - accuracy: 0.4743 - val_loss: 1.1932 - val_accuracy: 0.5142\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2040 - accuracy: 0.5047 - val_loss: 1.1846 - val_accuracy: 0.5208\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1854 - accuracy: 0.5118 - val_loss: 1.1800 - val_accuracy: 0.5165\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1731 - accuracy: 0.5170 - val_loss: 1.1680 - val_accuracy: 0.5226\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1612 - accuracy: 0.5207 - val_loss: 1.1703 - val_accuracy: 0.5201\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1582 - accuracy: 0.5248 - val_loss: 1.1647 - val_accuracy: 0.5209\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1482 - accuracy: 0.5284 - val_loss: 1.1669 - val_accuracy: 0.5240\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1471 - accuracy: 0.5282 - val_loss: 1.1637 - val_accuracy: 0.5226\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1350 - accuracy: 0.5323 - val_loss: 1.1623 - val_accuracy: 0.5271\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1264 - accuracy: 0.5356 - val_loss: 1.1682 - val_accuracy: 0.5209\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1188 - accuracy: 0.5386 - val_loss: 1.1714 - val_accuracy: 0.5229\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1104 - accuracy: 0.5401 - val_loss: 1.1712 - val_accuracy: 0.5230\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1029 - accuracy: 0.5439 - val_loss: 1.1687 - val_accuracy: 0.5228\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0960 - accuracy: 0.5459 - val_loss: 1.1703 - val_accuracy: 0.5251\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0880 - accuracy: 0.5498 - val_loss: 1.1787 - val_accuracy: 0.5218\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0809 - accuracy: 0.5530 - val_loss: 1.1783 - val_accuracy: 0.5242\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0695 - accuracy: 0.5559 - val_loss: 1.1844 - val_accuracy: 0.5206\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0642 - accuracy: 0.5592 - val_loss: 1.1886 - val_accuracy: 0.5204\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0524 - accuracy: 0.5621 - val_loss: 1.1909 - val_accuracy: 0.5228\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0445 - accuracy: 0.5690 - val_loss: 1.1981 - val_accuracy: 0.5181\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0343 - accuracy: 0.5729 - val_loss: 1.1950 - val_accuracy: 0.5169\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0262 - accuracy: 0.5761 - val_loss: 1.2008 - val_accuracy: 0.5169\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0172 - accuracy: 0.5792 - val_loss: 1.2079 - val_accuracy: 0.5141\n",
      "Epoch 24/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0089 - accuracy: 0.5843 - val_loss: 1.2081 - val_accuracy: 0.5143\n"
     ]
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model3.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d61ea0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 13us/sample - loss: 1.2951 - accuracy: 0.4740 - val_loss: 1.1908 - val_accuracy: 0.5107\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2020 - accuracy: 0.5061 - val_loss: 1.1779 - val_accuracy: 0.5170\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1874 - accuracy: 0.5119 - val_loss: 1.1815 - val_accuracy: 0.5165\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1766 - accuracy: 0.5186 - val_loss: 1.1692 - val_accuracy: 0.5212\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1630 - accuracy: 0.5203 - val_loss: 1.1670 - val_accuracy: 0.5247\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1538 - accuracy: 0.5250 - val_loss: 1.1682 - val_accuracy: 0.5216\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1473 - accuracy: 0.5275 - val_loss: 1.1663 - val_accuracy: 0.5242\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1396 - accuracy: 0.5300 - val_loss: 1.1675 - val_accuracy: 0.5204\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1312 - accuracy: 0.5339 - val_loss: 1.1672 - val_accuracy: 0.5237\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1266 - accuracy: 0.5357 - val_loss: 1.1663 - val_accuracy: 0.5231\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1186 - accuracy: 0.5383 - val_loss: 1.1713 - val_accuracy: 0.5235\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1114 - accuracy: 0.5422 - val_loss: 1.1750 - val_accuracy: 0.5208\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1013 - accuracy: 0.5446 - val_loss: 1.1702 - val_accuracy: 0.5206\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0930 - accuracy: 0.5503 - val_loss: 1.1706 - val_accuracy: 0.5206\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0846 - accuracy: 0.5520 - val_loss: 1.1801 - val_accuracy: 0.5181\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0779 - accuracy: 0.5547 - val_loss: 1.1785 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0696 - accuracy: 0.5565 - val_loss: 1.1873 - val_accuracy: 0.5112\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0579 - accuracy: 0.5625 - val_loss: 1.1875 - val_accuracy: 0.5191\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0497 - accuracy: 0.5654 - val_loss: 1.1907 - val_accuracy: 0.5200\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0421 - accuracy: 0.5694 - val_loss: 1.1976 - val_accuracy: 0.5152\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0335 - accuracy: 0.5727 - val_loss: 1.1989 - val_accuracy: 0.5132\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0248 - accuracy: 0.5777 - val_loss: 1.1998 - val_accuracy: 0.5153\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0148 - accuracy: 0.5830 - val_loss: 1.2058 - val_accuracy: 0.5125\n",
      "Epoch 24/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0064 - accuracy: 0.5848 - val_loss: 1.2153 - val_accuracy: 0.5112\n",
      "Epoch 25/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0071 - accuracy: 0.5852 - val_loss: 1.2159 - val_accuracy: 0.5074\n"
     ]
    }
   ],
   "source": [
    "model4 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model4.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1aff97c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 13us/sample - loss: 1.2930 - accuracy: 0.4740 - val_loss: 1.1976 - val_accuracy: 0.5134\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2040 - accuracy: 0.5046 - val_loss: 1.1800 - val_accuracy: 0.5182\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1853 - accuracy: 0.5137 - val_loss: 1.1729 - val_accuracy: 0.5201\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1721 - accuracy: 0.5186 - val_loss: 1.1771 - val_accuracy: 0.5190\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1631 - accuracy: 0.5195 - val_loss: 1.1690 - val_accuracy: 0.5244\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1563 - accuracy: 0.5236 - val_loss: 1.1703 - val_accuracy: 0.5247\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1507 - accuracy: 0.5268 - val_loss: 1.1635 - val_accuracy: 0.5251\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1403 - accuracy: 0.5305 - val_loss: 1.1666 - val_accuracy: 0.5208\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1331 - accuracy: 0.5331 - val_loss: 1.1676 - val_accuracy: 0.5223\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1230 - accuracy: 0.5363 - val_loss: 1.1728 - val_accuracy: 0.5177\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1192 - accuracy: 0.5374 - val_loss: 1.1720 - val_accuracy: 0.5211\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1171 - accuracy: 0.5386 - val_loss: 1.1727 - val_accuracy: 0.5219\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1050 - accuracy: 0.5420 - val_loss: 1.1697 - val_accuracy: 0.5249\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0959 - accuracy: 0.5462 - val_loss: 1.1731 - val_accuracy: 0.5203\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0887 - accuracy: 0.5499 - val_loss: 1.1766 - val_accuracy: 0.5233\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0786 - accuracy: 0.5535 - val_loss: 1.1817 - val_accuracy: 0.5207\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0806 - accuracy: 0.5548 - val_loss: 1.1892 - val_accuracy: 0.5153\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0698 - accuracy: 0.5584 - val_loss: 1.1856 - val_accuracy: 0.5199\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0542 - accuracy: 0.5616 - val_loss: 1.1866 - val_accuracy: 0.5206\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0485 - accuracy: 0.5668 - val_loss: 1.1923 - val_accuracy: 0.5160\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0379 - accuracy: 0.5697 - val_loss: 1.1964 - val_accuracy: 0.5183\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0314 - accuracy: 0.5734 - val_loss: 1.2004 - val_accuracy: 0.5174\n"
     ]
    }
   ],
   "source": [
    "model5 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model5.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model5.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42e8dec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 14us/sample - loss: 1.2860 - accuracy: 0.4771 - val_loss: 1.1983 - val_accuracy: 0.5124\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2021 - accuracy: 0.5062 - val_loss: 1.1923 - val_accuracy: 0.5175\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1859 - accuracy: 0.5118 - val_loss: 1.1751 - val_accuracy: 0.5204\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1713 - accuracy: 0.5184 - val_loss: 1.1688 - val_accuracy: 0.5214\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1660 - accuracy: 0.5202 - val_loss: 1.1671 - val_accuracy: 0.5232\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1557 - accuracy: 0.5253 - val_loss: 1.1602 - val_accuracy: 0.5221\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1473 - accuracy: 0.5271 - val_loss: 1.1706 - val_accuracy: 0.5229\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1395 - accuracy: 0.5309 - val_loss: 1.1674 - val_accuracy: 0.5188\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1376 - accuracy: 0.5309 - val_loss: 1.1697 - val_accuracy: 0.5215\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1259 - accuracy: 0.5347 - val_loss: 1.1650 - val_accuracy: 0.5224\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1203 - accuracy: 0.5387 - val_loss: 1.1711 - val_accuracy: 0.5225\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1100 - accuracy: 0.5409 - val_loss: 1.1714 - val_accuracy: 0.5224\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1002 - accuracy: 0.5456 - val_loss: 1.1767 - val_accuracy: 0.5248\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0932 - accuracy: 0.5472 - val_loss: 1.1780 - val_accuracy: 0.5170\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0930 - accuracy: 0.5481 - val_loss: 1.1783 - val_accuracy: 0.5206\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0795 - accuracy: 0.5529 - val_loss: 1.1865 - val_accuracy: 0.5171\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0686 - accuracy: 0.5576 - val_loss: 1.1858 - val_accuracy: 0.5170\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0589 - accuracy: 0.5628 - val_loss: 1.1871 - val_accuracy: 0.5176\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0502 - accuracy: 0.5652 - val_loss: 1.1943 - val_accuracy: 0.5133\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0434 - accuracy: 0.5677 - val_loss: 1.1954 - val_accuracy: 0.5207\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0350 - accuracy: 0.5709 - val_loss: 1.2038 - val_accuracy: 0.5110\n"
     ]
    }
   ],
   "source": [
    "model6 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model6.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model6.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48e04a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 14us/sample - loss: 1.2899 - accuracy: 0.4717 - val_loss: 1.1929 - val_accuracy: 0.5090\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2027 - accuracy: 0.5056 - val_loss: 1.1800 - val_accuracy: 0.5172\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1840 - accuracy: 0.5141 - val_loss: 1.1750 - val_accuracy: 0.5214\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1723 - accuracy: 0.5174 - val_loss: 1.1762 - val_accuracy: 0.5196\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1613 - accuracy: 0.5229 - val_loss: 1.1698 - val_accuracy: 0.5234\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1548 - accuracy: 0.5259 - val_loss: 1.1739 - val_accuracy: 0.5193\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1455 - accuracy: 0.5266 - val_loss: 1.1678 - val_accuracy: 0.5217\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1393 - accuracy: 0.5294 - val_loss: 1.1656 - val_accuracy: 0.5208\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1313 - accuracy: 0.5330 - val_loss: 1.1665 - val_accuracy: 0.5224\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1235 - accuracy: 0.5358 - val_loss: 1.1748 - val_accuracy: 0.5201\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1161 - accuracy: 0.5399 - val_loss: 1.1681 - val_accuracy: 0.5221\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1091 - accuracy: 0.5411 - val_loss: 1.1781 - val_accuracy: 0.5160\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1024 - accuracy: 0.5455 - val_loss: 1.1723 - val_accuracy: 0.5224\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0929 - accuracy: 0.5491 - val_loss: 1.1795 - val_accuracy: 0.5196\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0837 - accuracy: 0.5517 - val_loss: 1.1800 - val_accuracy: 0.5174\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0739 - accuracy: 0.5544 - val_loss: 1.1837 - val_accuracy: 0.5157\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0686 - accuracy: 0.5574 - val_loss: 1.1911 - val_accuracy: 0.5174\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0572 - accuracy: 0.5621 - val_loss: 1.1934 - val_accuracy: 0.5146\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0492 - accuracy: 0.5667 - val_loss: 1.1964 - val_accuracy: 0.5127\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0404 - accuracy: 0.5687 - val_loss: 1.1958 - val_accuracy: 0.5181\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0308 - accuracy: 0.5747 - val_loss: 1.2008 - val_accuracy: 0.5140\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0209 - accuracy: 0.5799 - val_loss: 1.2083 - val_accuracy: 0.5166\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0167 - accuracy: 0.5801 - val_loss: 1.2089 - val_accuracy: 0.5119\n"
     ]
    }
   ],
   "source": [
    "model7 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model7.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model7.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "863c14af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 14us/sample - loss: 1.2908 - accuracy: 0.4766 - val_loss: 1.1975 - val_accuracy: 0.5047\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2042 - accuracy: 0.5065 - val_loss: 1.1811 - val_accuracy: 0.5183\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1839 - accuracy: 0.5130 - val_loss: 1.1677 - val_accuracy: 0.5185\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1734 - accuracy: 0.5169 - val_loss: 1.1724 - val_accuracy: 0.5209\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1649 - accuracy: 0.5195 - val_loss: 1.1728 - val_accuracy: 0.5232\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1558 - accuracy: 0.5231 - val_loss: 1.1637 - val_accuracy: 0.5260\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1482 - accuracy: 0.5286 - val_loss: 1.1695 - val_accuracy: 0.5235\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1399 - accuracy: 0.5296 - val_loss: 1.1628 - val_accuracy: 0.5224\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1327 - accuracy: 0.5322 - val_loss: 1.1750 - val_accuracy: 0.5127\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1247 - accuracy: 0.5349 - val_loss: 1.1735 - val_accuracy: 0.5205\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1175 - accuracy: 0.5389 - val_loss: 1.1686 - val_accuracy: 0.5248\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1107 - accuracy: 0.5418 - val_loss: 1.1730 - val_accuracy: 0.5185\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1035 - accuracy: 0.5439 - val_loss: 1.1769 - val_accuracy: 0.5096\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0947 - accuracy: 0.5478 - val_loss: 1.1767 - val_accuracy: 0.5184\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0897 - accuracy: 0.5495 - val_loss: 1.1793 - val_accuracy: 0.5207\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0793 - accuracy: 0.5536 - val_loss: 1.1799 - val_accuracy: 0.5187\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0668 - accuracy: 0.5591 - val_loss: 1.1837 - val_accuracy: 0.5190\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0584 - accuracy: 0.5622 - val_loss: 1.1871 - val_accuracy: 0.5213\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0512 - accuracy: 0.5643 - val_loss: 1.1939 - val_accuracy: 0.5163\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0417 - accuracy: 0.5699 - val_loss: 1.1928 - val_accuracy: 0.5194\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0342 - accuracy: 0.5737 - val_loss: 1.2008 - val_accuracy: 0.5174\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0234 - accuracy: 0.5777 - val_loss: 1.2110 - val_accuracy: 0.5142\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0175 - accuracy: 0.5799 - val_loss: 1.2115 - val_accuracy: 0.5156\n"
     ]
    }
   ],
   "source": [
    "model8 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model8.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model8.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "010881d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 13us/sample - loss: 1.2875 - accuracy: 0.4755 - val_loss: 1.1945 - val_accuracy: 0.5144\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.2027 - accuracy: 0.5052 - val_loss: 1.1797 - val_accuracy: 0.5165\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1842 - accuracy: 0.5137 - val_loss: 1.1764 - val_accuracy: 0.5203\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1724 - accuracy: 0.5181 - val_loss: 1.1704 - val_accuracy: 0.5241\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1661 - accuracy: 0.5199 - val_loss: 1.1699 - val_accuracy: 0.5212\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1567 - accuracy: 0.5242 - val_loss: 1.1631 - val_accuracy: 0.5213\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1517 - accuracy: 0.5276 - val_loss: 1.1663 - val_accuracy: 0.5245\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1416 - accuracy: 0.5274 - val_loss: 1.1630 - val_accuracy: 0.5251\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1335 - accuracy: 0.5320 - val_loss: 1.1681 - val_accuracy: 0.5204\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1273 - accuracy: 0.5350 - val_loss: 1.1664 - val_accuracy: 0.5211\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1158 - accuracy: 0.5380 - val_loss: 1.1703 - val_accuracy: 0.5230\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1097 - accuracy: 0.5409 - val_loss: 1.1713 - val_accuracy: 0.5218\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1031 - accuracy: 0.5430 - val_loss: 1.1724 - val_accuracy: 0.5214\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0940 - accuracy: 0.5475 - val_loss: 1.1744 - val_accuracy: 0.5197\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0854 - accuracy: 0.5513 - val_loss: 1.1804 - val_accuracy: 0.5191\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0781 - accuracy: 0.5543 - val_loss: 1.1814 - val_accuracy: 0.5195\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0726 - accuracy: 0.5570 - val_loss: 1.1851 - val_accuracy: 0.5197\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0636 - accuracy: 0.5588 - val_loss: 1.1912 - val_accuracy: 0.5189\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0512 - accuracy: 0.5653 - val_loss: 1.1921 - val_accuracy: 0.5203\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0437 - accuracy: 0.5669 - val_loss: 1.1958 - val_accuracy: 0.5175\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0358 - accuracy: 0.5716 - val_loss: 1.1995 - val_accuracy: 0.5165\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0263 - accuracy: 0.5764 - val_loss: 1.1990 - val_accuracy: 0.5162\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0182 - accuracy: 0.5780 - val_loss: 1.2084 - val_accuracy: 0.5071\n"
     ]
    }
   ],
   "source": [
    "model9 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model9.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model9.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1fa73dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1000\n",
      "120000/120000 [==============================] - 2s 13us/sample - loss: 1.2838 - accuracy: 0.4745 - val_loss: 1.1907 - val_accuracy: 0.5142\n",
      "Epoch 2/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.2023 - accuracy: 0.5058 - val_loss: 1.1769 - val_accuracy: 0.5170\n",
      "Epoch 3/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1862 - accuracy: 0.5131 - val_loss: 1.1721 - val_accuracy: 0.5176\n",
      "Epoch 4/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1715 - accuracy: 0.5184 - val_loss: 1.1686 - val_accuracy: 0.5201\n",
      "Epoch 5/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1621 - accuracy: 0.5195 - val_loss: 1.1705 - val_accuracy: 0.5208\n",
      "Epoch 6/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1539 - accuracy: 0.5249 - val_loss: 1.1696 - val_accuracy: 0.5246\n",
      "Epoch 7/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.1470 - accuracy: 0.5261 - val_loss: 1.1696 - val_accuracy: 0.5193\n",
      "Epoch 8/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1382 - accuracy: 0.5307 - val_loss: 1.1715 - val_accuracy: 0.5221\n",
      "Epoch 9/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1349 - accuracy: 0.5309 - val_loss: 1.1713 - val_accuracy: 0.5199\n",
      "Epoch 10/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1246 - accuracy: 0.5346 - val_loss: 1.1696 - val_accuracy: 0.5232\n",
      "Epoch 11/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1153 - accuracy: 0.5385 - val_loss: 1.1677 - val_accuracy: 0.5244\n",
      "Epoch 12/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1089 - accuracy: 0.5404 - val_loss: 1.1711 - val_accuracy: 0.5219\n",
      "Epoch 13/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.1016 - accuracy: 0.5443 - val_loss: 1.1720 - val_accuracy: 0.5249\n",
      "Epoch 14/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0937 - accuracy: 0.5474 - val_loss: 1.1824 - val_accuracy: 0.5193\n",
      "Epoch 15/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0828 - accuracy: 0.5512 - val_loss: 1.1799 - val_accuracy: 0.5218\n",
      "Epoch 16/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0754 - accuracy: 0.5535 - val_loss: 1.1849 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0659 - accuracy: 0.5568 - val_loss: 1.1852 - val_accuracy: 0.5185\n",
      "Epoch 18/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0600 - accuracy: 0.5611 - val_loss: 1.1873 - val_accuracy: 0.5173\n",
      "Epoch 19/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0513 - accuracy: 0.5650 - val_loss: 1.1919 - val_accuracy: 0.5188\n",
      "Epoch 20/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0414 - accuracy: 0.5688 - val_loss: 1.1965 - val_accuracy: 0.5144\n",
      "Epoch 21/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0318 - accuracy: 0.5723 - val_loss: 1.2072 - val_accuracy: 0.5132\n",
      "Epoch 22/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0246 - accuracy: 0.5766 - val_loss: 1.2045 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "120000/120000 [==============================] - 1s 9us/sample - loss: 1.0138 - accuracy: 0.5798 - val_loss: 1.2109 - val_accuracy: 0.5128\n",
      "Epoch 24/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 1.0076 - accuracy: 0.5838 - val_loss: 1.2152 - val_accuracy: 0.5164\n",
      "Epoch 25/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 0.9975 - accuracy: 0.5874 - val_loss: 1.2164 - val_accuracy: 0.5154\n",
      "Epoch 26/1000\n",
      "120000/120000 [==============================] - 1s 10us/sample - loss: 0.9899 - accuracy: 0.5902 - val_loss: 1.2231 - val_accuracy: 0.5160\n"
     ]
    }
   ],
   "source": [
    "model10 = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Dense(512, input_shape=[1175,]),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(512),\n",
    "     tf.keras.layers.ReLU(),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model10.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer='adam',\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model10.fit(X_train_scaled[:, :-557], y_train, batch_size=512, epochs=1000, callbacks=[early_stop],\n",
    "                     validation_data=(X_valid_scaled[:, :-557], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47cd3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_valid_scaled[:, :-557])\n",
    "pred2 = model2.predict(X_valid_scaled[:, :-557])\n",
    "pred3 = model3.predict(X_valid_scaled[:, :-557])\n",
    "pred4 = model4.predict(X_valid_scaled[:, :-557])\n",
    "pred5 = model5.predict(X_valid_scaled[:, :-557])\n",
    "pred6 = model6.predict(X_valid_scaled[:, :-557])\n",
    "pred7 = model7.predict(X_valid_scaled[:, :-557])\n",
    "pred8 = model8.predict(X_valid_scaled[:, :-557])\n",
    "pred9 = model9.predict(X_valid_scaled[:, :-557])\n",
    "pred10 = model10.predict(X_valid_scaled[:, :-557])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b7396ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1524238256888075"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mlp = (pred1 + pred2 + pred3 + pred4 + pred5 + pred6 + pred7 + pred8 + pred9 + pred10) / 10\n",
    "log_loss(y_valid, pred_mlp)  # 1.1524238256888075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e240df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "daee5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_fraction = 0.7  # 0.7\n",
    "feature_fraction = 0.9  # 0.9\n",
    "n_model = 10  # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dfb4f363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.835240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 2 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.719457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 3 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.793521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 4 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.748699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 5 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.689484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 6 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.815211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 7 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.769633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 8 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.716562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 9 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.788493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n",
      "Training 10 model\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.829176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 438357\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 1732\n",
      "[LightGBM] [Info] Start training from score -2.135518\n",
      "[LightGBM] [Info] Start training from score -0.918084\n",
      "[LightGBM] [Info] Start training from score -1.060618\n",
      "[LightGBM] [Info] Start training from score -4.059943\n",
      "[LightGBM] [Info] Start training from score -2.937149\n",
      "[LightGBM] [Info] Start training from score -2.717722\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for i in range(n_model):\n",
    "    print('Training %d model'%(i+1))\n",
    "    d_train = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.1\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'multiclass'\n",
    "    params['num_classes'] = 6\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['bagging_fraction'] = bagging_fraction\n",
    "    params['bagging_freq'] = 1\n",
    "    params['bagging_seed'] = i+1\n",
    "    params['feature_fraction'] = feature_fraction\n",
    "    params['feature_fraction_seed'] = i+1\n",
    "    params['max_depth'] = 10\n",
    "    params['num_leaves'] = 32\n",
    "    params['lambda_l2'] = 24\n",
    "    #params['max_bin'] = 64\n",
    "\n",
    "    clf = lgb.train(params, d_train, 100)\n",
    "    model_dict['model_'+str(i)] = clf  # 1.1645216634935185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a03af564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1590863715913093"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lgb = np.zeros((len(y_valid), 6))\n",
    "for i in range(n_model):\n",
    "    pred_lgb += model_dict['model_'+str(i)].predict(X_valid_scaled)\n",
    "pred_lgb = pred_lgb / n_model   \n",
    "\n",
    "log_loss(y_valid, pred_lgb)  # 1.1590863715913093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f3938a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred_mlp + pred_lgb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c938aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.57072546e-03, 5.57289383e-02, 8.97353582e-01, 2.22444551e-04,\n",
       "        1.85221898e-03, 4.12720756e-02],\n",
       "       [6.92599978e-02, 2.74608884e-01, 6.21422029e-01, 1.17425804e-03,\n",
       "        7.18916246e-03, 2.63456698e-02],\n",
       "       [2.28711285e-01, 2.70365329e-01, 1.99727329e-01, 1.52601798e-01,\n",
       "        8.85579810e-02, 6.00362813e-02],\n",
       "       ...,\n",
       "       [6.39873077e-02, 3.29615641e-01, 4.69737381e-01, 2.69650596e-03,\n",
       "        3.71115569e-02, 9.68516209e-02],\n",
       "       [1.86162125e-01, 3.25978530e-01, 3.96424325e-01, 1.27466881e-02,\n",
       "        3.73194014e-02, 4.13689147e-02],\n",
       "       [5.89294910e-01, 3.01848296e-01, 8.59463698e-02, 7.33122963e-03,\n",
       "        7.73586397e-03, 7.84330762e-03]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "031963dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.147216886499985"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid, pred)  # 1.147216886499985"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a091b25",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "51388f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "clnt_id = df_test['CLNT_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "23da5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['PD_BUY_AM'] = df_test['PD_BUY_AM'].astype('string')\n",
    "df_test['PD_BUY_CT'] = df_test['PD_BUY_CT'].astype('string')\n",
    "df_test['TOT_SESS_HR_V'] = df_test['TOT_SESS_HR_V'].astype('string')\n",
    "\n",
    "df_test['PD_BUY_AM'] = df_test['PD_BUY_AM'].map(lambda x: x.replace(',', ''))\n",
    "df_test['PD_BUY_CT'] = df_test['PD_BUY_CT'].map(lambda x: x.replace(',', ''))\n",
    "df_test['TOT_SESS_HR_V'] = df_test['TOT_SESS_HR_V'].map(lambda x: x.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9756b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['PD_BUY_AM'] = df_test['PD_BUY_AM'].astype('int')\n",
    "df_test['PD_BUY_CT'] = df_test['PD_BUY_CT'].astype('int')\n",
    "df_test['TOT_SESS_HR_V'] = df_test['TOT_SESS_HR_V'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "97032d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SESS_DT'] = df_test['SESS_DT'].map(lambda x: date.fromisoformat(str(x)[:4] + '-' + str(x)[4:6] + '-' + str(x)[6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2c169221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 113104/113104 [13:29<00:00, 139.73it/s]\n"
     ]
    }
   ],
   "source": [
    "num_shoppings = []\n",
    "avg_prices = []\n",
    "total_prices = []\n",
    "avg_cts = []\n",
    "total_cts = []\n",
    "avg_sess_views = []\n",
    "total_sess_views = []\n",
    "avg_sess_hrs = []\n",
    "total_sess_hrs = []\n",
    "avg_shopping_intervals = []\n",
    "main_devices = []\n",
    "pd_cs = []\n",
    "clac1_nms = []\n",
    "clac2_nms = []\n",
    "clac3_nms = []\n",
    "\n",
    "for i in tqdm(range(len(clnt_id))):\n",
    "    temp_df_test = df_test[df_test['CLNT_ID'] == clnt_id[i]]\n",
    "    temp_df_test = temp_df_test.sort_values(by=['SESS_DT', 'HITS_SEQ', 'PD_C'])\n",
    "    temp_df_test = temp_df_test[~temp_df_test.duplicated(subset=['SESS_ID', 'HITS_SEQ', 'PD_C'], keep='last')]\n",
    "    \n",
    "    num_shopping = len(temp_df_test)\n",
    "    avg_price, total_price, avg_ct, total_ct = calc_avg_total_price_ct(temp_df_test)\n",
    "    avg_sess_view = temp_df_test['TOT_PAG_VIEW_CT'].values.mean()\n",
    "    total_sess_view = temp_df_test['TOT_PAG_VIEW_CT'].values.sum()\n",
    "    avg_sess_hr = temp_df_test['TOT_SESS_HR_V'].values.mean()\n",
    "    total_sess_hr = temp_df_test['TOT_SESS_HR_V'].values.sum()\n",
    "    avg_shopping_interval = calc_avg_shopping_interval(temp_df_test)\n",
    "    main_device = scipy.stats.mode(temp_df_test['DVC_CTG_NM'].values).mode[0]\n",
    "    pd_c = temp_df_test['PD_C'].values\n",
    "    clac1_nm = temp_df_test['CLAC1_NM'].values\n",
    "    clac2_nm = temp_df_test['CLAC2_NM'].values\n",
    "    clac3_nm = temp_df_test['CLAC3_NM'].values\n",
    "    \n",
    "    num_shoppings.append(num_shopping)\n",
    "    avg_prices.append(avg_price)\n",
    "    total_prices.append(total_price)\n",
    "    avg_cts.append(avg_ct)\n",
    "    total_cts.append(total_ct)\n",
    "    avg_sess_views.append(avg_sess_view)\n",
    "    total_sess_views.append(total_sess_view)\n",
    "    avg_sess_hrs.append(avg_sess_hr)\n",
    "    total_sess_hrs.append(total_sess_hr)\n",
    "    avg_shopping_intervals.append(avg_shopping_interval)\n",
    "    main_devices.append(main_device)\n",
    "    pd_cs.append(pd_c)\n",
    "    clac1_nms.append(clac1_nm)\n",
    "    clac2_nms.append(clac2_nm)\n",
    "    clac3_nms.append(clac3_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c4d13f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame([clnt_id, num_shoppings, avg_prices, total_prices, avg_cts, total_cts, avg_sess_views, \n",
    "                          total_sess_views, avg_sess_hrs, total_sess_hrs, avg_shopping_intervals, main_devices, \n",
    "                          pd_cs, clac1_nms, clac2_nms, clac3_nms]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9e91055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns = ['clnt_id', 'num_shopping', 'avg_price', 'total_price', 'avg_ct', 'total_ct', 'avg_sess_view', \n",
    "                    'total_sess_view', 'avg_sess_hr', 'total_sess_hr', 'avg_shopping_interval', 'main_device', \n",
    "                    'pd_c', 'clac1_nm', 'clac2_nm', 'clac3_nm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "98d28e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>avg_shopping_interval</th>\n",
       "      <th>main_device</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>clac1_nm</th>\n",
       "      <th>clac2_nm</th>\n",
       "      <th>clac3_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32000</td>\n",
       "      <td>128000</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>4</td>\n",
       "      <td>211.333</td>\n",
       "      <td>634</td>\n",
       "      <td>3315</td>\n",
       "      <td>9945</td>\n",
       "      <td>40.5</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[234664, 325761, 752670]</td>\n",
       "      <td>[스포츠패션, 스포츠패션, 출산/육아용품]</td>\n",
       "      <td>[유아동스포츠화, 유아동스포츠화, 유아스킨/바디케어]</td>\n",
       "      <td>[유아동런닝/트레이닝화, 유아동스포츠샌들/슬리퍼, 유아용화장품]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>106400</td>\n",
       "      <td>212800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>186</td>\n",
       "      <td>1051</td>\n",
       "      <td>2102</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[567605, 556431]</td>\n",
       "      <td>[패션잡화, 패션잡화]</td>\n",
       "      <td>[여성지갑, 여성지갑]</td>\n",
       "      <td>[여성일반지갑, 여성일반지갑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>123000</td>\n",
       "      <td>369000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.667</td>\n",
       "      <td>404</td>\n",
       "      <td>1745.67</td>\n",
       "      <td>5237</td>\n",
       "      <td>9.5</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[269142, 269142, 797432]</td>\n",
       "      <td>[남성의류, 남성의류, 패션잡화]</td>\n",
       "      <td>[남성의류하의, 남성의류하의, 남성가방]</td>\n",
       "      <td>[남성캐주얼바지, 남성캐주얼바지, 남성서류가방]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>17587.9</td>\n",
       "      <td>334170</td>\n",
       "      <td>1.11765</td>\n",
       "      <td>19</td>\n",
       "      <td>105.412</td>\n",
       "      <td>1792</td>\n",
       "      <td>1356.71</td>\n",
       "      <td>23064</td>\n",
       "      <td>7.25</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[738180, 514099, 566303, 843952, 843603, 76426...</td>\n",
       "      <td>[모바일, 여성의류, 식기/조리기구, 화장품/뷰티케어, 출산/육아용품, 문구/사무용...</td>\n",
       "      <td>[모바일액세서리, 여성의류상의, 밀폐/보관용기, 메이크업, 유아위생용품, 일반문구/...</td>\n",
       "      <td>[기타모바일액세서리, 여성티셔츠/탑, 보온병/텀블러, BB/파운데이션/컴팩트류, 유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>63000</td>\n",
       "      <td>126000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>138</td>\n",
       "      <td>2120</td>\n",
       "      <td>4240</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[674855, 674855]</td>\n",
       "      <td>[화장품/뷰티케어, 화장품/뷰티케어]</td>\n",
       "      <td>[메이크업, 메이크업]</td>\n",
       "      <td>[BB/파운데이션/컴팩트류, BB/파운데이션/컴팩트류]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113099</th>\n",
       "      <td>263089</td>\n",
       "      <td>3</td>\n",
       "      <td>68633.3</td>\n",
       "      <td>205900</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63.3333</td>\n",
       "      <td>190</td>\n",
       "      <td>1700.33</td>\n",
       "      <td>5101</td>\n",
       "      <td>6</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[50185, 760443, 9617]</td>\n",
       "      <td>[화장품/뷰티케어, 화장품/뷰티케어, 원예/애완]</td>\n",
       "      <td>[스킨케어, 메이크업, 고양이용품]</td>\n",
       "      <td>[스킨케어세트, BB/파운데이션/컴팩트류, 고양이사료]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113100</th>\n",
       "      <td>263097</td>\n",
       "      <td>4</td>\n",
       "      <td>60610</td>\n",
       "      <td>242440</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>469.75</td>\n",
       "      <td>1879</td>\n",
       "      <td>3422</td>\n",
       "      <td>13688</td>\n",
       "      <td>17</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[737465, 537882, 755981, 301542]</td>\n",
       "      <td>[화장품/뷰티케어, 구기/필드스포츠, 건강식품, 스포츠패션]</td>\n",
       "      <td>[스킨케어, 골프, 홍삼/인삼가공식품, 여성일반스포츠의류]</td>\n",
       "      <td>[스킨케어세트, 골프패션잡화, 홍삼/인삼혼합세트, 여성스포츠티셔츠/탑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113101</th>\n",
       "      <td>263098</td>\n",
       "      <td>1</td>\n",
       "      <td>100200</td>\n",
       "      <td>100200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>1175</td>\n",
       "      <td>1175</td>\n",
       "      <td>183</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[593872]</td>\n",
       "      <td>[남성의류]</td>\n",
       "      <td>[남성의류상의]</td>\n",
       "      <td>[남성남방셔츠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113102</th>\n",
       "      <td>263099</td>\n",
       "      <td>4</td>\n",
       "      <td>12250</td>\n",
       "      <td>49000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>1096</td>\n",
       "      <td>3890</td>\n",
       "      <td>15560</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[193132, 470807, 665269, 692330]</td>\n",
       "      <td>[남성의류, 남성의류, 남성의류, 남성의류]</td>\n",
       "      <td>[남성의류하의, 남성의류상의, 남성의류하의, 남성의류상의]</td>\n",
       "      <td>[남성캐주얼바지, 남성티셔츠, 남성캐주얼바지, 남성티셔츠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113103</th>\n",
       "      <td>263100</td>\n",
       "      <td>2</td>\n",
       "      <td>11200</td>\n",
       "      <td>22400</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>1474.5</td>\n",
       "      <td>2949</td>\n",
       "      <td>25</td>\n",
       "      <td>mobile</td>\n",
       "      <td>[310231, 678538]</td>\n",
       "      <td>[여성의류, 남성의류]</td>\n",
       "      <td>[여성의류하의, 남성의류상의]</td>\n",
       "      <td>[여성바지, 남성티셔츠]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113104 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clnt_id num_shopping avg_price total_price   avg_ct total_ct  \\\n",
       "0            2            3     32000      128000  1.33333        4   \n",
       "1            3            2    106400      212800        1        2   \n",
       "2           10            3    123000      369000        1        3   \n",
       "3           15           17   17587.9      334170  1.11765       19   \n",
       "4           29            2     63000      126000        1        2   \n",
       "...        ...          ...       ...         ...      ...      ...   \n",
       "113099  263089            3   68633.3      205900        1        3   \n",
       "113100  263097            4     60610      242440        1        4   \n",
       "113101  263098            1    100200      100200        1        1   \n",
       "113102  263099            4     12250       49000        1        4   \n",
       "113103  263100            2     11200       22400        1        2   \n",
       "\n",
       "       avg_sess_view total_sess_view avg_sess_hr total_sess_hr  \\\n",
       "0            211.333             634        3315          9945   \n",
       "1                 93             186        1051          2102   \n",
       "2            134.667             404     1745.67          5237   \n",
       "3            105.412            1792     1356.71         23064   \n",
       "4                 69             138        2120          4240   \n",
       "...              ...             ...         ...           ...   \n",
       "113099       63.3333             190     1700.33          5101   \n",
       "113100        469.75            1879        3422         13688   \n",
       "113101           136             136        1175          1175   \n",
       "113102           274            1096        3890         15560   \n",
       "113103           104             208      1474.5          2949   \n",
       "\n",
       "       avg_shopping_interval main_device  \\\n",
       "0                       40.5      mobile   \n",
       "1                          0      mobile   \n",
       "2                        9.5      mobile   \n",
       "3                       7.25      mobile   \n",
       "4                          0      mobile   \n",
       "...                      ...         ...   \n",
       "113099                     6      mobile   \n",
       "113100                    17      mobile   \n",
       "113101                   183      mobile   \n",
       "113102                     0      mobile   \n",
       "113103                    25      mobile   \n",
       "\n",
       "                                                     pd_c  \\\n",
       "0                                [234664, 325761, 752670]   \n",
       "1                                        [567605, 556431]   \n",
       "2                                [269142, 269142, 797432]   \n",
       "3       [738180, 514099, 566303, 843952, 843603, 76426...   \n",
       "4                                        [674855, 674855]   \n",
       "...                                                   ...   \n",
       "113099                              [50185, 760443, 9617]   \n",
       "113100                   [737465, 537882, 755981, 301542]   \n",
       "113101                                           [593872]   \n",
       "113102                   [193132, 470807, 665269, 692330]   \n",
       "113103                                   [310231, 678538]   \n",
       "\n",
       "                                                 clac1_nm  \\\n",
       "0                                 [스포츠패션, 스포츠패션, 출산/육아용품]   \n",
       "1                                            [패션잡화, 패션잡화]   \n",
       "2                                      [남성의류, 남성의류, 패션잡화]   \n",
       "3       [모바일, 여성의류, 식기/조리기구, 화장품/뷰티케어, 출산/육아용품, 문구/사무용...   \n",
       "4                                    [화장품/뷰티케어, 화장품/뷰티케어]   \n",
       "...                                                   ...   \n",
       "113099                        [화장품/뷰티케어, 화장품/뷰티케어, 원예/애완]   \n",
       "113100                  [화장품/뷰티케어, 구기/필드스포츠, 건강식품, 스포츠패션]   \n",
       "113101                                             [남성의류]   \n",
       "113102                           [남성의류, 남성의류, 남성의류, 남성의류]   \n",
       "113103                                       [여성의류, 남성의류]   \n",
       "\n",
       "                                                 clac2_nm  \\\n",
       "0                           [유아동스포츠화, 유아동스포츠화, 유아스킨/바디케어]   \n",
       "1                                            [여성지갑, 여성지갑]   \n",
       "2                                  [남성의류하의, 남성의류하의, 남성가방]   \n",
       "3       [모바일액세서리, 여성의류상의, 밀폐/보관용기, 메이크업, 유아위생용품, 일반문구/...   \n",
       "4                                            [메이크업, 메이크업]   \n",
       "...                                                   ...   \n",
       "113099                                [스킨케어, 메이크업, 고양이용품]   \n",
       "113100                   [스킨케어, 골프, 홍삼/인삼가공식품, 여성일반스포츠의류]   \n",
       "113101                                           [남성의류상의]   \n",
       "113102                   [남성의류하의, 남성의류상의, 남성의류하의, 남성의류상의]   \n",
       "113103                                   [여성의류하의, 남성의류상의]   \n",
       "\n",
       "                                                 clac3_nm  \n",
       "0                     [유아동런닝/트레이닝화, 유아동스포츠샌들/슬리퍼, 유아용화장품]  \n",
       "1                                        [여성일반지갑, 여성일반지갑]  \n",
       "2                              [남성캐주얼바지, 남성캐주얼바지, 남성서류가방]  \n",
       "3       [기타모바일액세서리, 여성티셔츠/탑, 보온병/텀블러, BB/파운데이션/컴팩트류, 유...  \n",
       "4                          [BB/파운데이션/컴팩트류, BB/파운데이션/컴팩트류]  \n",
       "...                                                   ...  \n",
       "113099                     [스킨케어세트, BB/파운데이션/컴팩트류, 고양이사료]  \n",
       "113100            [스킨케어세트, 골프패션잡화, 홍삼/인삼혼합세트, 여성스포츠티셔츠/탑]  \n",
       "113101                                           [남성남방셔츠]  \n",
       "113102                   [남성캐주얼바지, 남성티셔츠, 남성캐주얼바지, 남성티셔츠]  \n",
       "113103                                      [여성바지, 남성티셔츠]  \n",
       "\n",
       "[113104 rows x 16 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9403d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nm in df_test['CLAC3_NM'].unique():\n",
    "    if nm not in clac3_nm_dic.keys():\n",
    "        clac3_nm_dic[nm] = len(clac3_nm_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2891eb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'블랜더': 0,\n",
       " '거실수예소품': 1,\n",
       " '남성수영복': 2,\n",
       " '페이셜클렌저': 3,\n",
       " '선크림류': 4,\n",
       " '여성비치웨어': 5,\n",
       " '홍삼액': 6,\n",
       " 'BB/파운데이션/컴팩트류': 7,\n",
       " '에센스/세럼': 8,\n",
       " '여성속옷세트': 9,\n",
       " '브래지어': 10,\n",
       " '여성팬티': 11,\n",
       " '여성스포츠샌들/슬리퍼': 12,\n",
       " '유아동팬티': 13,\n",
       " '유아동일반양말': 14,\n",
       " '여성샌들': 15,\n",
       " '유아동타이즈': 16,\n",
       " '주방칼/가위': 17,\n",
       " '영유아점프수트/오버롤': 18,\n",
       " '아동모': 19,\n",
       " '프라이팬': 20,\n",
       " '롤티슈': 21,\n",
       " '플라스틱서랍장': 22,\n",
       " '유아용화장품': 23,\n",
       " '일반형냉장고': 24,\n",
       " '핸드로션/크림': 25,\n",
       " '남성스포츠티셔츠': 26,\n",
       " '크림/밤/오일': 27,\n",
       " '골프공': 28,\n",
       " '골프연습장비': 29,\n",
       " '립글로즈/틴트': 30,\n",
       " '남성일반지갑': 31,\n",
       " '남성런닝/트레이닝화': 32,\n",
       " '애견주거/실내용품': 33,\n",
       " '생수': 34,\n",
       " '여성트레이닝복': 35,\n",
       " '여성런닝셔츠/캐미솔': 36,\n",
       " '채소즙': 37,\n",
       " '남성용스킨케어류': 38,\n",
       " '3단우산': 39,\n",
       " '스포츠가방': 40,\n",
       " '남성팬티': 41,\n",
       " '여성남방셔츠': 42,\n",
       " '여성원피스': 43,\n",
       " '유아동이불/이불커버': 44,\n",
       " '남성티셔츠': 45,\n",
       " '남성캐주얼바지': 46,\n",
       " '여성코트': 47,\n",
       " '남성청바지': 48,\n",
       " '기타여성속옷': 49,\n",
       " '기타냉방가전': 50,\n",
       " '영유아티셔츠/탑': 51,\n",
       " '여아티셔츠/탑': 52,\n",
       " '생리대': 53,\n",
       " '유아용기저귀': 54,\n",
       " '유산균/프로바이오틱스': 55,\n",
       " '김치류': 56,\n",
       " '남성등산바지': 57,\n",
       " '유아동스포츠샌들/슬리퍼': 58,\n",
       " '골프패션잡화': 59,\n",
       " '염모제': 60,\n",
       " '장우산': 61,\n",
       " '골프필드용품': 62,\n",
       " '텐트': 63,\n",
       " '기타에어컨': 64,\n",
       " '여성스니커즈': 65,\n",
       " '남성정장셔츠': 66,\n",
       " '토스터/제빵기': 67,\n",
       " '선풍기': 68,\n",
       " '유아동런닝셔츠': 69,\n",
       " '배낭': 70,\n",
       " '여성크로스백': 71,\n",
       " '남성런닝셔츠': 72,\n",
       " '남성남방셔츠': 73,\n",
       " '여성스웨터/풀오버': 74,\n",
       " '영유아스커트': 75,\n",
       " '여아가디건': 76,\n",
       " '아동수영복': 77,\n",
       " '미스트': 78,\n",
       " '스킨/토너': 79,\n",
       " '애견장난감/훈련': 80,\n",
       " '고양이캣타워/실내용품': 81,\n",
       " '기타구강관리용품': 82,\n",
       " '남성등산티셔츠': 83,\n",
       " '남성점퍼': 84,\n",
       " '팬티라이너': 85,\n",
       " '여성로퍼': 86,\n",
       " '여성티셔츠/탑': 87,\n",
       " '냉동국탕류': 88,\n",
       " '서랍장/수납장': 89,\n",
       " '책상의자': 90,\n",
       " '스킨케어세트': 91,\n",
       " '페이셜팩류': 92,\n",
       " '출산/신생아용품세트': 93,\n",
       " '아기띠/캐리어': 94,\n",
       " '여성스포츠티셔츠/탑': 95,\n",
       " '유아동샌들': 96,\n",
       " '여성바지': 97,\n",
       " '영유아원피스': 98,\n",
       " '남성정장바지': 99,\n",
       " '남성일반스포츠바지': 100,\n",
       " '미술/창작완구': 101,\n",
       " '기타요가/필라테스소품': 102,\n",
       " '숟가락/젓가락': 103,\n",
       " '아쿠아슈즈': 104,\n",
       " '여성재킷': 105,\n",
       " '영유아바지': 106,\n",
       " '남성골프바지': 107,\n",
       " '유아동침구세트': 108,\n",
       " '유아/아동용치약': 109,\n",
       " '스포츠모자': 110,\n",
       " '유아동슬리퍼': 111,\n",
       " '여성골프패딩': 112,\n",
       " '여성숄더백': 113,\n",
       " '야구모자': 114,\n",
       " '유아동스니커즈': 115,\n",
       " '헤어에센스': 116,\n",
       " '탁자': 117,\n",
       " '닭가슴살': 118,\n",
       " '유아동내의': 119,\n",
       " '남아티셔츠/탑': 120,\n",
       " '오리발/스노클링': 121,\n",
       " '남아잠옷': 122,\n",
       " '식탁의자': 123,\n",
       " '유아용물티슈': 124,\n",
       " '애견간식': 125,\n",
       " '여성플랫': 126,\n",
       " '애견사료': 127,\n",
       " '반찬통/밀폐용기': 128,\n",
       " '어린이홍삼': 129,\n",
       " '스포츠시계': 130,\n",
       " '고양이모래/배변용품': 131,\n",
       " '남성스포츠샌들/슬리퍼': 132,\n",
       " '혼합즙': 133,\n",
       " '아이브로우': 134,\n",
       " '아이케어': 135,\n",
       " '바디워시': 136,\n",
       " '유아용샴푸/바디워시': 137,\n",
       " '샴푸': 138,\n",
       " '남성가디건': 139,\n",
       " '여성가디건': 140,\n",
       " '캐리어': 141,\n",
       " '한방음료': 142,\n",
       " '아동용가방': 143,\n",
       " '여성일반스포츠바지': 144,\n",
       " '노트북': 145,\n",
       " '메이크업세트': 146,\n",
       " '여성임부속옷': 147,\n",
       " '접시': 148,\n",
       " '반상기세트/홈세트': 149,\n",
       " '장롱': 150,\n",
       " '매트리스': 151,\n",
       " '여성점퍼': 152,\n",
       " '홈웨어세트': 153,\n",
       " '남성골프티셔츠': 154,\n",
       " '여성스웨트셔츠/후드/집업': 155,\n",
       " '남성비치웨어': 156,\n",
       " '기타모바일액세서리': 157,\n",
       " '성인침구속통/솜': 158,\n",
       " '바구니': 159,\n",
       " '테이프': 160,\n",
       " '칼/가위': 161,\n",
       " '수정용품': 162,\n",
       " '유아동선글라스': 163,\n",
       " '여성클러치백': 164,\n",
       " '영유아청바지': 165,\n",
       " '캠핑테이블/의자': 166,\n",
       " '여아바지': 167,\n",
       " '남아청바지': 168,\n",
       " '고양이사료': 169,\n",
       " '커튼': 170,\n",
       " '기타물놀이용품': 171,\n",
       " '여성신발부속품': 172,\n",
       " '노트북가방': 173,\n",
       " '여성카드/명함지갑': 174,\n",
       " '책상': 175,\n",
       " '여성스커트': 176,\n",
       " '욕실발판': 177,\n",
       " '마스카라': 178,\n",
       " '남성시계': 179,\n",
       " '남성패딩': 180,\n",
       " '식탁세트': 181,\n",
       " '피규어': 182,\n",
       " '욕실소품': 183,\n",
       " '롤플레잉완구': 184,\n",
       " '기타캠핑용품': 185,\n",
       " '분말표백제': 186,\n",
       " '풀': 187,\n",
       " '종합영양제': 188,\n",
       " '피트니스용품': 189,\n",
       " '스툴/리빙의자': 190,\n",
       " '책장': 191,\n",
       " '칫솔': 192,\n",
       " '수건': 193,\n",
       " '액상세탁세제': 194,\n",
       " '영유아블라우스': 195,\n",
       " '남아바지': 196,\n",
       " '헤어케어선물세트': 197,\n",
       " '여성등산티셔츠/탑': 198,\n",
       " '남성베스트': 199,\n",
       " '썬캡': 200,\n",
       " '스카프': 201,\n",
       " '블러셔/쉐이딩/하이라이터': 202,\n",
       " '여아레깅스': 203,\n",
       " '애견목욕/위생용품': 204,\n",
       " '기타일반문구/사무용품': 205,\n",
       " '린스/컨디셔너': 206,\n",
       " '샴푸/린스세트': 207,\n",
       " '미용비누': 208,\n",
       " '성인매트리스커버': 209,\n",
       " '스냅백': 210,\n",
       " '기타컴퓨터액세서리': 211,\n",
       " '유아동플랫': 212,\n",
       " '기타영양제': 213,\n",
       " '여아남방셔츠': 214,\n",
       " '남아의류세트': 215,\n",
       " '탄산수': 216,\n",
       " '일반청소기': 217,\n",
       " '손싸개/발싸개': 218,\n",
       " '유아동런닝/트레이닝화': 219,\n",
       " '여성토트백': 220,\n",
       " '여성일반양말': 221,\n",
       " '여성런닝/트레이닝화': 222,\n",
       " '치약': 223,\n",
       " '샤워/목욕도구/목욕헤어밴드': 224,\n",
       " '봉제인형': 225,\n",
       " '유아동베개/베개커버': 226,\n",
       " '놀이방매트': 227,\n",
       " '식음료모바일상품권': 228,\n",
       " '여아베스트': 229,\n",
       " '성인베개/베개커버': 230,\n",
       " '이유식용품': 231,\n",
       " '아이섀도우': 232,\n",
       " '남성샌들': 233,\n",
       " '기타이미용가전': 234,\n",
       " '요가/필라테스복': 235,\n",
       " '여성향수': 236,\n",
       " '기타정리용품': 237,\n",
       " '트리트먼트/팩': 238,\n",
       " '욕실청소용품': 239,\n",
       " '기타주방정리용품/소모품': 240,\n",
       " '여아청바지': 241,\n",
       " '기름종이': 242,\n",
       " '아이라이너': 243,\n",
       " '홍삼/인삼혼합세트': 244,\n",
       " '여성시계': 245,\n",
       " '손수건': 246,\n",
       " '팔찌': 247,\n",
       " '남성숄더/크로스백': 248,\n",
       " '지퍼백/비닐백': 249,\n",
       " '성인패드/스프레드': 250,\n",
       " '여성펌프스': 251,\n",
       " '구강청정제': 252,\n",
       " '남성일반양말': 253,\n",
       " '여성오픈토': 254,\n",
       " '공기청정기': 255,\n",
       " '여성등산바지': 256,\n",
       " '커튼링/커튼봉/부속품': 257,\n",
       " '메이크업베이스/프라이머': 258,\n",
       " '여아점퍼': 259,\n",
       " '남성등산점퍼/재킷': 260,\n",
       " '유아동슬립온': 261,\n",
       " '인삼가공식품': 262,\n",
       " '여성덧신류': 263,\n",
       " '냉동핫도그': 264,\n",
       " '여성블라우스': 265,\n",
       " '식기건조대/수저통': 266,\n",
       " '국자/뒤지개/주걱': 267,\n",
       " '여성부츠': 268,\n",
       " '여성베스트': 269,\n",
       " '에멀젼/로션': 270,\n",
       " '기타조리도구': 271,\n",
       " '바디보습': 272,\n",
       " '여성패딩': 273,\n",
       " '성인이불/이불커버': 274,\n",
       " '솥': 275,\n",
       " '이불/옷압축팩': 276,\n",
       " '섬유유연제/향기지속제': 277,\n",
       " '양산': 278,\n",
       " '여성수영복': 279,\n",
       " '남성내의': 280,\n",
       " '기타등산용품': 281,\n",
       " '유아용세척용품': 282,\n",
       " '도마': 283,\n",
       " '생활모바일상품권': 284,\n",
       " '젖병/젖꼭지': 285,\n",
       " '아동우산': 286,\n",
       " '케이스/보호필름': 287,\n",
       " '남성스킨케어세트': 288,\n",
       " '여성백팩': 289,\n",
       " '커피머신': 290,\n",
       " '방석/방석커버': 291,\n",
       " '장식장/진열장': 292,\n",
       " '다이어트보조식품': 293,\n",
       " '남성스니커즈': 294,\n",
       " '남성용클렌저': 295,\n",
       " '소품가방': 296,\n",
       " '변기시트/커버': 297,\n",
       " '헤드웨어': 298,\n",
       " '여행용소품': 299,\n",
       " '목걸이': 300,\n",
       " '미용보조식품': 301,\n",
       " '제빵용품': 302,\n",
       " 'PC부품': 303,\n",
       " '등산화': 304,\n",
       " '젤네일/케어류': 305,\n",
       " '핸디형청소기': 306,\n",
       " '주방선반/걸이대': 307,\n",
       " '옷걸이': 308,\n",
       " '유아동침대': 309,\n",
       " '로봇청소기': 310,\n",
       " '헤어드라이어': 311,\n",
       " '레저모바일상품권': 312,\n",
       " '스폰지/퍼프': 313,\n",
       " '커피용품': 314,\n",
       " '커피잔': 315,\n",
       " '저장장치': 316,\n",
       " '우주복': 317,\n",
       " '립스틱/립라이너': 318,\n",
       " '조립/프라모델': 319,\n",
       " '스케이트보드/킥보드': 320,\n",
       " '남성로퍼': 321,\n",
       " '여성쪼리': 322,\n",
       " '여성트렌치코트': 323,\n",
       " '남성정장재킷': 324,\n",
       " '골프화': 325,\n",
       " '남성트레이닝복': 326,\n",
       " '전기찜기': 327,\n",
       " '남성향수': 328,\n",
       " '일반비타민': 329,\n",
       " '여성슬링백': 330,\n",
       " '촉각놀이/오뚝이': 331,\n",
       " '기타패션잡화': 332,\n",
       " '데오도란트': 333,\n",
       " '수영모자': 334,\n",
       " '여성슬리퍼': 335,\n",
       " '고무장갑': 336,\n",
       " '일반두유': 337,\n",
       " '속눈썹/쌍꺼풀': 338,\n",
       " '물안경': 339,\n",
       " '기타여행용가방': 340,\n",
       " '남성트렌치코트': 341,\n",
       " '발찌': 342,\n",
       " '남성스웨터/풀오버': 343,\n",
       " '호두': 344,\n",
       " '캠핑침구': 345,\n",
       " '아동비치웨어': 346,\n",
       " '애견의류/악세서리': 347,\n",
       " '성인침구세트': 348,\n",
       " '남성등산패딩': 349,\n",
       " '냉동만두': 350,\n",
       " '냄비': 351,\n",
       " '남성캐주얼재킷': 352,\n",
       " '승마운동기': 353,\n",
       " '바디케어세트': 354,\n",
       " '거들': 355,\n",
       " '성인요/요커버': 356,\n",
       " '여성내의': 357,\n",
       " '루테인': 358,\n",
       " '여성청바지': 359,\n",
       " '여성잠옷': 360,\n",
       " '인덕션/가스레인지': 361,\n",
       " '캠핑취사': 362,\n",
       " '마우스': 363,\n",
       " '블랙박스': 364,\n",
       " '포크/나이프': 365,\n",
       " '남성속옷세트': 366,\n",
       " '여성슬립온': 367,\n",
       " '오메가3/기타추출오일': 368,\n",
       " '헤어세팅기': 369,\n",
       " '키보드': 370,\n",
       " '모바일배터리/충전기': 371,\n",
       " '채반/바구니/쟁반': 372,\n",
       " '선반장/행거': 373,\n",
       " '안경테': 374,\n",
       " '여성골프바지': 375,\n",
       " '커피메이커/포트': 376,\n",
       " '유아동스포츠티셔츠/탑': 377,\n",
       " '유아동스포츠스웨트셔츠/후드/집업': 378,\n",
       " '고양이간식': 379,\n",
       " '사무용/학생용가구세트': 380,\n",
       " '벽걸이형에어컨': 381,\n",
       " '여성등산점퍼/재킷': 382,\n",
       " '홍삼정/분말/환': 383,\n",
       " '토마토': 384,\n",
       " '스킨케어디바이스': 385,\n",
       " '입욕제/스파제품': 386,\n",
       " '과일즙': 387,\n",
       " '전기튀김기': 388,\n",
       " '성인담요': 389,\n",
       " '귀걸이': 390,\n",
       " '소파': 391,\n",
       " '행주': 392,\n",
       " '여성골프남방셔츠': 393,\n",
       " '영유아남방셔츠': 394,\n",
       " '스텝퍼/트위스트': 395,\n",
       " '여성등산패딩': 396,\n",
       " '식탁': 397,\n",
       " '전기밥솥': 398,\n",
       " '대접/볼': 399,\n",
       " '밥공기': 400,\n",
       " '찬기/종지': 401,\n",
       " '여성발가락양말': 402,\n",
       " '역할놀이': 403,\n",
       " '유아용카시트/매트': 404,\n",
       " '젖병소독/건조용품': 405,\n",
       " '유아/아동용칫솔': 406,\n",
       " '기타냉동간편식': 407,\n",
       " '유아목욕용품': 408,\n",
       " '유아동트레이닝복': 409,\n",
       " '여아잠옷': 410,\n",
       " '선반/걸이': 411,\n",
       " '여성양말선물세트': 412,\n",
       " '물티슈': 413,\n",
       " '남성코트': 414,\n",
       " '분말세탁세제': 415,\n",
       " '수유패드/보조용품': 416,\n",
       " '유아동의자': 417,\n",
       " '학생용가방': 418,\n",
       " '남성스포츠점퍼/재킷': 419,\n",
       " '유아공부상/디딤대': 420,\n",
       " '잉크/토너': 421,\n",
       " '여성향수세트': 422,\n",
       " '펜던트': 423,\n",
       " '여성일반지갑': 424,\n",
       " '보드게임': 425,\n",
       " '레고': 426,\n",
       " '유아동스포츠점퍼/재킷': 427,\n",
       " '치약/칫솔세트': 428,\n",
       " '수영가방': 429,\n",
       " '패션인형': 430,\n",
       " '도시락/찬합': 431,\n",
       " '발효원액': 432,\n",
       " '남성등산베스트': 433,\n",
       " '여성선글라스': 434,\n",
       " '여성점프수트/오버롤': 435,\n",
       " '치아발육기/딸랑이': 436,\n",
       " '남성카드/명함지갑': 437,\n",
       " '남성용선크림/메이크업류': 438,\n",
       " '남성골프점퍼/재킷': 439,\n",
       " '여성골프티셔츠/탑': 440,\n",
       " '기타국산과일류': 441,\n",
       " '여아스커트': 442,\n",
       " '건조기': 443,\n",
       " '기타기능성음료': 444,\n",
       " '스피커': 445,\n",
       " '얼음/빙수용품': 446,\n",
       " '스타킹': 447,\n",
       " '보온병/텀블러': 448,\n",
       " '전동칫솔/칫솔모': 449,\n",
       " '여아스웨트셔츠/후드/집업': 450,\n",
       " '혼합견과': 451,\n",
       " '볼펜': 452,\n",
       " '필통': 453,\n",
       " '샤프/샤프심': 454,\n",
       " '필기구세트': 455,\n",
       " '엽산/철분': 456,\n",
       " '유아패션잡화': 457,\n",
       " '휴대폰': 458,\n",
       " '각티슈/미용티슈': 459,\n",
       " '골프가방': 460,\n",
       " '여성타이즈': 461,\n",
       " '요가/스포츠매트': 462,\n",
       " '여성골프스커트': 463,\n",
       " '골프장갑': 464,\n",
       " '여성골프니트/가디건': 465,\n",
       " '여성골프베스트': 466,\n",
       " '영유아점퍼': 467,\n",
       " '영유아가디건': 468,\n",
       " '남성스웨트셔츠/후드/집업': 469,\n",
       " '사인펜': 470,\n",
       " '남성선글라스': 471,\n",
       " '반지': 472,\n",
       " '이어폰/헤드폰': 473,\n",
       " '조리도구세트': 474,\n",
       " '키친타올': 475,\n",
       " '남녀공용향수': 476,\n",
       " '유아동레인부츠/슈즈': 477,\n",
       " '유아건강보조제': 478,\n",
       " '여성가운': 479,\n",
       " '남성잠옷': 480,\n",
       " '유아동스포츠패딩': 481,\n",
       " '여아패딩': 482,\n",
       " '전통/종교장신구': 483,\n",
       " '복근/벨트마사지기구': 484,\n",
       " '벙거지': 485,\n",
       " '슬립': 486,\n",
       " '만년필': 487,\n",
       " '공병/모델링팩전용도구': 488,\n",
       " '화장대': 489,\n",
       " '핸드카트': 490,\n",
       " '여성레인부츠/슈즈': 491,\n",
       " '퍼즐': 492,\n",
       " '캐쥬얼크로스백': 493,\n",
       " '음악/악기완구': 494,\n",
       " '아기체육관/러닝홈': 495,\n",
       " '면봉/화장솜': 496,\n",
       " '남성골프남방셔츠': 497,\n",
       " '수예소품속통/솜': 498,\n",
       " '쿠션/쿠션커버': 499,\n",
       " '붙박이장': 500,\n",
       " '기타견과류': 501,\n",
       " '아몬드': 502,\n",
       " '여성등산베스트': 503,\n",
       " '영유아레깅스': 504,\n",
       " '여성컴포트화': 505,\n",
       " '남성정장화': 506,\n",
       " '블라인드/버티컬': 507,\n",
       " '스포츠두건/머플러/마스크': 508,\n",
       " '남성골프패딩': 509,\n",
       " '스포츠양말': 510,\n",
       " '남성정장세트': 511,\n",
       " '음료용컵': 512,\n",
       " '인라인/스케이트보드/킥보드안전용품': 513,\n",
       " '애견식기/물병': 514,\n",
       " '복숭아': 515,\n",
       " '글루코사민': 516,\n",
       " '헤어브러쉬/롤': 517,\n",
       " '거실화/실내화': 518,\n",
       " '유아동담요': 519,\n",
       " '고데기': 520,\n",
       " '칼슘/미네랄': 521,\n",
       " '주방수예소품': 522,\n",
       " '무선조종': 523,\n",
       " '수세미/솔': 524,\n",
       " '유모차': 525,\n",
       " '남성덧신류': 526,\n",
       " '참외': 527,\n",
       " '사과': 528,\n",
       " '제습기': 529,\n",
       " '양문형냉장고': 530,\n",
       " '메이크업브러쉬': 531,\n",
       " '가습기': 532,\n",
       " '유아동요/요커버': 533,\n",
       " '구명조끼/안전용품': 534,\n",
       " '네일케어도구': 535,\n",
       " '애견건강용품': 536,\n",
       " '오븐/전자레인지': 537,\n",
       " '압력솥': 538,\n",
       " '기타유아동화': 539,\n",
       " '유아동일반스포츠바지': 540,\n",
       " '여성세정제': 541,\n",
       " '비닐장갑': 542,\n",
       " '스포츠선글라스': 543,\n",
       " '미니자동차': 544,\n",
       " '전자교육완구': 545,\n",
       " '수박': 546,\n",
       " '바디슬리밍/리프팅': 547,\n",
       " '남아셔츠': 548,\n",
       " '헤어무스/젤': 549,\n",
       " '남아실내복': 550,\n",
       " '풋케어': 551,\n",
       " '여아재킷': 552,\n",
       " '제기': 553,\n",
       " '일반교육완구': 554,\n",
       " '올인원': 555,\n",
       " '유축기': 556,\n",
       " '욕실화': 557,\n",
       " '필기도구소모품': 558,\n",
       " '남성머니클립': 559,\n",
       " '헤어스프레이': 560,\n",
       " '스팀청소기': 561,\n",
       " '여성스포츠점퍼/재킷': 562,\n",
       " '기타보석류': 563,\n",
       " '자두': 564,\n",
       " '메론': 565,\n",
       " '멀티형에어컨': 566,\n",
       " '기타모자': 567,\n",
       " '유아동패드/스프레드': 568,\n",
       " '카메라액세서리': 569,\n",
       " '전기면도기': 570,\n",
       " '유아동방한화': 571,\n",
       " '남성서류가방': 572,\n",
       " '책상정리용품': 573,\n",
       " '비니': 574,\n",
       " '남성슬립온': 575,\n",
       " '디저트포크/스푼': 576,\n",
       " '목욕용장난감': 577,\n",
       " '우비': 578,\n",
       " '주방수납장': 579,\n",
       " '유아동수납장': 580,\n",
       " '냉동떡볶이': 581,\n",
       " '건강보조식품세트': 582,\n",
       " '특수용세탁세제': 583,\n",
       " '여성레깅스': 584,\n",
       " '집게/클립': 585,\n",
       " '캐노피': 586,\n",
       " '핸드워시/손세정제': 587,\n",
       " '유아용욕조': 588,\n",
       " '모유보관용품': 589,\n",
       " '바운서/쏘서/보행기': 590,\n",
       " '발포비타민': 591,\n",
       " '여성스포츠베스트': 592,\n",
       " '드럼세탁기': 593,\n",
       " '고양이건강용품': 594,\n",
       " '스탠드형에어컨': 595,\n",
       " '남성신발부속품': 596,\n",
       " '유아동속옷세트': 597,\n",
       " '자연유래영양제': 598,\n",
       " '조리기구세트': 599,\n",
       " '남성골프스웨트셔츠/후드/집업': 600,\n",
       " '여성방한화': 601,\n",
       " 'LED': 602,\n",
       " 'UHD': 603,\n",
       " '냉동튀김': 604,\n",
       " '캐쥬얼백팩': 605,\n",
       " '욕실수납용품': 606,\n",
       " '연필깎이': 607,\n",
       " '연필': 608,\n",
       " '탐폰': 609,\n",
       " '운동보조식품': 610,\n",
       " '남성백팩': 611,\n",
       " '유아동로퍼': 612,\n",
       " '헤어왁스': 613,\n",
       " '배냇저고리': 614,\n",
       " '영유아베스트': 615,\n",
       " '고양이장난감': 616,\n",
       " '고양이목욕/위생용품': 617,\n",
       " '여성스포츠스웨트셔츠/후드/집업': 618,\n",
       " '국그릇': 619,\n",
       " '남성힙색': 620,\n",
       " '남성스포츠화부속품': 621,\n",
       " '여아블라우스': 622,\n",
       " '기타주방가전': 623,\n",
       " '남성스포츠스웨트셔츠/후드/집업': 624,\n",
       " '서류정리용품': 625,\n",
       " '숙취해소음료': 626,\n",
       " '배': 627,\n",
       " '영화/문화모바일상품권': 628,\n",
       " '남성스포츠속옷': 629,\n",
       " '보온도시락': 630,\n",
       " '남아스웨트셔츠/후드/집업': 631,\n",
       " '홍삼절편': 632,\n",
       " '침실가구세트': 633,\n",
       " '일반네일/케어류': 634,\n",
       " '남성슬리퍼': 635,\n",
       " '시계세트': 636,\n",
       " '한우선물세트': 637,\n",
       " '남성클러치백': 638,\n",
       " '붕붕카/스프링카/흔들말': 639,\n",
       " '이발기': 640,\n",
       " '삼계탕용닭': 641,\n",
       " '남아레깅스': 642,\n",
       " '블록': 643,\n",
       " '기타청소기': 644,\n",
       " '남성양말선물세트': 645,\n",
       " '남성캐쥬얼스포츠양말': 646,\n",
       " '목욕타올': 647,\n",
       " '여성골프스웨트셔츠/후드/집업': 648,\n",
       " '호일/랩/기름종이': 649,\n",
       " '파일/바인더': 650,\n",
       " '기타피트니스기구': 651,\n",
       " '영양제세트': 652,\n",
       " '튜브/보트': 653,\n",
       " '에어로빅복': 654,\n",
       " '여성사파리': 655,\n",
       " '러닝/워킹머신': 656,\n",
       " '롤스크린': 657,\n",
       " '애견이동장': 658,\n",
       " '액상표백제': 659,\n",
       " '야외용돗자리': 660,\n",
       " '침대': 661,\n",
       " '여성등산전신/원피스': 662,\n",
       " '메탈미용소도구': 663,\n",
       " '모빌': 664,\n",
       " '주전자': 665,\n",
       " '주류잔': 666,\n",
       " '오븐팬/피자팬': 667,\n",
       " '홍삼근': 668,\n",
       " '남성사파리': 669,\n",
       " '여성골프점퍼/재킷': 670,\n",
       " '형광펜': 671,\n",
       " '독서대': 672,\n",
       " '보석세트': 673,\n",
       " '열쇠고리': 674,\n",
       " '기타여성의류아우터': 675,\n",
       " '영유아코트': 676,\n",
       " '군모': 677,\n",
       " '헬스바이크': 678,\n",
       " '남성등산/아웃도어세트': 679,\n",
       " '남성등산전신': 680,\n",
       " '유아동부츠': 681,\n",
       " '남성컴포트화': 682,\n",
       " '영유아스웨터/풀오버': 683,\n",
       " '스탠드형김치냉장고': 684,\n",
       " '부분세탁제': 685,\n",
       " '닭윗날개(봉)': 686,\n",
       " '샤워커튼': 687,\n",
       " '골프채': 688,\n",
       " '미러리스': 689,\n",
       " '기타유아안전용품': 690,\n",
       " '영유아재킷': 691,\n",
       " '등산지팡이/스틱': 692,\n",
       " '땅콩': 693,\n",
       " '냉동밥': 694,\n",
       " '스포츠아대/헤어밴드': 695,\n",
       " '순금/순은/장식품': 696,\n",
       " '가발/부분가발': 697,\n",
       " '여성등산/아웃도어세트': 698,\n",
       " '전기그릴': 699,\n",
       " '그릴/구이불판': 700,\n",
       " '컵/행주살균기': 701,\n",
       " '뚝배기': 702,\n",
       " '기타유아동양말류': 703,\n",
       " '유아변기/배변훈련기': 704,\n",
       " '여성골프전신/원피스': 705,\n",
       " '무릎담요': 706,\n",
       " '태블릿PC': 707,\n",
       " '캐슈넛': 708,\n",
       " '남성스포츠패딩': 709,\n",
       " '싱크대/배수구용품': 710,\n",
       " '여성스포츠속옷': 711,\n",
       " '교자상/다용도상': 712,\n",
       " '캐쥬얼힙색': 713,\n",
       " '매직/보드마카': 714,\n",
       " '영유아스웨트셔츠/후드/집업': 715,\n",
       " '남성골프베스트': 716,\n",
       " '여성스포츠스커트': 717,\n",
       " '자/제도용품': 718,\n",
       " '문구세트': 719,\n",
       " '남성수면양말': 720,\n",
       " '남아스웨터/풀오버': 721,\n",
       " '일반세탁기': 722,\n",
       " '캐쥬얼숄더백': 723,\n",
       " '이불/옷커버류': 724,\n",
       " '전기냄비/뚝배기': 725,\n",
       " '피스타치오': 726,\n",
       " '돼지고기선물세트': 727,\n",
       " '전자계산기': 728,\n",
       " '힙색/사이드백': 729,\n",
       " '머플러': 730,\n",
       " '넥워머': 731,\n",
       " '젓갈': 732,\n",
       " '세탁비누': 733,\n",
       " '목욕가운': 734,\n",
       " '남성발가락양말': 735,\n",
       " '공유기': 736,\n",
       " '협탁': 737,\n",
       " '성인침대커버/스커트': 738,\n",
       " '명함정리용품': 739,\n",
       " '절임반찬': 740,\n",
       " '과실주병': 741,\n",
       " '립밤/립스크럽': 742,\n",
       " '제모용품': 743,\n",
       " '제모기': 744,\n",
       " '계량도구': 745,\n",
       " '보드류': 746,\n",
       " '프린터/복합기/스캐너': 747,\n",
       " '양념통': 748,\n",
       " '방울토마토': 749,\n",
       " '밤': 750,\n",
       " '스포츠목걸이/팔찌': 751,\n",
       " '고양이식기/급수': 752,\n",
       " '그늘막/타프': 753,\n",
       " '기타모바일기기': 754,\n",
       " '유아동옷장': 755,\n",
       " '남아가디건': 756,\n",
       " '테이블데코': 757,\n",
       " '여성스포츠전신/원피스': 758,\n",
       " '냅킨': 759,\n",
       " '바란스': 760,\n",
       " '뚜껑형김치냉장고': 761,\n",
       " '남성골프니트/가디건': 762,\n",
       " '여아코트': 763,\n",
       " '유아동매트리스커버': 764,\n",
       " '여성스포츠패딩': 765,\n",
       " '다기류': 766,\n",
       " '컴팩트': 767,\n",
       " '2단우산': 768,\n",
       " '기타냉장고': 769,\n",
       " '물병': 770,\n",
       " '데스크탑/올인원PC': 771,\n",
       " '기타카메라': 772,\n",
       " '마카다미아': 773,\n",
       " '냉동부침': 774,\n",
       " '브로치': 775,\n",
       " '남아베스트': 776,\n",
       " '여행용세트': 777,\n",
       " '귤류': 778,\n",
       " '하이앤드': 779,\n",
       " '항아리/쌀독류': 780,\n",
       " '헤어롤': 781,\n",
       " '여아스웨터/풀오버': 782,\n",
       " '냉동고': 783,\n",
       " '하이브리드': 784,\n",
       " '기타여성양말류': 785,\n",
       " '패션액세서리세트': 786,\n",
       " '기타영유아아우터': 787,\n",
       " '잣': 788,\n",
       " '스포츠음료': 789,\n",
       " '스테이플러': 790,\n",
       " '영유아패딩': 791,\n",
       " '기타배낭소품': 792,\n",
       " '시공가구': 793,\n",
       " 'DIY가구': 794,\n",
       " '살구': 795,\n",
       " '여성수면양말': 796,\n",
       " '유아동침구매트': 797,\n",
       " '기타남성양말류': 798,\n",
       " '정수기': 799,\n",
       " '여아실내복': 800,\n",
       " '모니터': 801,\n",
       " '유아동침구속통/솜': 802,\n",
       " '전동보드/전동킥보드': 803,\n",
       " '공간박스': 804,\n",
       " '하이패스': 805,\n",
       " '신발장': 806,\n",
       " 'DSLR': 807,\n",
       " '남성실내복': 808,\n",
       " '기타남성화': 809,\n",
       " '네비게이션': 810,\n",
       " '전기프라이팬': 811,\n",
       " '여성실내복': 812,\n",
       " '오프너/와인스크류': 813,\n",
       " '유아동시계': 814,\n",
       " '환풍기': 815,\n",
       " '볶음반찬': 816,\n",
       " '파티션': 817,\n",
       " '냉온풍기': 818,\n",
       " '펀치류': 819,\n",
       " '냉동피자': 820,\n",
       " '기차/레일완구': 821,\n",
       " '인라인/롤러스케이트': 822,\n",
       " '매실': 823,\n",
       " '주방용탈수기': 824,\n",
       " '유아동침대커버/스커트': 825,\n",
       " '기타자동차가전기기': 826,\n",
       " '여성캐쥬얼스포츠양말': 827,\n",
       " '네일세트': 828,\n",
       " '남성스포츠베스트': 829,\n",
       " '채칼/강판/절구': 830,\n",
       " '캐쥬얼시계': 831,\n",
       " '니삭스/오버니삭스': 832,\n",
       " '싸인물/자석/압핀': 833,\n",
       " '고양이의류/악세서리': 834,\n",
       " '비타민/에너지음료': 835,\n",
       " '에어워셔': 836,\n",
       " '냉장/냉동가전소모품': 837,\n",
       " '남성부츠': 838,\n",
       " '물걸레청소기': 839,\n",
       " '음식물건조기': 840,\n",
       " '요구르트/청국장제조기': 841,\n",
       " '골프채세트': 842,\n",
       " '고양이이동장': 843,\n",
       " '냉동면': 844,\n",
       " '소프트웨어': 845,\n",
       " '캠코더': 846,\n",
       " '무화과': 847,\n",
       " 'OLED': 848,\n",
       " '탈수기': 849,\n",
       " '육가공품선물세트': 850,\n",
       " '딸기': 851,\n",
       " '식기세척기': 852,\n",
       " '차량용충전기': 853,\n",
       " '유아두유': 854,\n",
       " '닭근위': 855,\n",
       " '닭아랫날개(윙)': 856,\n",
       " '안경소품': 857,\n",
       " '여성가방액세서리': 858,\n",
       " '태닝/애프터선케어': 859,\n",
       " '유아동스포츠스커트': 860,\n",
       " '카메라렌즈': 861,\n",
       " '닭안심': 862,\n",
       " '포도': 863,\n",
       " '볶음탕용닭': 864,\n",
       " '콜렉션인형': 865,\n",
       " 'LCD': 866,\n",
       " '리모컨/액세서리': 867,\n",
       " '반죽기/제면기': 868,\n",
       " '식기건조기': 869,\n",
       " '단무지': 870,\n",
       " '닭다리': 871,\n",
       " '감': 872,\n",
       " '오리고기': 873,\n",
       " '침구청소기': 874,\n",
       " '싱크대': 875,\n",
       " '미용거울': 876,\n",
       " '남녀공용향수세트': 877,\n",
       " '인라인/스케이트보드/킥보드기타액세서리': 878,\n",
       " '남성등산스웨트셔츠/후드/집업': 879,\n",
       " '커튼류세트': 880,\n",
       " '오토캠핑용품세트': 881,\n",
       " '수도용품': 882,\n",
       " '석류': 883,\n",
       " '양푼/믹싱볼': 884,\n",
       " '자연/과학완구': 885,\n",
       " '기저귀크림/파우더': 886,\n",
       " '세탁기소모품': 887,\n",
       " '냉동디저트': 888,\n",
       " '기타광학기기': 889}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clac3_nm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b77932eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['clac1_nm'] = data_test['clac1_nm'].map(lambda x: [clac1_nm_dic[nm] for nm in x])\n",
    "data_test['clac2_nm'] = data_test['clac2_nm'].map(lambda x: [clac2_nm_dic[nm] for nm in x])\n",
    "data_test['clac3_nm'] = data_test['clac3_nm'].map(lambda x: [clac3_nm_dic[nm] for nm in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "51b20f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_matrix = np.zeros((len(data_test), len(clac1_nm_dic)))\n",
    "for i in range(len(data_test)):\n",
    "    for j in data_test['clac1_nm'][i]:\n",
    "        clac1_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "91dbc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac1_nm_' + str(i) for i in range(len(clac1_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8408cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac1_df = pd.DataFrame(clac1_matrix)\n",
    "clac1_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "42ffd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_matrix = np.zeros((len(data_test), len(clac2_nm_dic)))\n",
    "for i in range(len(data_test)):\n",
    "    for j in data_test['clac2_nm'][i]:\n",
    "        clac2_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf1c4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac2_nm_' + str(i) for i in range(len(clac2_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "669ceea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac2_df = pd.DataFrame(clac2_matrix)\n",
    "clac2_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "83909ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_matrix = np.zeros((len(data_test), len(clac3_nm_dic)))\n",
    "for i in range(len(data_test)):\n",
    "    for j in data_test['clac3_nm'][i]:\n",
    "        clac3_matrix[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2fbf8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clac3_nm_' + str(i) for i in range(len(clac3_nm_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2c89f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clac3_df = pd.DataFrame(clac3_matrix)\n",
    "clac3_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a0a12d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_concat = pd.concat([data_test.iloc[:, :-5], clac1_df, clac2_df, clac3_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b020941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>num_shopping</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_price</th>\n",
       "      <th>avg_ct</th>\n",
       "      <th>total_ct</th>\n",
       "      <th>avg_sess_view</th>\n",
       "      <th>total_sess_view</th>\n",
       "      <th>avg_sess_hr</th>\n",
       "      <th>total_sess_hr</th>\n",
       "      <th>...</th>\n",
       "      <th>clac3_nm_880</th>\n",
       "      <th>clac3_nm_881</th>\n",
       "      <th>clac3_nm_882</th>\n",
       "      <th>clac3_nm_883</th>\n",
       "      <th>clac3_nm_884</th>\n",
       "      <th>clac3_nm_885</th>\n",
       "      <th>clac3_nm_886</th>\n",
       "      <th>clac3_nm_887</th>\n",
       "      <th>clac3_nm_888</th>\n",
       "      <th>clac3_nm_889</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32000</td>\n",
       "      <td>128000</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>4</td>\n",
       "      <td>211.333</td>\n",
       "      <td>634</td>\n",
       "      <td>3315</td>\n",
       "      <td>9945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>106400</td>\n",
       "      <td>212800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>186</td>\n",
       "      <td>1051</td>\n",
       "      <td>2102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>123000</td>\n",
       "      <td>369000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.667</td>\n",
       "      <td>404</td>\n",
       "      <td>1745.67</td>\n",
       "      <td>5237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>17587.9</td>\n",
       "      <td>334170</td>\n",
       "      <td>1.11765</td>\n",
       "      <td>19</td>\n",
       "      <td>105.412</td>\n",
       "      <td>1792</td>\n",
       "      <td>1356.71</td>\n",
       "      <td>23064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>63000</td>\n",
       "      <td>126000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>138</td>\n",
       "      <td>2120</td>\n",
       "      <td>4240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113099</th>\n",
       "      <td>263089</td>\n",
       "      <td>3</td>\n",
       "      <td>68633.3</td>\n",
       "      <td>205900</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63.3333</td>\n",
       "      <td>190</td>\n",
       "      <td>1700.33</td>\n",
       "      <td>5101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113100</th>\n",
       "      <td>263097</td>\n",
       "      <td>4</td>\n",
       "      <td>60610</td>\n",
       "      <td>242440</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>469.75</td>\n",
       "      <td>1879</td>\n",
       "      <td>3422</td>\n",
       "      <td>13688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113101</th>\n",
       "      <td>263098</td>\n",
       "      <td>1</td>\n",
       "      <td>100200</td>\n",
       "      <td>100200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>1175</td>\n",
       "      <td>1175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113102</th>\n",
       "      <td>263099</td>\n",
       "      <td>4</td>\n",
       "      <td>12250</td>\n",
       "      <td>49000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>1096</td>\n",
       "      <td>3890</td>\n",
       "      <td>15560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113103</th>\n",
       "      <td>263100</td>\n",
       "      <td>2</td>\n",
       "      <td>11200</td>\n",
       "      <td>22400</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>1474.5</td>\n",
       "      <td>2949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113104 rows × 1066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clnt_id num_shopping avg_price total_price   avg_ct total_ct  \\\n",
       "0            2            3     32000      128000  1.33333        4   \n",
       "1            3            2    106400      212800        1        2   \n",
       "2           10            3    123000      369000        1        3   \n",
       "3           15           17   17587.9      334170  1.11765       19   \n",
       "4           29            2     63000      126000        1        2   \n",
       "...        ...          ...       ...         ...      ...      ...   \n",
       "113099  263089            3   68633.3      205900        1        3   \n",
       "113100  263097            4     60610      242440        1        4   \n",
       "113101  263098            1    100200      100200        1        1   \n",
       "113102  263099            4     12250       49000        1        4   \n",
       "113103  263100            2     11200       22400        1        2   \n",
       "\n",
       "       avg_sess_view total_sess_view avg_sess_hr total_sess_hr  ...  \\\n",
       "0            211.333             634        3315          9945  ...   \n",
       "1                 93             186        1051          2102  ...   \n",
       "2            134.667             404     1745.67          5237  ...   \n",
       "3            105.412            1792     1356.71         23064  ...   \n",
       "4                 69             138        2120          4240  ...   \n",
       "...              ...             ...         ...           ...  ...   \n",
       "113099       63.3333             190     1700.33          5101  ...   \n",
       "113100        469.75            1879        3422         13688  ...   \n",
       "113101           136             136        1175          1175  ...   \n",
       "113102           274            1096        3890         15560  ...   \n",
       "113103           104             208      1474.5          2949  ...   \n",
       "\n",
       "       clac3_nm_880  clac3_nm_881  clac3_nm_882  clac3_nm_883  clac3_nm_884  \\\n",
       "0               0.0           0.0           0.0           0.0           0.0   \n",
       "1               0.0           0.0           0.0           0.0           0.0   \n",
       "2               0.0           0.0           0.0           0.0           0.0   \n",
       "3               0.0           0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "113099          0.0           0.0           0.0           0.0           0.0   \n",
       "113100          0.0           0.0           0.0           0.0           0.0   \n",
       "113101          0.0           0.0           0.0           0.0           0.0   \n",
       "113102          0.0           0.0           0.0           0.0           0.0   \n",
       "113103          0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        clac3_nm_885  clac3_nm_886  clac3_nm_887  clac3_nm_888  clac3_nm_889  \n",
       "0                0.0           0.0           0.0           0.0           0.0  \n",
       "1                0.0           0.0           0.0           0.0           0.0  \n",
       "2                0.0           0.0           0.0           0.0           0.0  \n",
       "3                0.0           0.0           0.0           0.0           0.0  \n",
       "4                0.0           0.0           0.0           0.0           0.0  \n",
       "...              ...           ...           ...           ...           ...  \n",
       "113099           0.0           0.0           0.0           0.0           0.0  \n",
       "113100           0.0           0.0           0.0           0.0           0.0  \n",
       "113101           0.0           0.0           0.0           0.0           0.0  \n",
       "113102           0.0           0.0           0.0           0.0           0.0  \n",
       "113103           0.0           0.0           0.0           0.0           0.0  \n",
       "\n",
       "[113104 rows x 1066 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7d569400",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac1 = np.array(data_test_concat.iloc[:, 11:48]).dot(lookup_table_clac1)\n",
    "mat_clac1 = mat_clac1 / mat_clac1.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "da110d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac1 = pd.DataFrame(mat_clac1)\n",
    "mat_clac1 = mat_clac1.rename(columns={0: 'given_clac1_F20_prob', 1:'given_clac1_F30_prob', 2:'given_clac1_F40_prob', 3:'given_clac1_M20_prob', 4:'given_clac1_M30_prob', 5:'given_clac1_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b91c9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac1 = np.where(np.array(data_test_concat.iloc[:, 11:48]) >= 1, 1, 0).dot(lookup_table_clac1)\n",
    "mat_buy_clac1 = mat_buy_clac1 / mat_buy_clac1.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d1e33ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac1 = pd.DataFrame(mat_buy_clac1)\n",
    "mat_buy_clac1 = mat_buy_clac1.rename(columns={0: 'buy_clac1_F20_prob', 1:'buy_clac1_F30_prob', 2:'buy_clac1_F40_prob', 3:'buy_clac1_M20_prob', 4:'buy_clac1_M30_prob', 5:'buy_clac1_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1d3c9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac2 = np.array(data_test_concat.iloc[:, 48:-890]).dot(lookup_table_clac2)\n",
    "mat_clac2 = mat_clac2 / mat_clac2.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "032239eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac2 = pd.DataFrame(mat_clac2)\n",
    "mat_clac2 = mat_clac2.rename(columns={0: 'given_clac2_F20_prob', 1:'given_clac2_F30_prob', 2:'given_clac2_F40_prob', 3:'given_clac2_M20_prob', 4:'given_clac2_M30_prob', 5:'given_clac2_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a5973ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac2 = np.where(np.array(data_test_concat.iloc[:, 48:-890]) >= 1, 1, 0).dot(lookup_table_clac2)\n",
    "mat_buy_clac2 = mat_buy_clac2 / mat_buy_clac2.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c3bc1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac2 = pd.DataFrame(mat_buy_clac2)\n",
    "mat_buy_clac2 = mat_buy_clac2.rename(columns={0: 'buy_clac2_F20_prob', 1:'buy_clac2_F30_prob', 2:'buy_clac2_F40_prob', 3:'buy_clac2_M20_prob', 4:'buy_clac2_M30_prob', 5:'buy_clac2_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "af5a9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_clac3 = np.concatenate([lookup_table_clac3, np.ones([7, 6]) * 1/6], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7c9b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac3 = np.array(data_test_concat.iloc[:, -890:]).dot(lookup_table_clac3)\n",
    "mat_clac3 = mat_clac3 / mat_clac3.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "94362059",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_clac3 = pd.DataFrame(mat_clac3)\n",
    "mat_clac3 = mat_clac3.rename(columns={0: 'given_clac3_F20_prob', 1:'given_clac3_F30_prob', 2:'given_clac3_F40_prob', 3:'given_clac3_M20_prob', 4:'given_clac3_M30_prob', 5:'given_clac3_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a78ecc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac3 = np.where(np.array(data_test_concat.iloc[:, -890:]) >= 1, 1, 0).dot(lookup_table_clac3)\n",
    "mat_buy_clac3 = mat_buy_clac3 / mat_buy_clac3.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3fe045e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_buy_clac3 = pd.DataFrame(mat_buy_clac3)\n",
    "mat_buy_clac3 = mat_buy_clac3.rename(columns={0: 'buy_clac3_F20_prob', 1:'buy_clac3_F30_prob', 2:'buy_clac3_F40_prob', 3:'buy_clac3_M20_prob', 4:'buy_clac3_M30_prob', 5:'buy_clac3_M40_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c0c83bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['PD_C'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'PD_C'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3137eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:04<00:00, 27884.46it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_pd_w2v[-len(test_pd_w2v):]):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        pd_mean_vector.append(tmp)\n",
    "        \n",
    "pd_mean_vector = np.array(pd_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "05fb6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [17:48, 105.88it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_pd_w2v[-len(test_pd_w2v):])):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        pd_unweight_vector.append(tmp)\n",
    "        \n",
    "pd_unweight_vector = np.array(pd_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e9bfff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [09:06, 207.03it/s]\n"
     ]
    }
   ],
   "source": [
    "pd_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_pd_w2v[-len(test_pd_w2v):])):\n",
    "        tmp = np.zeros(256) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += pd_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        pd_weight_vector.append(tmp)\n",
    "        \n",
    "pd_weight_vector = np.array(pd_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5f539051",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd_mean = pd_mean_vector\n",
    "test_pd_unweight = pd_unweight_vector\n",
    "test_pd_weight = pd_weight_vector\n",
    "\n",
    "test_pd_mean = pd.DataFrame(test_pd_mean)\n",
    "test_pd_unweight = pd.DataFrame(test_pd_unweight)\n",
    "test_pd_weight = pd.DataFrame(test_pd_weight)\n",
    "\n",
    "test_pd_mean.columns = ['pd_mean_'+str(i) for i in range(256)]\n",
    "test_pd_unweight.columns = ['pd_unweight_'+str(i) for i in range(256)]\n",
    "test_pd_weight.columns = ['pd_weight_'+str(i) for i in range(256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b52301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['PD_BRA_NM'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'PD_BRA_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a1ee2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:02<00:00, 39453.33it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_bra_w2v[-len(test_bra_w2v):]):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        bra_mean_vector.append(tmp)\n",
    "        \n",
    "bra_mean_vector = np.array(bra_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b4389401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [10:29, 179.56it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_bra_w2v[-len(test_bra_w2v):])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        bra_unweight_vector.append(tmp)\n",
    "        \n",
    "bra_unweight_vector = np.array(bra_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7185932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [06:47, 277.46it/s]\n"
     ]
    }
   ],
   "source": [
    "bra_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_bra_w2v[-len(test_bra_w2v):])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += bra_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        bra_weight_vector.append(tmp)\n",
    "        \n",
    "bra_weight_vector = np.array(bra_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a9321ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bra_mean = bra_mean_vector\n",
    "test_bra_unweight = bra_unweight_vector\n",
    "test_bra_weight = bra_weight_vector\n",
    "\n",
    "test_bra_mean = pd.DataFrame(test_bra_mean)\n",
    "test_bra_unweight = pd.DataFrame(test_bra_unweight)\n",
    "test_bra_weight = pd.DataFrame(test_bra_weight)\n",
    "\n",
    "test_bra_mean.columns = ['bra_mean_'+str(i) for i in range(128)]\n",
    "test_bra_unweight.columns = ['bra_unweight_'+str(i) for i in range(128)]\n",
    "test_bra_weight.columns = ['bra_weight_'+str(i) for i in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "41307a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['KWD_NM'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'KWD_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cd4aabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:04<00:00, 23558.67it/s]\n"
     ]
    }
   ],
   "source": [
    "kwd_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_kwd_w2v[-len(test_kwd_w2v):]):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        kwd_mean_vector.append(tmp)\n",
    "        \n",
    "kwd_mean_vector = np.array(kwd_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6676a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [27:14, 69.20it/s] \n"
     ]
    }
   ],
   "source": [
    "kwd_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_kwd_w2v[-len(test_kwd_w2v):])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word] * tt[kk[i]][word]\n",
    "                cnt += tt[kk[i]][word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        kwd_unweight_vector.append(tmp)\n",
    "        \n",
    "kwd_unweight_vector = np.array(kwd_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2820ce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [11:43, 160.87it/s]\n"
     ]
    }
   ],
   "source": [
    "kwd_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_kwd_w2v[-len(test_kwd_w2v):])):\n",
    "        tmp = np.zeros(128) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += kwd_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        kwd_weight_vector.append(tmp)\n",
    "        \n",
    "kwd_weight_vector = np.array(kwd_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "465dd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwd_mean = kwd_mean_vector\n",
    "test_kwd_unweight = kwd_unweight_vector\n",
    "test_kwd_weight = kwd_weight_vector\n",
    "\n",
    "test_kwd_mean = pd.DataFrame(test_kwd_mean)\n",
    "test_kwd_unweight = pd.DataFrame(test_kwd_unweight)\n",
    "test_kwd_weight = pd.DataFrame(test_kwd_weight)\n",
    "\n",
    "test_kwd_mean.columns = ['kwd_mean_'+str(i) for i in range(128)]\n",
    "test_kwd_unweight.columns = ['kwd_unweight_'+str(i) for i in range(128)]\n",
    "test_kwd_weight.columns = ['kwd_weight_'+str(i) for i in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cc0035b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['CLAC3_NM'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'CLAC3_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2938f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:02<00:00, 41843.84it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac3_w2v[-len(test_clac3_w2v):]):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        clac3_mean_vector.append(tmp)\n",
    "        \n",
    "clac3_mean_vector = np.array(clac3_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0961ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [00:04, 26316.69it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac3_w2v[-len(test_clac3_w2v):])):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word] * clac3_matrix[i, clac3_nm_dic[word]]\n",
    "                cnt += clac3_matrix[i, clac3_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac3_unweight_vector.append(tmp)\n",
    "        \n",
    "clac3_unweight_vector = np.array(clac3_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2731348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [06:47, 277.63it/s]\n"
     ]
    }
   ],
   "source": [
    "clac3_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac3_w2v[-len(test_clac3_w2v):])):\n",
    "        tmp = np.zeros(30) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac3_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac3_weight_vector.append(tmp)\n",
    "        \n",
    "clac3_weight_vector = np.array(clac3_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "57cedee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clac3_mean = clac3_mean_vector\n",
    "test_clac3_unweight = clac3_unweight_vector\n",
    "test_clac3_weight = clac3_weight_vector\n",
    "\n",
    "test_clac3_mean = pd.DataFrame(test_clac3_mean)\n",
    "test_clac3_unweight = pd.DataFrame(test_clac3_unweight)\n",
    "test_clac3_weight = pd.DataFrame(test_clac3_weight)\n",
    "\n",
    "test_clac3_mean.columns = ['clac3_mean_'+str(i) for i in range(30)]\n",
    "test_clac3_unweight.columns = ['clac3_unweight_'+str(i) for i in range(30)]\n",
    "test_clac3_weight.columns = ['clac3_weight_'+str(i) for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "955d2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['CLAC2_NM'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'CLAC2_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "188ce700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:02<00:00, 46386.39it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac2_w2v[-len(test_clac2_w2v):]):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        clac2_mean_vector.append(tmp)\n",
    "        \n",
    "clac2_mean_vector = np.array(clac2_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "12ef2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [00:03, 31331.93it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac2_w2v[-len(test_clac2_w2v):])):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word] * clac2_matrix[i, clac2_nm_dic[word]]\n",
    "                cnt += clac2_matrix[i, clac2_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac2_unweight_vector.append(tmp)\n",
    "        \n",
    "clac2_unweight_vector = np.array(clac2_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "97416d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [05:47, 325.31it/s]\n"
     ]
    }
   ],
   "source": [
    "clac2_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac2_w2v[-len(test_clac2_w2v):])):\n",
    "        tmp = np.zeros(10) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac2_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac2_weight_vector.append(tmp)\n",
    "        \n",
    "clac2_weight_vector = np.array(clac2_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "50366967",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clac2_mean = clac2_mean_vector\n",
    "test_clac2_unweight = clac2_unweight_vector\n",
    "test_clac2_weight = clac2_weight_vector\n",
    "\n",
    "test_clac2_mean = pd.DataFrame(test_clac2_mean)\n",
    "test_clac2_unweight = pd.DataFrame(test_clac2_unweight)\n",
    "test_clac2_weight = pd.DataFrame(test_clac2_weight)\n",
    "\n",
    "test_clac2_mean.columns = ['clac2_mean_'+str(i) for i in range(10)]\n",
    "test_clac2_unweight.columns = ['clac2_unweight_'+str(i) for i in range(10)]\n",
    "test_clac2_weight.columns = ['clac2_weight_'+str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "563a490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_test.groupby('CLNT_ID')['CLAC1_NM'].value_counts()[df_test['CLNT_ID'].unique()]\n",
    "kk = df_test['CLNT_ID'].unique()\n",
    "ww = df_test.groupby(['CLNT_ID', 'CLAC1_NM'])['KWD_NM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "67ace089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:01<00:00, 57800.50it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_clac1_w2v[-len(test_clac1_w2v):]):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt  \n",
    "        clac1_mean_vector.append(tmp)\n",
    "        \n",
    "clac1_mean_vector = np.array(clac1_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7df4b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [00:02, 38104.20it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_unweight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac1_w2v[-len(test_clac1_w2v):])):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word] * clac1_matrix[i, clac1_nm_dic[word]]\n",
    "                cnt += clac1_matrix[i, clac1_nm_dic[word]]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac1_unweight_vector.append(tmp)\n",
    "        \n",
    "clac1_unweight_vector = np.array(clac1_unweight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7df755e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113104it [04:28, 421.84it/s]\n"
     ]
    }
   ],
   "source": [
    "clac1_weight_vector = []\n",
    "\n",
    "for i, words in tqdm(enumerate(train_clac1_w2v[-len(test_clac1_w2v):])):\n",
    "        tmp = np.zeros(5) \n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += clac1_w2v[word] * (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "                cnt += (ww[kk[i]] / ww[kk[i]].sum())[word]\n",
    "            except:\n",
    "                pass\n",
    "        #tmp /= cnt \n",
    "        clac1_weight_vector.append(tmp)\n",
    "        \n",
    "clac1_weight_vector = np.array(clac1_weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1be52159",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clac1_mean = clac1_mean_vector\n",
    "test_clac1_unweight = clac1_unweight_vector\n",
    "test_clac1_weight = clac1_weight_vector\n",
    "\n",
    "test_clac1_mean = pd.DataFrame(test_clac1_mean)\n",
    "test_clac1_unweight = pd.DataFrame(test_clac1_unweight)\n",
    "test_clac1_weight = pd.DataFrame(test_clac1_weight)\n",
    "\n",
    "test_clac1_mean.columns = ['clac1_mean_'+str(i) for i in range(5)]\n",
    "test_clac1_unweight.columns = ['clac1_unweight_'+str(i) for i in range(5)]\n",
    "test_clac1_weight.columns = ['clac1_weight_'+str(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "da6b9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_concat = pd.concat([data_test_concat.iloc[:, 1:11], mat_clac1, mat_buy_clac1, mat_clac2, mat_buy_clac2, mat_clac3, mat_buy_clac3, test_pd_mean, test_bra_mean, test_kwd_mean, test_clac1_mean, test_clac2_mean, test_clac3_mean, test_pd_unweight, test_bra_unweight, test_kwd_unweight, test_clac1_unweight, test_clac2_unweight, test_clac3_unweight, test_pd_weight, test_bra_weight, test_kwd_weight, test_clac1_weight, test_clac2_weight, test_clac3_weight], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1d8319ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_concat.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d04c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_concat = pd.read_csv('test.csv')\n",
    "test_stat = pd.read_csv('stat_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "293c70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_concat = pd.concat([test_stat.iloc[:, 1:], data_test_concat.iloc[:, 10:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "392a3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(data_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7097add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_test_scaled[:, :-557])\n",
    "pred2 = model2.predict(X_test_scaled[:, :-557])\n",
    "pred3 = model3.predict(X_test_scaled[:, :-557])\n",
    "pred4 = model4.predict(X_test_scaled[:, :-557])\n",
    "pred5 = model5.predict(X_test_scaled[:, :-557])\n",
    "pred6 = model6.predict(X_test_scaled[:, :-557])\n",
    "pred7 = model7.predict(X_test_scaled[:, :-557])\n",
    "pred8 = model8.predict(X_test_scaled[:, :-557])\n",
    "pred9 = model9.predict(X_test_scaled[:, :-557])\n",
    "pred10 = model10.predict(X_test_scaled[:, :-557])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04c5a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp = (pred1 + pred2 + pred3 + pred4 + pred5 + pred6 + pred7 + pred8 + pred9 + pred10) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d000c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb = np.zeros((len(X_test_scaled), 6))\n",
    "for i in range(n_model):\n",
    "    pred_lgb += model_dict['model_'+str(i)].predict(X_test_scaled)\n",
    "pred_lgb = pred_lgb / n_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "642f55ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01483922, 0.75846819, 0.12915512, 0.00084974, 0.06176788,\n",
       "        0.03491985],\n",
       "       [0.49494485, 0.2411636 , 0.16966314, 0.05907518, 0.01124558,\n",
       "        0.02390764],\n",
       "       [0.04323738, 0.2232262 , 0.49311356, 0.01315682, 0.09265073,\n",
       "        0.13461531],\n",
       "       ...,\n",
       "       [0.05330672, 0.37161363, 0.31219931, 0.02595297, 0.09278512,\n",
       "        0.14414225],\n",
       "       [0.17001405, 0.47227626, 0.16736071, 0.05017716, 0.09524455,\n",
       "        0.04492727],\n",
       "       [0.0470015 , 0.20116348, 0.6817618 , 0.00733369, 0.01636128,\n",
       "        0.04637825]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5fcf375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred_mlp + pred_lgb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7daec60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03059318, 0.72713347, 0.1353143 , 0.00091057, 0.07431102,\n",
       "        0.03173749],\n",
       "       [0.57986506, 0.20258786, 0.12928684, 0.06264269, 0.01032955,\n",
       "        0.01528801],\n",
       "       [0.04360476, 0.2405963 , 0.4654439 , 0.01737814, 0.09299009,\n",
       "        0.13998683],\n",
       "       ...,\n",
       "       [0.04565929, 0.35647236, 0.34295776, 0.01862472, 0.08863805,\n",
       "        0.14764782],\n",
       "       [0.13791403, 0.45997391, 0.23494042, 0.0298647 , 0.08869868,\n",
       "        0.04860827],\n",
       "       [0.05066791, 0.18960662, 0.67846334, 0.00921454, 0.01420041,\n",
       "        0.05784716]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e0c691aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7a2f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[:, 1:] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cbf40810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_ID</th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.727133</td>\n",
       "      <td>0.135314</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>0.031737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.579865</td>\n",
       "      <td>0.202588</td>\n",
       "      <td>0.129287</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.015288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.043605</td>\n",
       "      <td>0.240596</td>\n",
       "      <td>0.465444</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>0.092990</td>\n",
       "      <td>0.139987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>0.280376</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.073255</td>\n",
       "      <td>0.076189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>0.329472</td>\n",
       "      <td>0.091156</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113099</th>\n",
       "      <td>263089</td>\n",
       "      <td>0.173268</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.402903</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.019356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113100</th>\n",
       "      <td>263097</td>\n",
       "      <td>0.143175</td>\n",
       "      <td>0.268077</td>\n",
       "      <td>0.522866</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>0.050065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113101</th>\n",
       "      <td>263098</td>\n",
       "      <td>0.045659</td>\n",
       "      <td>0.356472</td>\n",
       "      <td>0.342958</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>0.147648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113102</th>\n",
       "      <td>263099</td>\n",
       "      <td>0.137914</td>\n",
       "      <td>0.459974</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.029865</td>\n",
       "      <td>0.088699</td>\n",
       "      <td>0.048608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113103</th>\n",
       "      <td>263100</td>\n",
       "      <td>0.050668</td>\n",
       "      <td>0.189607</td>\n",
       "      <td>0.678463</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.057847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CLNT_ID       F20       F30       F40       M20       M30       M40\n",
       "0             2  0.030593  0.727133  0.135314  0.000911  0.074311  0.031737\n",
       "1             3  0.579865  0.202588  0.129287  0.062643  0.010330  0.015288\n",
       "2            10  0.043605  0.240596  0.465444  0.017378  0.092990  0.139987\n",
       "3            15  0.017765  0.550447  0.280376  0.001969  0.073255  0.076189\n",
       "4            29  0.552116  0.329472  0.091156  0.007910  0.011378  0.007968\n",
       "...         ...       ...       ...       ...       ...       ...       ...\n",
       "113099   263089  0.173268  0.391064  0.402903  0.002203  0.011206  0.019356\n",
       "113100   263097  0.143175  0.268077  0.522866  0.004085  0.011733  0.050065\n",
       "113101   263098  0.045659  0.356472  0.342958  0.018625  0.088638  0.147648\n",
       "113102   263099  0.137914  0.459974  0.234940  0.029865  0.088699  0.048608\n",
       "113103   263100  0.050668  0.189607  0.678463  0.009215  0.014200  0.057847\n",
       "\n",
       "[113104 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d92bbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('./sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ff136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2508c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
